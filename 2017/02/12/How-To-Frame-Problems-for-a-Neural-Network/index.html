<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://52ml.me">
  <title>How To &quot;Frame Problems&quot; for a Neural Network | 52ml</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sentiment Classification &amp;amp; How To “Frame Problems” for a Neural Networkby Andrew Trask

Twitter: @iamtrask
Blog: http://iamtrask.github.io

What You Should Already Know
neural networks, forward an">
<meta property="og:type" content="article">
<meta property="og:title" content="How To "Frame Problems" for a Neural Network">
<meta property="og:url" content="http://52ml.me/2017/02/12/How-To-Frame-Problems-for-a-Neural-Network/index.html">
<meta property="og:site_name" content="52ml">
<meta property="og:description" content="Sentiment Classification &amp;amp; How To “Frame Problems” for a Neural Networkby Andrew Trask

Twitter: @iamtrask
Blog: http://iamtrask.github.io

What You Should Already Know
neural networks, forward an">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_18_0.png">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_19_0.png">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_24_0.png">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_45_0.png">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_57_0.png">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_68_0.png">
<meta property="og:image" content="http://52ml.me/assets/img/neural_network/output_75_0.png">
<meta property="og:updated_time" content="2017-02-13T07:04:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="How To "Frame Problems" for a Neural Network">
<meta name="twitter:description" content="Sentiment Classification &amp;amp; How To “Frame Problems” for a Neural Networkby Andrew Trask

Twitter: @iamtrask
Blog: http://iamtrask.github.io

What You Should Already Know
neural networks, forward an">
<meta name="twitter:image" content="http://52ml.me/assets/img/neural_network/output_18_0.png">
  
    <link rel="alternative" href="/atom.xml" title="52ml" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.2d7529.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="https://avatars2.githubusercontent.com/u/1274619?v=3&amp;u=c6a71cc5c764a76986801e43adec5e2e1b7de320&amp;s=140" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Vincent</a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/tags/机器学习">机器学习</a></li>
	        
				<li><a href="/tags/纳米学位">纳米学位</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/andyli386" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="http://weibo.com/u/5705860183" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="weixin" target="_blank" href="/assets/img/andyli386.jpg" title="weixin"><i class="icon-weixin"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="https://avatars2.githubusercontent.com/u/1274619?v=3&amp;u=c6a71cc5c764a76986801e43adec5e2e1b7de320&amp;s=140" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Vincent</h1>
			</hgroup>
			
			
			
				
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/andyli386" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/u/5705860183" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="weixin" target="_blank" href="/assets/img/andyli386.jpg" title="weixin"><i class="icon-weixin"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 70%">
				
				
					<li style="width: 33.333333333333336%"><a href="/">主页</a></li>
		        
					<li style="width: 33.333333333333336%"><a href="/tags/机器学习">机器学习</a></li>
		        
					<li style="width: 33.333333333333336%"><a href="/tags/纳米学位">纳米学位</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-How-To-Frame-Problems-for-a-Neural-Network" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      How To &quot;Frame Problems&quot; for a Neural Network
    </h1>
  

        
        <a href="/2017/02/12/How-To-Frame-Problems-for-a-Neural-Network/" class="archive-article-date">
  	<time datetime="2017-02-12T13:01:02.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2017-02-12</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Sentiment-Classification-amp-How-To-“Frame-Problems”-for-a-Neural-Network"><a href="#Sentiment-Classification-amp-How-To-“Frame-Problems”-for-a-Neural-Network" class="headerlink" title="Sentiment Classification &amp; How To “Frame Problems” for a Neural Network"></a>Sentiment Classification &amp; How To “Frame Problems” for a Neural Network</h1><p>by Andrew Trask</p>
<ul>
<li><strong>Twitter</strong>: @iamtrask</li>
<li><strong>Blog</strong>: <a href="http://iamtrask.github.io" target="_blank" rel="external">http://iamtrask.github.io</a></li>
</ul>
<h3 id="What-You-Should-Already-Know"><a href="#What-You-Should-Already-Know" class="headerlink" title="What You Should Already Know"></a>What You Should Already Know</h3><ul>
<li>neural networks, forward and back-propagation</li>
<li>stochastic gradient descent</li>
<li>mean squared error</li>
<li>and train/test splits</li>
</ul>
<h3 id="Where-to-Get-Help-if-You-Need-it"><a href="#Where-to-Get-Help-if-You-Need-it" class="headerlink" title="Where to Get Help if You Need it"></a>Where to Get Help if You Need it</h3><ul>
<li>Re-watch previous Udacity Lectures</li>
<li>Leverage the recommended Course Reading Material - <a href="https://www.manning.com/books/grokking-deep-learning" target="_blank" rel="external">Grokking Deep Learning</a> (40% Off: <strong>traskud17</strong>)</li>
<li>Shoot me a tweet @iamtrask<a id="more"></a>
</li>
</ul>
<h3 id="Tutorial-Outline"><a href="#Tutorial-Outline" class="headerlink" title="Tutorial Outline:"></a>Tutorial Outline:</h3><ul>
<li>Intro: The Importance of “Framing a Problem”</li>
</ul>
<ul>
<li>Curate a Dataset</li>
<li>Developing a “Predictive Theory”</li>
<li><strong>PROJECT 1</strong>: Quick Theory Validation</li>
</ul>
<ul>
<li>Transforming Text to Numbers</li>
<li><strong>PROJECT 2</strong>: Creating the Input/Output Data</li>
</ul>
<ul>
<li>Putting it all together in a Neural Network</li>
<li><strong>PROJECT 3</strong>: Building our Neural Network</li>
</ul>
<ul>
<li>Understanding Neural Noise</li>
<li><strong>PROJECT 4</strong>: Making Learning Faster by Reducing Noise</li>
</ul>
<ul>
<li>Analyzing Inefficiencies in our Network</li>
<li><strong>PROJECT 5</strong>: Making our Network Train and Run Faster</li>
</ul>
<ul>
<li>Further Noise Reduction</li>
<li><strong>PROJECT 6</strong>: Reducing Noise by Strategically Reducing the Vocabulary</li>
</ul>
<ul>
<li>Analysis: What’s going on in the weights?</li>
</ul>
<h1 id="Lesson-Curate-a-Dataset"><a href="#Lesson-Curate-a-Dataset" class="headerlink" title="Lesson: Curate a Dataset"></a>Lesson: Curate a Dataset</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretty_print_review_and_label</span><span class="params">(i)</span>:</span></div><div class="line">    print(labels[i] + <span class="string">"\t:\t"</span> + reviews[i][:<span class="number">80</span>] + <span class="string">"..."</span>)</div><div class="line"></div><div class="line">g = open(<span class="string">'reviews.txt'</span>,<span class="string">'r'</span>) <span class="comment"># What we know!</span></div><div class="line">reviews = list(map(<span class="keyword">lambda</span> x:x[:<span class="number">-1</span>],g.readlines()))</div><div class="line">g.close()</div><div class="line"></div><div class="line">g = open(<span class="string">'labels.txt'</span>,<span class="string">'r'</span>) <span class="comment"># What we WANT to know!</span></div><div class="line">labels = list(map(<span class="keyword">lambda</span> x:x[:<span class="number">-1</span>].upper(),g.readlines()))</div><div class="line">g.close()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">len(reviews)</div></pre></td></tr></table></figure>
<pre><code>25000
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">reviews[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<pre><code>&apos;bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   &apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">labels[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<pre><code>&apos;POSITIVE&apos;
</code></pre><h1 id="Lesson-Develop-a-Predictive-Theory"><a href="#Lesson-Develop-a-Predictive-Theory" class="headerlink" title="Lesson: Develop a Predictive Theory"></a>Lesson: Develop a Predictive Theory</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">"labels.txt \t : \t reviews.txt\n"</span>)</div><div class="line">pretty_print_review_and_label(<span class="number">2137</span>)</div><div class="line">pretty_print_review_and_label(<span class="number">12816</span>)</div><div class="line">pretty_print_review_and_label(<span class="number">6267</span>)</div><div class="line">pretty_print_review_and_label(<span class="number">21934</span>)</div><div class="line">pretty_print_review_and_label(<span class="number">5297</span>)</div><div class="line">pretty_print_review_and_label(<span class="number">4998</span>)</div></pre></td></tr></table></figure>
<pre><code>labels.txt      :      reviews.txt

NEGATIVE    :    this movie is terrible but it has some good effects .  ...
POSITIVE    :    adrian pasdar is excellent is this film . he makes a fascinating woman .  ...
NEGATIVE    :    comment this movie is impossible . is terrible  very improbable  bad interpretat...
POSITIVE    :    excellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...
NEGATIVE    :    if you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...
POSITIVE    :    this schiffer guy is a real genius  the movie is of excellent quality and both e...
</code></pre><h1 id="Project-1-Quick-Theory-Validation"><a href="#Project-1-Quick-Theory-Validation" class="headerlink" title="Project 1: Quick Theory Validation"></a>Project 1: Quick Theory Validation</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">positive_counts = Counter()</div><div class="line">negative_counts = Counter()</div><div class="line">total_counts = Counter()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(reviews)):</div><div class="line">    <span class="keyword">if</span>(labels[i] == <span class="string">'POSITIVE'</span>):</div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> reviews[i].split(<span class="string">" "</span>):</div><div class="line">            positive_counts[word] += <span class="number">1</span></div><div class="line">            total_counts[word] += <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> reviews[i].split(<span class="string">" "</span>):</div><div class="line">            negative_counts[word] += <span class="number">1</span></div><div class="line">            total_counts[word] += <span class="number">1</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">positive_counts.most_common()</div></pre></td></tr></table></figure>
<pre><code>[(&apos;&apos;, 550468),
 (&apos;the&apos;, 173324),
 (&apos;.&apos;, 159654),
 (&apos;and&apos;, 89722),
 (&apos;a&apos;, 83688),
 (&apos;of&apos;, 76855),
 (&apos;to&apos;, 66746),
 (&apos;is&apos;, 57245),
 (&apos;in&apos;, 50215),
 (&apos;br&apos;, 49235),
 (&apos;it&apos;, 48025),
 (&apos;i&apos;, 40743),
 (&apos;that&apos;, 35630),
 (&apos;this&apos;, 35080),
 (&apos;s&apos;, 33815),
 (&apos;as&apos;, 26308),
 (&apos;with&apos;, 23247),
 (&apos;for&apos;, 22416),
 (&apos;was&apos;, 21917),
 (&apos;film&apos;, 20937),
 (&apos;but&apos;, 20822),
 (&apos;movie&apos;, 19074),
 (&apos;his&apos;, 17227),
 (&apos;on&apos;, 17008),
 (&apos;you&apos;, 16681),
 (&apos;he&apos;, 16282),
 (&apos;are&apos;, 14807),
 (&apos;not&apos;, 14272),
 (&apos;t&apos;, 13720),
 (&apos;one&apos;, 13655),
 (&apos;have&apos;, 12587),
 (&apos;be&apos;, 12416),
 (&apos;by&apos;, 11997),
 (&apos;all&apos;, 11942),
 (&apos;who&apos;, 11464),
 (&apos;an&apos;, 11294),
 (&apos;at&apos;, 11234),
 (&apos;from&apos;, 10767),
 (&apos;her&apos;, 10474),
 (&apos;they&apos;, 9895),
 (&apos;has&apos;, 9186),
 (&apos;so&apos;, 9154),
 (&apos;like&apos;, 9038),
 (&apos;about&apos;, 8313),
 (&apos;very&apos;, 8305),
 (&apos;out&apos;, 8134),
 (&apos;there&apos;, 8057),
 (&apos;she&apos;, 7779),
 (&apos;what&apos;, 7737),
 (&apos;or&apos;, 7732),
 (&apos;good&apos;, 7720),
 (&apos;more&apos;, 7521),
 (&apos;when&apos;, 7456),
 (&apos;some&apos;, 7441),
 (&apos;if&apos;, 7285),
 (&apos;just&apos;, 7152),
 (&apos;can&apos;, 7001),
 (&apos;story&apos;, 6780),
 (&apos;time&apos;, 6515),
 (&apos;my&apos;, 6488),
 (&apos;great&apos;, 6419),
 (&apos;well&apos;, 6405),
 (&apos;up&apos;, 6321),
 (&apos;which&apos;, 6267),
 (&apos;their&apos;, 6107),
 (&apos;see&apos;, 6026),
 (&apos;also&apos;, 5550),
 (&apos;we&apos;, 5531),
 (&apos;really&apos;, 5476),
 (&apos;would&apos;, 5400),
 (&apos;will&apos;, 5218),
 (&apos;me&apos;, 5167),
 (&apos;had&apos;, 5148),
 (&apos;only&apos;, 5137),
 (&apos;him&apos;, 5018),
 (&apos;even&apos;, 4964),
 (&apos;most&apos;, 4864),
 (&apos;other&apos;, 4858),
 (&apos;were&apos;, 4782),
 (&apos;first&apos;, 4755),
 (&apos;than&apos;, 4736),
 (&apos;much&apos;, 4685),
 (&apos;its&apos;, 4622),
 (&apos;no&apos;, 4574),
 (&apos;into&apos;, 4544),
 (&apos;people&apos;, 4479),
 (&apos;best&apos;, 4319),
 (&apos;love&apos;, 4301),
 (&apos;get&apos;, 4272),
 (&apos;how&apos;, 4213),
 (&apos;life&apos;, 4199),
 (&apos;been&apos;, 4189),
 (&apos;because&apos;, 4079),
 (&apos;way&apos;, 4036),
 (&apos;do&apos;, 3941),
 (&apos;made&apos;, 3823),
 (&apos;films&apos;, 3813),
 (&apos;them&apos;, 3805),
 (&apos;after&apos;, 3800),
 (&apos;many&apos;, 3766),
 (&apos;two&apos;, 3733),
 (&apos;too&apos;, 3659),
 (&apos;think&apos;, 3655),
 (&apos;movies&apos;, 3586),
 (&apos;characters&apos;, 3560),
 (&apos;character&apos;, 3514),
 (&apos;don&apos;, 3468),
 (&apos;man&apos;, 3460),
 (&apos;show&apos;, 3432),
 (&apos;watch&apos;, 3424),
 (&apos;seen&apos;, 3414),
 (&apos;then&apos;, 3358),
 (&apos;little&apos;, 3341),
 (&apos;still&apos;, 3340),
 (&apos;make&apos;, 3303),
 (&apos;could&apos;, 3237),
 (&apos;never&apos;, 3226),
 (&apos;being&apos;, 3217),
 (&apos;where&apos;, 3173),
 (&apos;does&apos;, 3069),
 (&apos;over&apos;, 3017),
 (&apos;any&apos;, 3002),
 (&apos;while&apos;, 2899),
 (&apos;know&apos;, 2833),
 (&apos;did&apos;, 2790),
 (&apos;years&apos;, 2758),
 (&apos;here&apos;, 2740),
 (&apos;ever&apos;, 2734),
 (&apos;end&apos;, 2696),
 (&apos;these&apos;, 2694),
 (&apos;such&apos;, 2590),
 (&apos;real&apos;, 2568),
 (&apos;scene&apos;, 2567),
 (&apos;back&apos;, 2547),
 (&apos;those&apos;, 2485),
 (&apos;though&apos;, 2475),
 (&apos;off&apos;, 2463),
 (&apos;new&apos;, 2458),
 (&apos;your&apos;, 2453),
 (&apos;go&apos;, 2440),
 (&apos;acting&apos;, 2437),
 (&apos;plot&apos;, 2432),
 (&apos;world&apos;, 2429),
 (&apos;scenes&apos;, 2427),
 (&apos;say&apos;, 2414),
 (&apos;through&apos;, 2409),
 (&apos;makes&apos;, 2390),
 (&apos;better&apos;, 2381),
 (&apos;now&apos;, 2368),
 (&apos;work&apos;, 2346),
 (&apos;young&apos;, 2343),
 (&apos;old&apos;, 2311),
 (&apos;ve&apos;, 2307),
 (&apos;find&apos;, 2272),
 (&apos;both&apos;, 2248),
 (&apos;before&apos;, 2177),
 (&apos;us&apos;, 2162),
 (&apos;again&apos;, 2158),
 (&apos;series&apos;, 2153),
 (&apos;quite&apos;, 2143),
 (&apos;something&apos;, 2135),
 (&apos;cast&apos;, 2133),
 (&apos;should&apos;, 2121),
 (&apos;part&apos;, 2098),
 (&apos;always&apos;, 2088),
 (&apos;lot&apos;, 2087),
 (&apos;another&apos;, 2075),
 (&apos;actors&apos;, 2047),
 (&apos;director&apos;, 2040),
 (&apos;family&apos;, 2032),
 (&apos;between&apos;, 2016),
 (&apos;own&apos;, 2016),
 (&apos;m&apos;, 1998),
 (&apos;may&apos;, 1997),
 (&apos;same&apos;, 1972),
 (&apos;role&apos;, 1967),
 (&apos;watching&apos;, 1966),
 (&apos;every&apos;, 1954),
 (&apos;funny&apos;, 1953),
 (&apos;doesn&apos;, 1935),
 (&apos;performance&apos;, 1928),
 (&apos;few&apos;, 1918),
 (&apos;bad&apos;, 1907),
 (&apos;look&apos;, 1900),
 (&apos;re&apos;, 1884),
 (&apos;why&apos;, 1855),
 (&apos;things&apos;, 1849),
 (&apos;times&apos;, 1832),
 (&apos;big&apos;, 1815),
 (&apos;however&apos;, 1795),
 (&apos;actually&apos;, 1790),
 (&apos;action&apos;, 1789),
 (&apos;going&apos;, 1783),
 (&apos;bit&apos;, 1757),
 (&apos;comedy&apos;, 1742),
 (&apos;down&apos;, 1740),
 (&apos;music&apos;, 1738),
 (&apos;must&apos;, 1728),
 (&apos;take&apos;, 1709),
 (&apos;saw&apos;, 1692),
 (&apos;long&apos;, 1690),
 (&apos;right&apos;, 1688),
 (&apos;fun&apos;, 1686),
 (&apos;fact&apos;, 1684),
 (&apos;excellent&apos;, 1683),
 (&apos;around&apos;, 1674),
 (&apos;didn&apos;, 1672),
 (&apos;without&apos;, 1671),
 (&apos;thing&apos;, 1662),
 (&apos;thought&apos;, 1639),
 (&apos;got&apos;, 1635),
 (&apos;each&apos;, 1630),
 (&apos;day&apos;, 1614),
 (&apos;feel&apos;, 1597),
 (&apos;seems&apos;, 1596),
 (&apos;come&apos;, 1594),
 (&apos;done&apos;, 1586),
 (&apos;beautiful&apos;, 1580),
 (&apos;especially&apos;, 1572),
 (&apos;played&apos;, 1571),
 (&apos;almost&apos;, 1566),
 (&apos;want&apos;, 1562),
 (&apos;yet&apos;, 1556),
 (&apos;give&apos;, 1553),
 (&apos;pretty&apos;, 1549),
 (&apos;last&apos;, 1543),
 (&apos;since&apos;, 1519),
 (&apos;different&apos;, 1504),
 (&apos;although&apos;, 1501),
 (&apos;gets&apos;, 1490),
 (&apos;true&apos;, 1487),
 (&apos;interesting&apos;, 1481),
 (&apos;job&apos;, 1470),
 (&apos;enough&apos;, 1455),
 (&apos;our&apos;, 1454),
 (&apos;shows&apos;, 1447),
 (&apos;horror&apos;, 1441),
 (&apos;woman&apos;, 1439),
 (&apos;tv&apos;, 1400),
 (&apos;probably&apos;, 1398),
 (&apos;father&apos;, 1395),
 (&apos;original&apos;, 1393),
 (&apos;girl&apos;, 1390),
 (&apos;point&apos;, 1379),
 (&apos;plays&apos;, 1378),
 (&apos;wonderful&apos;, 1372),
 (&apos;far&apos;, 1358),
 (&apos;course&apos;, 1358),
 (&apos;john&apos;, 1350),
 (&apos;rather&apos;, 1340),
 (&apos;isn&apos;, 1328),
 (&apos;ll&apos;, 1326),
 (&apos;later&apos;, 1324),
 (&apos;dvd&apos;, 1324),
 (&apos;whole&apos;, 1310),
 (&apos;war&apos;, 1310),
 (&apos;d&apos;, 1307),
 (&apos;found&apos;, 1306),
 (&apos;away&apos;, 1306),
 (&apos;screen&apos;, 1305),
 (&apos;nothing&apos;, 1300),
 (&apos;year&apos;, 1297),
 (&apos;once&apos;, 1296),
 (&apos;hard&apos;, 1294),
 (&apos;together&apos;, 1280),
 (&apos;set&apos;, 1277),
 (&apos;am&apos;, 1277),
 (&apos;having&apos;, 1266),
 (&apos;making&apos;, 1265),
 (&apos;place&apos;, 1263),
 (&apos;might&apos;, 1260),
 (&apos;comes&apos;, 1260),
 (&apos;sure&apos;, 1253),
 (&apos;american&apos;, 1248),
 (&apos;play&apos;, 1245),
 (&apos;kind&apos;, 1244),
 (&apos;perfect&apos;, 1242),
 (&apos;takes&apos;, 1242),
 (&apos;performances&apos;, 1237),
 (&apos;himself&apos;, 1230),
 (&apos;worth&apos;, 1221),
 (&apos;everyone&apos;, 1221),
 (&apos;anyone&apos;, 1214),
 (&apos;actor&apos;, 1203),
 (&apos;three&apos;, 1201),
 (&apos;wife&apos;, 1196),
 (&apos;classic&apos;, 1192),
 (&apos;goes&apos;, 1186),
 (&apos;ending&apos;, 1178),
 (&apos;version&apos;, 1168),
 (&apos;star&apos;, 1149),
 (&apos;enjoy&apos;, 1146),
 (&apos;book&apos;, 1142),
 (&apos;nice&apos;, 1132),
 (&apos;everything&apos;, 1128),
 (&apos;during&apos;, 1124),
 (&apos;put&apos;, 1118),
 (&apos;seeing&apos;, 1111),
 (&apos;least&apos;, 1102),
 (&apos;house&apos;, 1100),
 (&apos;high&apos;, 1095),
 (&apos;watched&apos;, 1094),
 (&apos;loved&apos;, 1087),
 (&apos;men&apos;, 1087),
 (&apos;night&apos;, 1082),
 (&apos;anything&apos;, 1075),
 (&apos;believe&apos;, 1071),
 (&apos;guy&apos;, 1071),
 (&apos;top&apos;, 1063),
 (&apos;amazing&apos;, 1058),
 (&apos;hollywood&apos;, 1056),
 (&apos;looking&apos;, 1053),
 (&apos;main&apos;, 1044),
 (&apos;definitely&apos;, 1043),
 (&apos;gives&apos;, 1031),
 (&apos;home&apos;, 1029),
 (&apos;seem&apos;, 1028),
 (&apos;episode&apos;, 1023),
 (&apos;audience&apos;, 1020),
 (&apos;sense&apos;, 1020),
 (&apos;truly&apos;, 1017),
 (&apos;special&apos;, 1011),
 (&apos;second&apos;, 1009),
 (&apos;short&apos;, 1009),
 (&apos;fan&apos;, 1009),
 (&apos;mind&apos;, 1005),
 (&apos;human&apos;, 1001),
 (&apos;recommend&apos;, 999),
 (&apos;full&apos;, 996),
 (&apos;black&apos;, 995),
 (&apos;help&apos;, 991),
 (&apos;along&apos;, 989),
 (&apos;trying&apos;, 987),
 (&apos;small&apos;, 986),
 (&apos;death&apos;, 985),
 (&apos;friends&apos;, 981),
 (&apos;remember&apos;, 974),
 (&apos;often&apos;, 970),
 (&apos;said&apos;, 966),
 (&apos;favorite&apos;, 962),
 (&apos;heart&apos;, 959),
 (&apos;early&apos;, 957),
 (&apos;left&apos;, 956),
 (&apos;until&apos;, 955),
 (&apos;script&apos;, 954),
 (&apos;let&apos;, 954),
 (&apos;maybe&apos;, 937),
 (&apos;today&apos;, 936),
 (&apos;live&apos;, 934),
 (&apos;less&apos;, 934),
 (&apos;moments&apos;, 933),
 (&apos;others&apos;, 929),
 (&apos;brilliant&apos;, 926),
 (&apos;shot&apos;, 925),
 (&apos;liked&apos;, 923),
 (&apos;become&apos;, 916),
 (&apos;won&apos;, 915),
 (&apos;used&apos;, 910),
 (&apos;style&apos;, 907),
 (&apos;mother&apos;, 895),
 (&apos;lives&apos;, 894),
 (&apos;came&apos;, 893),
 (&apos;stars&apos;, 890),
 (&apos;cinema&apos;, 889),
 (&apos;looks&apos;, 885),
 (&apos;perhaps&apos;, 884),
 (&apos;read&apos;, 882),
 (&apos;enjoyed&apos;, 879),
 (&apos;boy&apos;, 875),
 (&apos;drama&apos;, 873),
 (&apos;highly&apos;, 871),
 (&apos;given&apos;, 870),
 (&apos;playing&apos;, 867),
 (&apos;use&apos;, 864),
 (&apos;next&apos;, 859),
 (&apos;women&apos;, 858),
 (&apos;fine&apos;, 857),
 (&apos;effects&apos;, 856),
 (&apos;kids&apos;, 854),
 (&apos;entertaining&apos;, 853),
 (&apos;need&apos;, 852),
 (&apos;line&apos;, 850),
 (&apos;works&apos;, 848),
 (&apos;someone&apos;, 847),
 (&apos;mr&apos;, 836),
 (&apos;simply&apos;, 835),
 (&apos;picture&apos;, 833),
 (&apos;children&apos;, 833),
 (&apos;face&apos;, 831),
 (&apos;keep&apos;, 831),
 (&apos;friend&apos;, 831),
 (&apos;dark&apos;, 830),
 (&apos;overall&apos;, 828),
 (&apos;certainly&apos;, 828),
 (&apos;minutes&apos;, 827),
 (&apos;wasn&apos;, 824),
 (&apos;history&apos;, 822),
 (&apos;finally&apos;, 820),
 (&apos;couple&apos;, 816),
 (&apos;against&apos;, 815),
 (&apos;son&apos;, 809),
 (&apos;understand&apos;, 808),
 (&apos;lost&apos;, 807),
 (&apos;michael&apos;, 805),
 (&apos;else&apos;, 801),
 (&apos;throughout&apos;, 798),
 (&apos;fans&apos;, 797),
 (&apos;city&apos;, 792),
 (&apos;reason&apos;, 789),
 (&apos;written&apos;, 787),
 (&apos;production&apos;, 787),
 (&apos;several&apos;, 784),
 (&apos;school&apos;, 783),
 (&apos;based&apos;, 781),
 (&apos;rest&apos;, 781),
 (&apos;try&apos;, 780),
 (&apos;dead&apos;, 776),
 (&apos;hope&apos;, 775),
 (&apos;strong&apos;, 768),
 (&apos;white&apos;, 765),
 (&apos;tell&apos;, 759),
 (&apos;itself&apos;, 758),
 (&apos;half&apos;, 753),
 (&apos;person&apos;, 749),
 (&apos;sometimes&apos;, 746),
 (&apos;past&apos;, 744),
 (&apos;start&apos;, 744),
 (&apos;genre&apos;, 743),
 (&apos;beginning&apos;, 739),
 (&apos;final&apos;, 739),
 (&apos;town&apos;, 738),
 (&apos;art&apos;, 734),
 (&apos;humor&apos;, 732),
 (&apos;game&apos;, 732),
 (&apos;yes&apos;, 731),
 (&apos;idea&apos;, 731),
 (&apos;late&apos;, 730),
 (&apos;becomes&apos;, 729),
 (&apos;despite&apos;, 729),
 (&apos;able&apos;, 726),
 (&apos;case&apos;, 726),
 (&apos;money&apos;, 723),
 (&apos;child&apos;, 721),
 (&apos;completely&apos;, 721),
 (&apos;side&apos;, 719),
 (&apos;camera&apos;, 716),
 (&apos;getting&apos;, 714),
 (&apos;instead&apos;, 712),
 (&apos;soon&apos;, 702),
 (&apos;under&apos;, 700),
 (&apos;viewer&apos;, 699),
 (&apos;age&apos;, 697),
 (&apos;days&apos;, 696),
 (&apos;stories&apos;, 696),
 (&apos;felt&apos;, 694),
 (&apos;simple&apos;, 694),
 (&apos;roles&apos;, 693),
 (&apos;video&apos;, 688),
 (&apos;name&apos;, 683),
 (&apos;either&apos;, 683),
 (&apos;doing&apos;, 677),
 (&apos;turns&apos;, 674),
 (&apos;wants&apos;, 671),
 (&apos;close&apos;, 671),
 (&apos;title&apos;, 669),
 (&apos;wrong&apos;, 668),
 (&apos;went&apos;, 666),
 (&apos;james&apos;, 665),
 (&apos;evil&apos;, 659),
 (&apos;budget&apos;, 657),
 (&apos;episodes&apos;, 657),
 (&apos;relationship&apos;, 655),
 (&apos;fantastic&apos;, 653),
 (&apos;piece&apos;, 653),
 (&apos;david&apos;, 651),
 (&apos;turn&apos;, 648),
 (&apos;murder&apos;, 646),
 (&apos;parts&apos;, 645),
 (&apos;brother&apos;, 644),
 (&apos;absolutely&apos;, 643),
 (&apos;head&apos;, 643),
 (&apos;experience&apos;, 642),
 (&apos;eyes&apos;, 641),
 (&apos;sex&apos;, 638),
 (&apos;direction&apos;, 637),
 (&apos;called&apos;, 637),
 (&apos;directed&apos;, 636),
 (&apos;lines&apos;, 634),
 (&apos;behind&apos;, 633),
 (&apos;sort&apos;, 632),
 (&apos;actress&apos;, 631),
 (&apos;lead&apos;, 630),
 (&apos;oscar&apos;, 628),
 (&apos;including&apos;, 627),
 (&apos;example&apos;, 627),
 (&apos;known&apos;, 625),
 (&apos;musical&apos;, 625),
 (&apos;chance&apos;, 621),
 (&apos;score&apos;, 620),
 (&apos;already&apos;, 619),
 (&apos;feeling&apos;, 619),
 (&apos;hit&apos;, 619),
 (&apos;voice&apos;, 615),
 (&apos;moment&apos;, 612),
 (&apos;living&apos;, 612),
 (&apos;low&apos;, 610),
 (&apos;supporting&apos;, 610),
 (&apos;ago&apos;, 609),
 (&apos;themselves&apos;, 608),
 (&apos;reality&apos;, 605),
 (&apos;hilarious&apos;, 605),
 (&apos;jack&apos;, 604),
 (&apos;told&apos;, 603),
 (&apos;hand&apos;, 601),
 (&apos;quality&apos;, 600),
 (&apos;moving&apos;, 600),
 (&apos;dialogue&apos;, 600),
 (&apos;song&apos;, 599),
 (&apos;happy&apos;, 599),
 (&apos;matter&apos;, 598),
 (&apos;paul&apos;, 598),
 (&apos;light&apos;, 594),
 (&apos;future&apos;, 593),
 (&apos;entire&apos;, 592),
 (&apos;finds&apos;, 591),
 (&apos;gave&apos;, 589),
 (&apos;laugh&apos;, 587),
 (&apos;released&apos;, 586),
 (&apos;expect&apos;, 584),
 (&apos;fight&apos;, 581),
 (&apos;particularly&apos;, 580),
 (&apos;cinematography&apos;, 579),
 (&apos;police&apos;, 579),
 (&apos;whose&apos;, 578),
 (&apos;type&apos;, 578),
 (&apos;sound&apos;, 578),
 (&apos;view&apos;, 573),
 (&apos;enjoyable&apos;, 573),
 (&apos;number&apos;, 572),
 (&apos;romantic&apos;, 572),
 (&apos;husband&apos;, 572),
 (&apos;daughter&apos;, 572),
 (&apos;documentary&apos;, 571),
 (&apos;self&apos;, 570),
 (&apos;superb&apos;, 569),
 (&apos;modern&apos;, 569),
 (&apos;took&apos;, 569),
 (&apos;robert&apos;, 569),
 (&apos;mean&apos;, 566),
 (&apos;shown&apos;, 563),
 (&apos;coming&apos;, 561),
 (&apos;important&apos;, 560),
 (&apos;king&apos;, 559),
 (&apos;leave&apos;, 559),
 (&apos;change&apos;, 558),
 (&apos;somewhat&apos;, 555),
 (&apos;wanted&apos;, 555),
 (&apos;tells&apos;, 554),
 (&apos;events&apos;, 552),
 (&apos;run&apos;, 552),
 (&apos;career&apos;, 552),
 (&apos;country&apos;, 552),
 (&apos;heard&apos;, 550),
 (&apos;season&apos;, 550),
 (&apos;greatest&apos;, 549),
 (&apos;girls&apos;, 549),
 (&apos;etc&apos;, 547),
 (&apos;care&apos;, 546),
 (&apos;starts&apos;, 545),
 (&apos;english&apos;, 542),
 (&apos;killer&apos;, 541),
 (&apos;tale&apos;, 540),
 (&apos;guys&apos;, 540),
 (&apos;totally&apos;, 540),
 (&apos;animation&apos;, 540),
 (&apos;usual&apos;, 539),
 (&apos;miss&apos;, 535),
 (&apos;opinion&apos;, 535),
 (&apos;easy&apos;, 531),
 (&apos;violence&apos;, 531),
 (&apos;songs&apos;, 530),
 (&apos;british&apos;, 528),
 (&apos;says&apos;, 526),
 (&apos;realistic&apos;, 525),
 (&apos;writing&apos;, 524),
 (&apos;writer&apos;, 522),
 (&apos;act&apos;, 522),
 (&apos;comic&apos;, 521),
 (&apos;thriller&apos;, 519),
 (&apos;television&apos;, 517),
 (&apos;power&apos;, 516),
 (&apos;ones&apos;, 515),
 (&apos;kid&apos;, 514),
 (&apos;york&apos;, 513),
 (&apos;novel&apos;, 513),
 (&apos;alone&apos;, 512),
 (&apos;problem&apos;, 512),
 (&apos;attention&apos;, 509),
 (&apos;involved&apos;, 508),
 (&apos;kill&apos;, 507),
 (&apos;extremely&apos;, 507),
 (&apos;seemed&apos;, 506),
 (&apos;hero&apos;, 505),
 (&apos;french&apos;, 505),
 (&apos;rock&apos;, 504),
 (&apos;stuff&apos;, 501),
 (&apos;wish&apos;, 499),
 (&apos;begins&apos;, 498),
 (&apos;taken&apos;, 497),
 (&apos;sad&apos;, 497),
 (&apos;ways&apos;, 496),
 (&apos;richard&apos;, 495),
 (&apos;knows&apos;, 494),
 (&apos;atmosphere&apos;, 493),
 (&apos;similar&apos;, 491),
 (&apos;surprised&apos;, 491),
 (&apos;taking&apos;, 491),
 (&apos;car&apos;, 491),
 (&apos;george&apos;, 490),
 (&apos;perfectly&apos;, 490),
 (&apos;across&apos;, 489),
 (&apos;team&apos;, 489),
 (&apos;eye&apos;, 489),
 (&apos;sequence&apos;, 489),
 (&apos;room&apos;, 488),
 (&apos;due&apos;, 488),
 (&apos;among&apos;, 488),
 (&apos;serious&apos;, 488),
 (&apos;powerful&apos;, 488),
 (&apos;strange&apos;, 487),
 (&apos;order&apos;, 487),
 (&apos;cannot&apos;, 487),
 (&apos;b&apos;, 487),
 (&apos;beauty&apos;, 486),
 (&apos;famous&apos;, 485),
 (&apos;happened&apos;, 484),
 (&apos;tries&apos;, 484),
 (&apos;herself&apos;, 484),
 (&apos;myself&apos;, 484),
 (&apos;class&apos;, 483),
 (&apos;four&apos;, 482),
 (&apos;cool&apos;, 481),
 (&apos;release&apos;, 479),
 (&apos;anyway&apos;, 479),
 (&apos;theme&apos;, 479),
 (&apos;opening&apos;, 478),
 (&apos;entertainment&apos;, 477),
 (&apos;slow&apos;, 475),
 (&apos;ends&apos;, 475),
 (&apos;unique&apos;, 475),
 (&apos;exactly&apos;, 475),
 (&apos;easily&apos;, 474),
 (&apos;level&apos;, 474),
 (&apos;o&apos;, 474),
 (&apos;red&apos;, 474),
 (&apos;interest&apos;, 472),
 (&apos;happen&apos;, 471),
 (&apos;crime&apos;, 470),
 (&apos;viewing&apos;, 468),
 (&apos;sets&apos;, 467),
 (&apos;memorable&apos;, 467),
 (&apos;stop&apos;, 466),
 (&apos;group&apos;, 466),
 (&apos;problems&apos;, 463),
 (&apos;dance&apos;, 463),
 (&apos;working&apos;, 463),
 (&apos;sister&apos;, 463),
 (&apos;message&apos;, 463),
 (&apos;knew&apos;, 462),
 (&apos;mystery&apos;, 461),
 (&apos;nature&apos;, 461),
 (&apos;bring&apos;, 460),
 (&apos;believable&apos;, 459),
 (&apos;thinking&apos;, 459),
 (&apos;brought&apos;, 459),
 (&apos;mostly&apos;, 458),
 (&apos;disney&apos;, 457),
 (&apos;couldn&apos;, 457),
 (&apos;society&apos;, 456),
 (&apos;lady&apos;, 455),
 (&apos;within&apos;, 455),
 (&apos;blood&apos;, 454),
 (&apos;parents&apos;, 453),
 (&apos;upon&apos;, 453),
 (&apos;viewers&apos;, 453),
 (&apos;meets&apos;, 452),
 (&apos;form&apos;, 452),
 (&apos;peter&apos;, 452),
 (&apos;tom&apos;, 452),
 (&apos;usually&apos;, 452),
 (&apos;soundtrack&apos;, 452),
 (&apos;local&apos;, 450),
 (&apos;certain&apos;, 448),
 (&apos;follow&apos;, 448),
 (&apos;whether&apos;, 447),
 (&apos;possible&apos;, 446),
 (&apos;emotional&apos;, 445),
 (&apos;killed&apos;, 444),
 (&apos;above&apos;, 444),
 (&apos;de&apos;, 444),
 (&apos;god&apos;, 443),
 (&apos;middle&apos;, 443),
 (&apos;needs&apos;, 442),
 (&apos;happens&apos;, 442),
 (&apos;flick&apos;, 442),
 (&apos;masterpiece&apos;, 441),
 (&apos;period&apos;, 440),
 (&apos;major&apos;, 440),
 (&apos;named&apos;, 439),
 (&apos;haven&apos;, 439),
 (&apos;particular&apos;, 438),
 (&apos;th&apos;, 438),
 (&apos;earth&apos;, 437),
 (&apos;feature&apos;, 437),
 (&apos;stand&apos;, 436),
 (&apos;words&apos;, 435),
 (&apos;typical&apos;, 435),
 (&apos;elements&apos;, 433),
 (&apos;obviously&apos;, 433),
 (&apos;romance&apos;, 431),
 (&apos;jane&apos;, 430),
 (&apos;yourself&apos;, 427),
 (&apos;showing&apos;, 427),
 (&apos;brings&apos;, 426),
 (&apos;fantasy&apos;, 426),
 (&apos;guess&apos;, 423),
 (&apos;america&apos;, 423),
 (&apos;unfortunately&apos;, 422),
 (&apos;huge&apos;, 422),
 (&apos;indeed&apos;, 421),
 (&apos;running&apos;, 421),
 (&apos;talent&apos;, 420),
 (&apos;stage&apos;, 419),
 (&apos;started&apos;, 418),
 (&apos;leads&apos;, 417),
 (&apos;sweet&apos;, 417),
 (&apos;japanese&apos;, 417),
 (&apos;poor&apos;, 416),
 (&apos;deal&apos;, 416),
 (&apos;incredible&apos;, 413),
 (&apos;personal&apos;, 413),
 (&apos;fast&apos;, 412),
 (&apos;became&apos;, 410),
 (&apos;deep&apos;, 410),
 (&apos;hours&apos;, 409),
 (&apos;giving&apos;, 408),
 (&apos;nearly&apos;, 408),
 (&apos;dream&apos;, 408),
 (&apos;clearly&apos;, 407),
 (&apos;turned&apos;, 407),
 (&apos;obvious&apos;, 406),
 (&apos;near&apos;, 406),
 (&apos;cut&apos;, 405),
 (&apos;surprise&apos;, 405),
 (&apos;era&apos;, 404),
 (&apos;body&apos;, 404),
 (&apos;hour&apos;, 403),
 (&apos;female&apos;, 403),
 (&apos;five&apos;, 403),
 (&apos;note&apos;, 399),
 (&apos;learn&apos;, 398),
 (&apos;truth&apos;, 398),
 (&apos;except&apos;, 397),
 (&apos;feels&apos;, 397),
 (&apos;match&apos;, 397),
 (&apos;tony&apos;, 397),
 (&apos;filmed&apos;, 394),
 (&apos;clear&apos;, 394),
 (&apos;complete&apos;, 394),
 (&apos;street&apos;, 393),
 (&apos;eventually&apos;, 393),
 (&apos;keeps&apos;, 393),
 (&apos;older&apos;, 393),
 (&apos;lots&apos;, 393),
 (&apos;buy&apos;, 392),
 (&apos;william&apos;, 391),
 (&apos;stewart&apos;, 391),
 (&apos;fall&apos;, 390),
 (&apos;joe&apos;, 390),
 (&apos;meet&apos;, 390),
 (&apos;unlike&apos;, 389),
 (&apos;talking&apos;, 389),
 (&apos;shots&apos;, 389),
 (&apos;rating&apos;, 389),
 (&apos;difficult&apos;, 389),
 (&apos;dramatic&apos;, 388),
 (&apos;means&apos;, 388),
 (&apos;situation&apos;, 386),
 (&apos;wonder&apos;, 386),
 (&apos;present&apos;, 386),
 (&apos;appears&apos;, 386),
 (&apos;subject&apos;, 386),
 (&apos;comments&apos;, 385),
 (&apos;general&apos;, 383),
 (&apos;sequences&apos;, 383),
 (&apos;lee&apos;, 383),
 (&apos;points&apos;, 382),
 (&apos;earlier&apos;, 382),
 (&apos;gone&apos;, 379),
 (&apos;check&apos;, 379),
 (&apos;suspense&apos;, 378),
 (&apos;recommended&apos;, 378),
 (&apos;ten&apos;, 378),
 (&apos;third&apos;, 377),
 (&apos;business&apos;, 377),
 (&apos;talk&apos;, 375),
 (&apos;leaves&apos;, 375),
 (&apos;beyond&apos;, 375),
 (&apos;portrayal&apos;, 374),
 (&apos;beautifully&apos;, 373),
 (&apos;single&apos;, 372),
 (&apos;bill&apos;, 372),
 (&apos;plenty&apos;, 371),
 (&apos;word&apos;, 371),
 (&apos;whom&apos;, 370),
 (&apos;falls&apos;, 370),
 (&apos;scary&apos;, 369),
 (&apos;non&apos;, 369),
 (&apos;figure&apos;, 369),
 (&apos;battle&apos;, 369),
 (&apos;using&apos;, 368),
 (&apos;return&apos;, 368),
 (&apos;doubt&apos;, 367),
 (&apos;add&apos;, 367),
 (&apos;hear&apos;, 366),
 (&apos;solid&apos;, 366),
 (&apos;success&apos;, 366),
 (&apos;jokes&apos;, 365),
 (&apos;oh&apos;, 365),
 (&apos;touching&apos;, 365),
 (&apos;political&apos;, 365),
 (&apos;hell&apos;, 364),
 (&apos;awesome&apos;, 364),
 (&apos;boys&apos;, 364),
 (&apos;sexual&apos;, 362),
 (&apos;recently&apos;, 362),
 (&apos;dog&apos;, 362),
 (&apos;please&apos;, 361),
 (&apos;wouldn&apos;, 361),
 (&apos;straight&apos;, 361),
 (&apos;features&apos;, 361),
 (&apos;forget&apos;, 360),
 (&apos;setting&apos;, 360),
 (&apos;lack&apos;, 360),
 (&apos;married&apos;, 359),
 (&apos;mark&apos;, 359),
 (&apos;social&apos;, 357),
 (&apos;interested&apos;, 356),
 (&apos;adventure&apos;, 356),
 (&apos;actual&apos;, 355),
 (&apos;terrific&apos;, 355),
 (&apos;sees&apos;, 355),
 (&apos;brothers&apos;, 355),
 (&apos;move&apos;, 354),
 (&apos;call&apos;, 354),
 (&apos;various&apos;, 353),
 (&apos;theater&apos;, 353),
 (&apos;dr&apos;, 353),
 (&apos;animated&apos;, 352),
 (&apos;western&apos;, 351),
 (&apos;baby&apos;, 350),
 (&apos;space&apos;, 350),
 (&apos;leading&apos;, 348),
 (&apos;disappointed&apos;, 348),
 (&apos;portrayed&apos;, 346),
 (&apos;aren&apos;, 346),
 (&apos;screenplay&apos;, 345),
 (&apos;smith&apos;, 345),
 (&apos;towards&apos;, 344),
 (&apos;hate&apos;, 344),
 (&apos;noir&apos;, 343),
 (&apos;outstanding&apos;, 342),
 (&apos;decent&apos;, 342),
 (&apos;kelly&apos;, 342),
 (&apos;directors&apos;, 341),
 (&apos;journey&apos;, 341),
 (&apos;none&apos;, 340),
 (&apos;looked&apos;, 340),
 (&apos;effective&apos;, 340),
 (&apos;storyline&apos;, 339),
 (&apos;caught&apos;, 339),
 (&apos;sci&apos;, 339),
 (&apos;fi&apos;, 339),
 (&apos;cold&apos;, 339),
 (&apos;mary&apos;, 339),
 (&apos;rich&apos;, 338),
 (&apos;charming&apos;, 338),
 (&apos;popular&apos;, 337),
 (&apos;rare&apos;, 337),
 (&apos;manages&apos;, 337),
 (&apos;harry&apos;, 337),
 (&apos;spirit&apos;, 336),
 (&apos;appreciate&apos;, 335),
 (&apos;open&apos;, 335),
 (&apos;moves&apos;, 334),
 (&apos;basically&apos;, 334),
 (&apos;acted&apos;, 334),
 (&apos;inside&apos;, 333),
 (&apos;boring&apos;, 333),
 (&apos;century&apos;, 333),
 (&apos;mention&apos;, 333),
 (&apos;deserves&apos;, 333),
 (&apos;subtle&apos;, 333),
 (&apos;pace&apos;, 333),
 (&apos;familiar&apos;, 332),
 (&apos;background&apos;, 332),
 (&apos;ben&apos;, 331),
 (&apos;creepy&apos;, 330),
 (&apos;supposed&apos;, 330),
 (&apos;secret&apos;, 329),
 (&apos;die&apos;, 328),
 (&apos;jim&apos;, 328),
 (&apos;question&apos;, 327),
 (&apos;effect&apos;, 327),
 (&apos;natural&apos;, 327),
 (&apos;impressive&apos;, 326),
 (&apos;rate&apos;, 326),
 (&apos;language&apos;, 326),
 (&apos;saying&apos;, 325),
 (&apos;intelligent&apos;, 325),
 (&apos;telling&apos;, 324),
 (&apos;realize&apos;, 324),
 (&apos;material&apos;, 324),
 (&apos;scott&apos;, 324),
 (&apos;singing&apos;, 323),
 (&apos;dancing&apos;, 322),
 (&apos;visual&apos;, 321),
 (&apos;adult&apos;, 321),
 (&apos;imagine&apos;, 321),
 (&apos;kept&apos;, 320),
 (&apos;office&apos;, 320),
 (&apos;uses&apos;, 319),
 (&apos;pure&apos;, 318),
 (&apos;wait&apos;, 318),
 (&apos;stunning&apos;, 318),
 (&apos;review&apos;, 317),
 (&apos;previous&apos;, 317),
 (&apos;copy&apos;, 317),
 (&apos;seriously&apos;, 317),
 (&apos;reading&apos;, 316),
 (&apos;create&apos;, 316),
 (&apos;hot&apos;, 316),
 (&apos;created&apos;, 316),
 (&apos;magic&apos;, 316),
 (&apos;somehow&apos;, 316),
 (&apos;stay&apos;, 315),
 (&apos;attempt&apos;, 315),
 (&apos;escape&apos;, 315),
 (&apos;crazy&apos;, 315),
 (&apos;air&apos;, 315),
 (&apos;frank&apos;, 315),
 (&apos;hands&apos;, 314),
 (&apos;filled&apos;, 313),
 (&apos;expected&apos;, 312),
 (&apos;average&apos;, 312),
 (&apos;surprisingly&apos;, 312),
 (&apos;complex&apos;, 311),
 (&apos;quickly&apos;, 310),
 (&apos;successful&apos;, 310),
 (&apos;studio&apos;, 310),
 (&apos;plus&apos;, 309),
 (&apos;male&apos;, 309),
 (&apos;co&apos;, 307),
 (&apos;images&apos;, 306),
 (&apos;casting&apos;, 306),
 (&apos;following&apos;, 306),
 (&apos;minute&apos;, 306),
 (&apos;exciting&apos;, 306),
 (&apos;members&apos;, 305),
 (&apos;follows&apos;, 305),
 (&apos;themes&apos;, 305),
 (&apos;german&apos;, 305),
 (&apos;reasons&apos;, 305),
 (&apos;e&apos;, 305),
 (&apos;touch&apos;, 304),
 (&apos;edge&apos;, 304),
 (&apos;free&apos;, 304),
 (&apos;cute&apos;, 304),
 (&apos;genius&apos;, 304),
 (&apos;outside&apos;, 303),
 (&apos;reviews&apos;, 302),
 (&apos;admit&apos;, 302),
 (&apos;ok&apos;, 302),
 (&apos;younger&apos;, 302),
 (&apos;fighting&apos;, 301),
 (&apos;odd&apos;, 301),
 (&apos;master&apos;, 301),
 (&apos;recent&apos;, 300),
 (&apos;thanks&apos;, 300),
 (&apos;break&apos;, 300),
 (&apos;comment&apos;, 300),
 (&apos;apart&apos;, 299),
 (&apos;emotions&apos;, 298),
 (&apos;lovely&apos;, 298),
 (&apos;begin&apos;, 298),
 (&apos;doctor&apos;, 297),
 (&apos;party&apos;, 297),
 (&apos;italian&apos;, 297),
 (&apos;la&apos;, 296),
 (&apos;missed&apos;, 296),
 ...]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">pos_neg_ratios = Counter()</div><div class="line"></div><div class="line"><span class="keyword">for</span> term,cnt <span class="keyword">in</span> list(total_counts.most_common()):</div><div class="line">    <span class="keyword">if</span>(cnt &gt; <span class="number">100</span>):</div><div class="line">        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+<span class="number">1</span>)</div><div class="line">        pos_neg_ratios[term] = pos_neg_ratio</div><div class="line"></div><div class="line"><span class="keyword">for</span> word,ratio <span class="keyword">in</span> pos_neg_ratios.most_common():</div><div class="line">    <span class="keyword">if</span>(ratio &gt; <span class="number">1</span>):</div><div class="line">        pos_neg_ratios[word] = np.log(ratio)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        pos_neg_ratios[word] = -np.log((<span class="number">1</span> / (ratio+<span class="number">0.01</span>)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># words most frequently seen in a review with a "POSITIVE" label</span></div><div class="line">pos_neg_ratios.most_common()</div></pre></td></tr></table></figure>
<pre><code>[(&apos;edie&apos;, 4.6913478822291435),
 (&apos;paulie&apos;, 4.0775374439057197),
 (&apos;felix&apos;, 3.1527360223636558),
 (&apos;polanski&apos;, 2.8233610476132043),
 (&apos;matthau&apos;, 2.8067217286092401),
 (&apos;victoria&apos;, 2.6810215287142909),
 (&apos;mildred&apos;, 2.6026896854443837),
 (&apos;gandhi&apos;, 2.5389738710582761),
 (&apos;flawless&apos;, 2.451005098112319),
 (&apos;superbly&apos;, 2.2600254785752498),
 (&apos;perfection&apos;, 2.1594842493533721),
 (&apos;astaire&apos;, 2.1400661634962708),
 (&apos;captures&apos;, 2.0386195471595809),
 (&apos;voight&apos;, 2.0301704926730531),
 (&apos;wonderfully&apos;, 2.0218960560332353),
 (&apos;powell&apos;, 1.9783454248084671),
 (&apos;brosnan&apos;, 1.9547990964725592),
 (&apos;lily&apos;, 1.9203768470501485),
 (&apos;bakshi&apos;, 1.9029851043382795),
 (&apos;lincoln&apos;, 1.9014583864844796),
 (&apos;refreshing&apos;, 1.8551812956655511),
 (&apos;breathtaking&apos;, 1.8481124057791867),
 (&apos;bourne&apos;, 1.8478489358790986),
 (&apos;lemmon&apos;, 1.8458266904983307),
 (&apos;delightful&apos;, 1.8002701588959635),
 (&apos;flynn&apos;, 1.7996646487351682),
 (&apos;andrews&apos;, 1.7764919970972666),
 (&apos;homer&apos;, 1.7692866133759964),
 (&apos;beautifully&apos;, 1.7626953362841438),
 (&apos;soccer&apos;, 1.7578579175523736),
 (&apos;elvira&apos;, 1.7397031072720019),
 (&apos;underrated&apos;, 1.7197859696029656),
 (&apos;gripping&apos;, 1.7165360479904674),
 (&apos;superb&apos;, 1.7091514458966952),
 (&apos;delight&apos;, 1.6714733033535532),
 (&apos;welles&apos;, 1.6677068205580761),
 (&apos;sadness&apos;, 1.663505133704376),
 (&apos;sinatra&apos;, 1.6389967146756448),
 (&apos;touching&apos;, 1.637217476541176),
 (&apos;timeless&apos;, 1.62924053973028),
 (&apos;macy&apos;, 1.6211339521972916),
 (&apos;unforgettable&apos;, 1.6177367152487956),
 (&apos;favorites&apos;, 1.6158688027643908),
 (&apos;stewart&apos;, 1.6119987332957739),
 (&apos;sullivan&apos;, 1.6094379124341003),
 (&apos;extraordinary&apos;, 1.6094379124341003),
 (&apos;hartley&apos;, 1.6094379124341003),
 (&apos;brilliantly&apos;, 1.5950491749820008),
 (&apos;friendship&apos;, 1.5677652160335325),
 (&apos;wonderful&apos;, 1.5645425925262093),
 (&apos;palma&apos;, 1.5553706911638245),
 (&apos;magnificent&apos;, 1.54663701119507),
 (&apos;finest&apos;, 1.5462590108125689),
 (&apos;jackie&apos;, 1.5439233053234738),
 (&apos;ritter&apos;, 1.5404450409471491),
 (&apos;tremendous&apos;, 1.5184661342283736),
 (&apos;freedom&apos;, 1.5091151908062312),
 (&apos;fantastic&apos;, 1.5048433868558566),
 (&apos;terrific&apos;, 1.5026699370083942),
 (&apos;noir&apos;, 1.493925025312256),
 (&apos;sidney&apos;, 1.493925025312256),
 (&apos;outstanding&apos;, 1.4910053152089213),
 (&apos;pleasantly&apos;, 1.4894785973551214),
 (&apos;mann&apos;, 1.4894785973551214),
 (&apos;nancy&apos;, 1.488077055429833),
 (&apos;marie&apos;, 1.4825711915553104),
 (&apos;marvelous&apos;, 1.4739999415389962),
 (&apos;excellent&apos;, 1.4647538505723599),
 (&apos;ruth&apos;, 1.4596256342054401),
 (&apos;stanwyck&apos;, 1.4412101187160054),
 (&apos;widmark&apos;, 1.4350845252893227),
 (&apos;splendid&apos;, 1.4271163556401458),
 (&apos;chan&apos;, 1.423108334242607),
 (&apos;exceptional&apos;, 1.4201959127955721),
 (&apos;tender&apos;, 1.410986973710262),
 (&apos;gentle&apos;, 1.4078005663408544),
 (&apos;poignant&apos;, 1.4022947024663317),
 (&apos;gem&apos;, 1.3932148039644643),
 (&apos;amazing&apos;, 1.3919815802404802),
 (&apos;chilling&apos;, 1.3862943611198906),
 (&apos;fisher&apos;, 1.3862943611198906),
 (&apos;davies&apos;, 1.3862943611198906),
 (&apos;captivating&apos;, 1.3862943611198906),
 (&apos;darker&apos;, 1.3652409519220583),
 (&apos;april&apos;, 1.3499267169490159),
 (&apos;kelly&apos;, 1.3461743673304654),
 (&apos;blake&apos;, 1.3418425985490567),
 (&apos;overlooked&apos;, 1.329135947279942),
 (&apos;ralph&apos;, 1.32818673031261),
 (&apos;bette&apos;, 1.3156767939059373),
 (&apos;hoffman&apos;, 1.3150668518315229),
 (&apos;cole&apos;, 1.3121863889661687),
 (&apos;shines&apos;, 1.3049487216659381),
 (&apos;powerful&apos;, 1.2999662776313934),
 (&apos;notch&apos;, 1.2950456896547455),
 (&apos;remarkable&apos;, 1.2883688239495823),
 (&apos;pitt&apos;, 1.286210902562908),
 (&apos;winters&apos;, 1.2833463918674481),
 (&apos;vivid&apos;, 1.2762934659055623),
 (&apos;gritty&apos;, 1.2757524867200667),
 (&apos;giallo&apos;, 1.2745029551317739),
 (&apos;portrait&apos;, 1.2704625455947689),
 (&apos;innocence&apos;, 1.2694300209805796),
 (&apos;psychiatrist&apos;, 1.2685113254635072),
 (&apos;favorite&apos;, 1.2668956297860055),
 (&apos;ensemble&apos;, 1.2656663733312759),
 (&apos;stunning&apos;, 1.2622417124499117),
 (&apos;burns&apos;, 1.259880436264232),
 (&apos;garbo&apos;, 1.258954938743289),
 (&apos;barbara&apos;, 1.2580400255962119),
 (&apos;philip&apos;, 1.2527629684953681),
 (&apos;panic&apos;, 1.2527629684953681),
 (&apos;holly&apos;, 1.2527629684953681),
 (&apos;carol&apos;, 1.2481440226390734),
 (&apos;perfect&apos;, 1.246742480713785),
 (&apos;appreciated&apos;, 1.2462482874741743),
 (&apos;favourite&apos;, 1.2411123512753928),
 (&apos;journey&apos;, 1.2367626271489269),
 (&apos;rural&apos;, 1.235471471385307),
 (&apos;bond&apos;, 1.2321436812926323),
 (&apos;builds&apos;, 1.2305398317106577),
 (&apos;brilliant&apos;, 1.2287554137664785),
 (&apos;brooklyn&apos;, 1.2286654169163074),
 (&apos;von&apos;, 1.225175011976539),
 (&apos;recommended&apos;, 1.2163953243244932),
 (&apos;unfolds&apos;, 1.2163953243244932),
 (&apos;daniel&apos;, 1.20215296760895),
 (&apos;perfectly&apos;, 1.1971931173405572),
 (&apos;crafted&apos;, 1.1962507582320256),
 (&apos;prince&apos;, 1.1939224684724346),
 (&apos;troubled&apos;, 1.192138346678933),
 (&apos;consequences&apos;, 1.1865810616140668),
 (&apos;haunting&apos;, 1.1814999484738773),
 (&apos;cinderella&apos;, 1.180052620608284),
 (&apos;alexander&apos;, 1.1759989522835299),
 (&apos;emotions&apos;, 1.1753049094563641),
 (&apos;boxing&apos;, 1.1735135968412274),
 (&apos;subtle&apos;, 1.1734135017508081),
 (&apos;curtis&apos;, 1.1649873576129823),
 (&apos;rare&apos;, 1.1566438362402944),
 (&apos;loved&apos;, 1.1563661500586044),
 (&apos;daughters&apos;, 1.1526795099383853),
 (&apos;courage&apos;, 1.1438688802562305),
 (&apos;dentist&apos;, 1.1426722784621401),
 (&apos;highly&apos;, 1.1420208631618658),
 (&apos;nominated&apos;, 1.1409146683587992),
 (&apos;tony&apos;, 1.1397491942285991),
 (&apos;draws&apos;, 1.1325138403437911),
 (&apos;everyday&apos;, 1.1306150197542835),
 (&apos;contrast&apos;, 1.1284652518177909),
 (&apos;cried&apos;, 1.1213405397456659),
 (&apos;fabulous&apos;, 1.1210851445201684),
 (&apos;ned&apos;, 1.120591195386885),
 (&apos;fay&apos;, 1.120591195386885),
 (&apos;emma&apos;, 1.1184149159642893),
 (&apos;sensitive&apos;, 1.113318436057805),
 (&apos;smooth&apos;, 1.1089750757036563),
 (&apos;dramas&apos;, 1.1080910326226534),
 (&apos;today&apos;, 1.1050431789984001),
 (&apos;helps&apos;, 1.1023091505494358),
 (&apos;inspiring&apos;, 1.0986122886681098),
 (&apos;jimmy&apos;, 1.0937696641923216),
 (&apos;awesome&apos;, 1.0931328229034842),
 (&apos;unique&apos;, 1.0881409888008142),
 (&apos;tragic&apos;, 1.0871835928444868),
 (&apos;intense&apos;, 1.0870514662670339),
 (&apos;stellar&apos;, 1.0857088838322018),
 (&apos;rival&apos;, 1.0822184788924332),
 (&apos;provides&apos;, 1.0797081340289569),
 (&apos;depression&apos;, 1.0782034170369026),
 (&apos;shy&apos;, 1.0775588794702773),
 (&apos;carrie&apos;, 1.076139432816051),
 (&apos;blend&apos;, 1.0753554265038423),
 (&apos;hank&apos;, 1.0736109864626924),
 (&apos;diana&apos;, 1.0726368022648489),
 (&apos;adorable&apos;, 1.0726368022648489),
 (&apos;unexpected&apos;, 1.0722255334949147),
 (&apos;achievement&apos;, 1.0668635903535293),
 (&apos;bettie&apos;, 1.0663514264498881),
 (&apos;happiness&apos;, 1.0632729222228008),
 (&apos;glorious&apos;, 1.0608719606852626),
 (&apos;davis&apos;, 1.0541605260972757),
 (&apos;terrifying&apos;, 1.0525211814678428),
 (&apos;beauty&apos;, 1.050410186850232),
 (&apos;ideal&apos;, 1.0479685558493548),
 (&apos;fears&apos;, 1.0467872208035236),
 (&apos;hong&apos;, 1.0438040521731147),
 (&apos;seasons&apos;, 1.0433496099930604),
 (&apos;fascinating&apos;, 1.0414538748281612),
 (&apos;carries&apos;, 1.0345904299031787),
 (&apos;satisfying&apos;, 1.0321225473992768),
 (&apos;definite&apos;, 1.0319209141694374),
 (&apos;touched&apos;, 1.0296194171811581),
 (&apos;greatest&apos;, 1.0248947127715422),
 (&apos;creates&apos;, 1.0241097613701886),
 (&apos;aunt&apos;, 1.023388867430522),
 (&apos;walter&apos;, 1.022328983918479),
 (&apos;spectacular&apos;, 1.0198314108149955),
 (&apos;portrayal&apos;, 1.0189810189761024),
 (&apos;ann&apos;, 1.0127808528183286),
 (&apos;enterprise&apos;, 1.0116009116784799),
 (&apos;musicals&apos;, 1.0096648026516135),
 (&apos;deeply&apos;, 1.0094845087721023),
 (&apos;incredible&apos;, 1.0061677561461084),
 (&apos;mature&apos;, 1.0060195018402847),
 (&apos;triumph&apos;, 0.99682959435816731),
 (&apos;margaret&apos;, 0.99682959435816731),
 (&apos;navy&apos;, 0.99493385919326827),
 (&apos;harry&apos;, 0.99176919305006062),
 (&apos;lucas&apos;, 0.990398704027877),
 (&apos;sweet&apos;, 0.98966110487955483),
 (&apos;joey&apos;, 0.98794672078059009),
 (&apos;oscar&apos;, 0.98721905111049713),
 (&apos;balance&apos;, 0.98649499054740353),
 (&apos;warm&apos;, 0.98485340331145166),
 (&apos;ages&apos;, 0.98449898190068863),
 (&apos;guilt&apos;, 0.98082925301172619),
 (&apos;glover&apos;, 0.98082925301172619),
 (&apos;carrey&apos;, 0.98082925301172619),
 (&apos;learns&apos;, 0.97881108885548895),
 (&apos;unusual&apos;, 0.97788374278196932),
 (&apos;sons&apos;, 0.97777581552483595),
 (&apos;complex&apos;, 0.97761897738147796),
 (&apos;essence&apos;, 0.97753435711487369),
 (&apos;brazil&apos;, 0.9769153536905899),
 (&apos;widow&apos;, 0.97650959186720987),
 (&apos;solid&apos;, 0.97537964824416146),
 (&apos;beautiful&apos;, 0.97326301262841053),
 (&apos;holmes&apos;, 0.97246100334120955),
 (&apos;awe&apos;, 0.97186058302896583),
 (&apos;vhs&apos;, 0.97116734209998934),
 (&apos;eerie&apos;, 0.97116734209998934),
 (&apos;lonely&apos;, 0.96873720724669754),
 (&apos;grim&apos;, 0.96873720724669754),
 (&apos;sport&apos;, 0.96825047080486615),
 (&apos;debut&apos;, 0.96508089604358704),
 (&apos;destiny&apos;, 0.96343751029985703),
 (&apos;thrillers&apos;, 0.96281074750904794),
 (&apos;tears&apos;, 0.95977584381389391),
 (&apos;rose&apos;, 0.95664202739772253),
 (&apos;feelings&apos;, 0.95551144502743635),
 (&apos;ginger&apos;, 0.95551144502743635),
 (&apos;winning&apos;, 0.95471810900804055),
 (&apos;stanley&apos;, 0.95387344302319799),
 (&apos;cox&apos;, 0.95343027882361187),
 (&apos;paris&apos;, 0.95278479030472663),
 (&apos;heart&apos;, 0.95238806924516806),
 (&apos;hooked&apos;, 0.95155887071161305),
 (&apos;comfortable&apos;, 0.94803943018873538),
 (&apos;mgm&apos;, 0.94446160884085151),
 (&apos;masterpiece&apos;, 0.94155039863339296),
 (&apos;themes&apos;, 0.94118828349588235),
 (&apos;danny&apos;, 0.93967118051821874),
 (&apos;anime&apos;, 0.93378388932167222),
 (&apos;perry&apos;, 0.93328830824272613),
 (&apos;joy&apos;, 0.93301752567946861),
 (&apos;lovable&apos;, 0.93081883243706487),
 (&apos;mysteries&apos;, 0.92953595862417571),
 (&apos;hal&apos;, 0.92953595862417571),
 (&apos;louis&apos;, 0.92871325187271225),
 (&apos;charming&apos;, 0.92520609553210742),
 (&apos;urban&apos;, 0.92367083917177761),
 (&apos;allows&apos;, 0.92183091224977043),
 (&apos;impact&apos;, 0.91815814604895041),
 (&apos;italy&apos;, 0.91629073187415511),
 (&apos;gradually&apos;, 0.91629073187415511),
 (&apos;lifestyle&apos;, 0.91629073187415511),
 (&apos;spy&apos;, 0.91289514287301687),
 (&apos;treat&apos;, 0.91193342650519937),
 (&apos;subsequent&apos;, 0.91056005716517008),
 (&apos;kennedy&apos;, 0.90981821736853763),
 (&apos;loving&apos;, 0.90967549275543591),
 (&apos;surprising&apos;, 0.90937028902958128),
 (&apos;quiet&apos;, 0.90648673177753425),
 (&apos;winter&apos;, 0.90624039602065365),
 (&apos;reveals&apos;, 0.90490540964902977),
 (&apos;raw&apos;, 0.90445627422715225),
 (&apos;funniest&apos;, 0.90078654533818991),
 (&apos;pleased&apos;, 0.89994159387262562),
 (&apos;norman&apos;, 0.89994159387262562),
 (&apos;thief&apos;, 0.89874642222324552),
 (&apos;season&apos;, 0.89827222637147675),
 (&apos;secrets&apos;, 0.89794159320595857),
 (&apos;colorful&apos;, 0.89705936994626756),
 (&apos;highest&apos;, 0.8967461358011849),
 (&apos;compelling&apos;, 0.89462923509297576),
 (&apos;danes&apos;, 0.89248008318043659),
 (&apos;castle&apos;, 0.88967708335606499),
 (&apos;kudos&apos;, 0.88889175768604067),
 (&apos;great&apos;, 0.88810470901464589),
 (&apos;baseball&apos;, 0.88730319500090271),
 (&apos;subtitles&apos;, 0.88730319500090271),
 (&apos;bleak&apos;, 0.88730319500090271),
 (&apos;winner&apos;, 0.88643776872447388),
 (&apos;tragedy&apos;, 0.88563699078315261),
 (&apos;todd&apos;, 0.88551907320740142),
 (&apos;nicely&apos;, 0.87924946019380601),
 (&apos;arthur&apos;, 0.87546873735389985),
 (&apos;essential&apos;, 0.87373111745535925),
 (&apos;gorgeous&apos;, 0.8731725250935497),
 (&apos;fonda&apos;, 0.87294029100054127),
 (&apos;eastwood&apos;, 0.87139541196626402),
 (&apos;focuses&apos;, 0.87082835779739776),
 (&apos;enjoyed&apos;, 0.87070195951624607),
 (&apos;natural&apos;, 0.86997924506912838),
 (&apos;intensity&apos;, 0.86835126958503595),
 (&apos;witty&apos;, 0.86824103423244681),
 (&apos;rob&apos;, 0.8642954367557748),
 (&apos;worlds&apos;, 0.86377269759070874),
 (&apos;health&apos;, 0.86113891179907498),
 (&apos;magical&apos;, 0.85953791528170564),
 (&apos;deeper&apos;, 0.85802182375017932),
 (&apos;lucy&apos;, 0.85618680780444956),
 (&apos;moving&apos;, 0.85566611005772031),
 (&apos;lovely&apos;, 0.85290640004681306),
 (&apos;purple&apos;, 0.8513711857748395),
 (&apos;memorable&apos;, 0.84801189112086062),
 (&apos;sings&apos;, 0.84729786038720367),
 (&apos;craig&apos;, 0.84342938360928321),
 (&apos;modesty&apos;, 0.84342938360928321),
 (&apos;relate&apos;, 0.84326559685926517),
 (&apos;episodes&apos;, 0.84223712084137292),
 (&apos;strong&apos;, 0.84167135777060931),
 (&apos;smith&apos;, 0.83959811108590054),
 (&apos;tear&apos;, 0.83704136022001441),
 (&apos;apartment&apos;, 0.83333115290549531),
 (&apos;princess&apos;, 0.83290912293510388),
 (&apos;disagree&apos;, 0.83290912293510388),
 (&apos;kung&apos;, 0.83173334384609199),
 (&apos;adventure&apos;, 0.83150561393278388),
 (&apos;columbo&apos;, 0.82667857318446791),
 (&apos;jake&apos;, 0.82667857318446791),
 (&apos;adds&apos;, 0.82485652591452319),
 (&apos;hart&apos;, 0.82472353834866463),
 (&apos;strength&apos;, 0.82417544296634937),
 (&apos;realizes&apos;, 0.82360006895738058),
 (&apos;dave&apos;, 0.8232003088081431),
 (&apos;childhood&apos;, 0.82208086393583857),
 (&apos;forbidden&apos;, 0.81989888619908913),
 (&apos;tight&apos;, 0.81883539572344199),
 (&apos;surreal&apos;, 0.8178506590609026),
 (&apos;manager&apos;, 0.81770990320170756),
 (&apos;dancer&apos;, 0.81574950265227764),
 (&apos;studios&apos;, 0.81093021621632877),
 (&apos;con&apos;, 0.81093021621632877),
 (&apos;miike&apos;, 0.80821651034473263),
 (&apos;realistic&apos;, 0.80807714723392232),
 (&apos;explicit&apos;, 0.80792269515237358),
 (&apos;kurt&apos;, 0.8060875917405409),
 (&apos;traditional&apos;, 0.80535917116687328),
 (&apos;deals&apos;, 0.80535917116687328),
 (&apos;holds&apos;, 0.80493858654806194),
 (&apos;carl&apos;, 0.80437281567016972),
 (&apos;touches&apos;, 0.80396154690023547),
 (&apos;gene&apos;, 0.80314807577427383),
 (&apos;albert&apos;, 0.8027669055771679),
 (&apos;abc&apos;, 0.80234647252493729),
 (&apos;cry&apos;, 0.80011930011211307),
 (&apos;sides&apos;, 0.7995275841185171),
 (&apos;develops&apos;, 0.79850769621777162),
 (&apos;eyre&apos;, 0.79850769621777162),
 (&apos;dances&apos;, 0.79694397424158891),
 (&apos;oscars&apos;, 0.79633141679517616),
 (&apos;legendary&apos;, 0.79600456599965308),
 (&apos;hearted&apos;, 0.79492987486988764),
 (&apos;importance&apos;, 0.79492987486988764),
 (&apos;portraying&apos;, 0.79356592830699269),
 (&apos;impressed&apos;, 0.79258107754813223),
 (&apos;waters&apos;, 0.79112758892014912),
 (&apos;empire&apos;, 0.79078565012386137),
 (&apos;edge&apos;, 0.789774016249017),
 (&apos;jean&apos;, 0.78845736036427028),
 (&apos;environment&apos;, 0.78845736036427028),
 (&apos;sentimental&apos;, 0.7864791203521645),
 (&apos;captured&apos;, 0.78623760362595729),
 (&apos;styles&apos;, 0.78592891401091158),
 (&apos;daring&apos;, 0.78592891401091158),
 (&apos;frank&apos;, 0.78275933924963248),
 (&apos;tense&apos;, 0.78275933924963248),
 (&apos;backgrounds&apos;, 0.78275933924963248),
 (&apos;matches&apos;, 0.78275933924963248),
 (&apos;gothic&apos;, 0.78209466657644144),
 (&apos;sharp&apos;, 0.7814397877056235),
 (&apos;achieved&apos;, 0.78015855754957497),
 (&apos;court&apos;, 0.77947526404844247),
 (&apos;steals&apos;, 0.7789140023173704),
 (&apos;rules&apos;, 0.77844476107184035),
 (&apos;colors&apos;, 0.77684619943659217),
 (&apos;reunion&apos;, 0.77318988823348167),
 (&apos;covers&apos;, 0.77139937745969345),
 (&apos;tale&apos;, 0.77010822169607374),
 (&apos;rain&apos;, 0.7683706017975328),
 (&apos;denzel&apos;, 0.76804848873306297),
 (&apos;stays&apos;, 0.76787072675588186),
 (&apos;blob&apos;, 0.76725515271366718),
 (&apos;maria&apos;, 0.76214005204689672),
 (&apos;conventional&apos;, 0.76214005204689672),
 (&apos;fresh&apos;, 0.76158434211317383),
 (&apos;midnight&apos;, 0.76096977689870637),
 (&apos;landscape&apos;, 0.75852993982279704),
 (&apos;animated&apos;, 0.75768570169751648),
 (&apos;titanic&apos;, 0.75666058628227129),
 (&apos;sunday&apos;, 0.75666058628227129),
 (&apos;spring&apos;, 0.7537718023763802),
 (&apos;cagney&apos;, 0.7537718023763802),
 (&apos;enjoyable&apos;, 0.75246375771636476),
 (&apos;immensely&apos;, 0.75198768058287868),
 (&apos;sir&apos;, 0.7507762933965817),
 (&apos;nevertheless&apos;, 0.75067102469813185),
 (&apos;driven&apos;, 0.74994477895307854),
 (&apos;performances&apos;, 0.74883252516063137),
 (&apos;memories&apos;, 0.74721440183022114),
 (&apos;nowadays&apos;, 0.74721440183022114),
 (&apos;simple&apos;, 0.74641420974143258),
 (&apos;golden&apos;, 0.74533293373051557),
 (&apos;leslie&apos;, 0.74533293373051557),
 (&apos;lovers&apos;, 0.74497224842453125),
 (&apos;relationship&apos;, 0.74484232345601786),
 (&apos;supporting&apos;, 0.74357803418683721),
 (&apos;che&apos;, 0.74262723782331497),
 (&apos;packed&apos;, 0.7410032017375805),
 (&apos;trek&apos;, 0.74021469141793106),
 (&apos;provoking&apos;, 0.73840377214806618),
 (&apos;strikes&apos;, 0.73759894313077912),
 (&apos;depiction&apos;, 0.73682224406260699),
 (&apos;emotional&apos;, 0.73678211645681524),
 (&apos;secretary&apos;, 0.7366322924996842),
 (&apos;influenced&apos;, 0.73511137965897755),
 (&apos;florida&apos;, 0.73511137965897755),
 (&apos;germany&apos;, 0.73288750920945944),
 (&apos;brings&apos;, 0.73142936713096229),
 (&apos;lewis&apos;, 0.73129894652432159),
 (&apos;elderly&apos;, 0.73088750854279239),
 (&apos;owner&apos;, 0.72743625403857748),
 (&apos;streets&apos;, 0.72666987259858895),
 (&apos;henry&apos;, 0.72642196944481741),
 (&apos;portrays&apos;, 0.72593700338293632),
 (&apos;bears&apos;, 0.7252354951114458),
 (&apos;china&apos;, 0.72489587887452556),
 (&apos;anger&apos;, 0.72439972406404984),
 (&apos;society&apos;, 0.72433010799663333),
 (&apos;available&apos;, 0.72415741730250549),
 (&apos;best&apos;, 0.72347034060446314),
 (&apos;bugs&apos;, 0.72270598280148979),
 (&apos;magic&apos;, 0.71878961117328299),
 (&apos;delivers&apos;, 0.71846498854423513),
 (&apos;verhoeven&apos;, 0.71846498854423513),
 (&apos;jim&apos;, 0.71783979315031676),
 (&apos;donald&apos;, 0.71667767797013937),
 (&apos;endearing&apos;, 0.71465338578090898),
 (&apos;relationships&apos;, 0.71393795022901896),
 (&apos;greatly&apos;, 0.71256526641704687),
 (&apos;charlie&apos;, 0.71024161391924534),
 (&apos;brad&apos;, 0.71024161391924534),
 (&apos;simon&apos;, 0.70967648251115578),
 (&apos;effectively&apos;, 0.70914752190638641),
 (&apos;march&apos;, 0.70774597998109789),
 (&apos;atmosphere&apos;, 0.70744773070214162),
 (&apos;influence&apos;, 0.70733181555190172),
 (&apos;genius&apos;, 0.706392407309966),
 (&apos;emotionally&apos;, 0.70556970055850243),
 (&apos;ken&apos;, 0.70526854109229009),
 (&apos;identity&apos;, 0.70484322032313651),
 (&apos;sophisticated&apos;, 0.70470800296102132),
 (&apos;dan&apos;, 0.70457587638356811),
 (&apos;andrew&apos;, 0.70329955202396321),
 (&apos;india&apos;, 0.70144598337464037),
 (&apos;roy&apos;, 0.69970458110610434),
 (&apos;surprisingly&apos;, 0.6995780708902356),
 (&apos;sky&apos;, 0.69780919366575667),
 (&apos;romantic&apos;, 0.69664981111114743),
 (&apos;match&apos;, 0.69566924999265523),
 (&apos;meets&apos;, 0.69314718055994529),
 (&apos;cowboy&apos;, 0.69314718055994529),
 (&apos;wave&apos;, 0.69314718055994529),
 (&apos;bitter&apos;, 0.69314718055994529),
 (&apos;patient&apos;, 0.69314718055994529),
 (&apos;stylish&apos;, 0.69314718055994529),
 (&apos;britain&apos;, 0.69314718055994529),
 (&apos;affected&apos;, 0.69314718055994529),
 (&apos;beatty&apos;, 0.69314718055994529),
 (&apos;love&apos;, 0.69198533541937324),
 (&apos;paul&apos;, 0.68980827929443067),
 (&apos;andy&apos;, 0.68846333124751902),
 (&apos;performance&apos;, 0.68797386327972465),
 (&apos;patrick&apos;, 0.68645819240914863),
 (&apos;unlike&apos;, 0.68546468438792907),
 (&apos;brooks&apos;, 0.68433655087779044),
 (&apos;refuses&apos;, 0.68348526964820844),
 (&apos;award&apos;, 0.6824518914431974),
 (&apos;complaint&apos;, 0.6824518914431974),
 (&apos;ride&apos;, 0.68229716453587952),
 (&apos;dawson&apos;, 0.68171848473632257),
 (&apos;luke&apos;, 0.68158635815886937),
 (&apos;wells&apos;, 0.68087708796813096),
 (&apos;france&apos;, 0.6804081547825156),
 (&apos;sports&apos;, 0.68007509899259255),
 (&apos;handsome&apos;, 0.68007509899259255),
 (&apos;directs&apos;, 0.67875844310784572),
 (&apos;rebel&apos;, 0.67875844310784572),
 (&apos;greater&apos;, 0.67605274720064523),
 (&apos;dreams&apos;, 0.67599410133369586),
 (&apos;effective&apos;, 0.67565402311242806),
 (&apos;interpretation&apos;, 0.67479804189174875),
 (&apos;works&apos;, 0.67445504754779284),
 (&apos;brando&apos;, 0.67445504754779284),
 (&apos;noble&apos;, 0.6737290947028437),
 (&apos;paced&apos;, 0.67314651385327573),
 (&apos;le&apos;, 0.67067432470788668),
 (&apos;master&apos;, 0.67015766233524654),
 (&apos;h&apos;, 0.6696166831497512),
 (&apos;rings&apos;, 0.66904962898088483),
 (&apos;easy&apos;, 0.66895995494594152),
 (&apos;city&apos;, 0.66820823221269321),
 (&apos;sunshine&apos;, 0.66782937257565544),
 (&apos;succeeds&apos;, 0.66647893347778397),
 (&apos;relations&apos;, 0.664159643686693),
 (&apos;england&apos;, 0.66387679825983203),
 (&apos;glimpse&apos;, 0.66329421741026418),
 (&apos;aired&apos;, 0.66268797307523675),
 (&apos;sees&apos;, 0.66263163663399482),
 (&apos;both&apos;, 0.66248336767382998),
 (&apos;definitely&apos;, 0.66199789483898808),
 (&apos;imaginative&apos;, 0.66139848224536502),
 (&apos;appreciate&apos;, 0.66083893732728749),
 (&apos;tricks&apos;, 0.66071190480679143),
 (&apos;striking&apos;, 0.66071190480679143),
 (&apos;carefully&apos;, 0.65999497324304479),
 (&apos;complicated&apos;, 0.65981076029235353),
 (&apos;perspective&apos;, 0.65962448852130173),
 (&apos;trilogy&apos;, 0.65877953705573755),
 (&apos;future&apos;, 0.65834665141052828),
 (&apos;lion&apos;, 0.65742909795786608),
 (&apos;douglas&apos;, 0.65540685257709819),
 (&apos;victor&apos;, 0.65540685257709819),
 (&apos;inspired&apos;, 0.65459851044271034),
 (&apos;marriage&apos;, 0.65392646740666405),
 (&apos;demands&apos;, 0.65392646740666405),
 (&apos;father&apos;, 0.65172321672194655),
 (&apos;page&apos;, 0.65123628494430852),
 (&apos;instant&apos;, 0.65058756614114943),
 (&apos;era&apos;, 0.6495567444850836),
 (&apos;ruthless&apos;, 0.64934455790155243),
 (&apos;saga&apos;, 0.64934455790155243),
 (&apos;joan&apos;, 0.64891392558311978),
 (&apos;joseph&apos;, 0.64841128671855386),
 (&apos;workers&apos;, 0.64829661439459352),
 (&apos;fantasy&apos;, 0.64726757480925168),
 (&apos;distant&apos;, 0.64551913157069074),
 (&apos;accomplished&apos;, 0.64551913157069074),
 (&apos;manhattan&apos;, 0.64435701639051324),
 (&apos;personal&apos;, 0.64355023942057321),
 (&apos;meeting&apos;, 0.64313675998528386),
 (&apos;individual&apos;, 0.64313675998528386),
 (&apos;pushing&apos;, 0.64313675998528386),
 (&apos;pleasant&apos;, 0.64250344774119039),
 (&apos;brave&apos;, 0.64185388617239469),
 (&apos;william&apos;, 0.64083139119578469),
 (&apos;hudson&apos;, 0.64077919504262937),
 (&apos;friendly&apos;, 0.63949446706762514),
 (&apos;eccentric&apos;, 0.63907995928966954),
 (&apos;awards&apos;, 0.63875310849414646),
 (&apos;jack&apos;, 0.63838309514997038),
 (&apos;seeking&apos;, 0.63808740337691783),
 (&apos;divorce&apos;, 0.63757732940513456),
 (&apos;colonel&apos;, 0.63757732940513456),
 (&apos;jane&apos;, 0.63443957973316734),
 (&apos;keeping&apos;, 0.63414883979798953),
 (&apos;gives&apos;, 0.63383568159497883),
 (&apos;ted&apos;, 0.63342794585832296),
 (&apos;animation&apos;, 0.63208692379869902),
 (&apos;progress&apos;, 0.6317782341836532),
 (&apos;larger&apos;, 0.63127177684185776),
 (&apos;concert&apos;, 0.63127177684185776),
 (&apos;nation&apos;, 0.6296337748376194),
 (&apos;albeit&apos;, 0.62739580299716491),
 (&apos;adapted&apos;, 0.62613647027698516),
 (&apos;discovers&apos;, 0.62542900650499444),
 (&apos;classic&apos;, 0.62504956428050518),
 (&apos;segment&apos;, 0.62335141862440335),
 (&apos;morgan&apos;, 0.62303761437291871),
 (&apos;mouse&apos;, 0.62294292188669675),
 (&apos;impressive&apos;, 0.62211140744319349),
 (&apos;artist&apos;, 0.62168821657780038),
 (&apos;ultimate&apos;, 0.62168821657780038),
 (&apos;griffith&apos;, 0.62117368093485603),
 (&apos;drew&apos;, 0.62082651898031915),
 (&apos;emily&apos;, 0.62082651898031915),
 (&apos;moved&apos;, 0.6197197120051281),
 (&apos;families&apos;, 0.61903920840622351),
 (&apos;profound&apos;, 0.61903920840622351),
 (&apos;innocent&apos;, 0.61851219917136446),
 (&apos;versions&apos;, 0.61730910416844087),
 (&apos;eddie&apos;, 0.61691981517206107),
 (&apos;criticism&apos;, 0.61651395453902935),
 (&apos;nature&apos;, 0.61594514653194088),
 (&apos;recognized&apos;, 0.61518563909023349),
 (&apos;sexuality&apos;, 0.61467556511845012),
 (&apos;contract&apos;, 0.61400986000122149),
 (&apos;brian&apos;, 0.61344043794920278),
 (&apos;remembered&apos;, 0.6131044728864089),
 (&apos;determined&apos;, 0.6123858239154869),
 (&apos;offers&apos;, 0.61207935747116349),
 (&apos;pleasure&apos;, 0.61195702582993206),
 (&apos;washington&apos;, 0.61180154110599294),
 (&apos;images&apos;, 0.61159731359583758),
 (&apos;games&apos;, 0.61067095873570676),
 (&apos;academy&apos;, 0.60872983874736208),
 (&apos;fashioned&apos;, 0.60798937221963845),
 (&apos;melodrama&apos;, 0.60749173598145145),
 (&apos;rough&apos;, 0.60613580357031549),
 (&apos;charismatic&apos;, 0.60613580357031549),
 (&apos;peoples&apos;, 0.60613580357031549),
 (&apos;dealing&apos;, 0.60517840761398811),
 (&apos;fine&apos;, 0.60496962268013299),
 (&apos;tap&apos;, 0.60391604683200273),
 (&apos;trio&apos;, 0.60157998703445481),
 (&apos;russell&apos;, 0.60120968523425966),
 (&apos;figures&apos;, 0.60077386042893011),
 (&apos;ward&apos;, 0.60005675749393339),
 (&apos;shine&apos;, 0.59911823091166894),
 (&apos;brady&apos;, 0.59911823091166894),
 (&apos;job&apos;, 0.59845562125168661),
 (&apos;satisfied&apos;, 0.59652034487087369),
 (&apos;river&apos;, 0.59637962862495086),
 (&apos;brown&apos;, 0.595773016534769),
 (&apos;believable&apos;, 0.59566072133302495),
 (&apos;always&apos;, 0.59470710774669278),
 (&apos;bound&apos;, 0.59470710774669278),
 (&apos;hall&apos;, 0.5933967777928858),
 (&apos;cook&apos;, 0.5916777203950857),
 (&apos;claire&apos;, 0.59136448625000293),
 (&apos;broadway&apos;, 0.59033768669372433),
 (&apos;anna&apos;, 0.58778666490211906),
 (&apos;peace&apos;, 0.58628403501758408),
 (&apos;visually&apos;, 0.58539431926349916),
 (&apos;morality&apos;, 0.58525821854876026),
 (&apos;falk&apos;, 0.58525821854876026),
 (&apos;growing&apos;, 0.58466653756587539),
 (&apos;experiences&apos;, 0.58314628534561685),
 (&apos;stood&apos;, 0.58314628534561685),
 (&apos;touch&apos;, 0.58122926435596001),
 (&apos;lives&apos;, 0.5810976767513224),
 (&apos;kubrick&apos;, 0.58066919713325493),
 (&apos;timing&apos;, 0.58047401805583243),
 (&apos;expressions&apos;, 0.57981849525294216),
 (&apos;struggles&apos;, 0.57981849525294216),
 (&apos;authentic&apos;, 0.57848427223980559),
 (&apos;helen&apos;, 0.57763429343810091),
 (&apos;pre&apos;, 0.57700753064729182),
 (&apos;quirky&apos;, 0.5753641449035618),
 (&apos;young&apos;, 0.57531672344534313),
 (&apos;inner&apos;, 0.57454143815209846),
 (&apos;mexico&apos;, 0.57443087372056334),
 (&apos;clint&apos;, 0.57380042292737909),
 (&apos;sisters&apos;, 0.57286101468544337),
 (&apos;realism&apos;, 0.57226528899949558),
 (&apos;french&apos;, 0.5720692490067093),
 (&apos;personalities&apos;, 0.5720692490067093),
 (&apos;surprises&apos;, 0.57113222999698177),
 (&apos;adventures&apos;, 0.57113222999698177),
 (&apos;overcome&apos;, 0.5697681593994407),
 (&apos;timothy&apos;, 0.56953322459276867),
 (&apos;tales&apos;, 0.56909453188996639),
 (&apos;war&apos;, 0.56843317302781682),
 (&apos;civil&apos;, 0.5679840376059393),
 (&apos;countries&apos;, 0.56737779327091187),
 (&apos;streep&apos;, 0.56710645966458029),
 (&apos;tradition&apos;, 0.56685345523565323),
 (&apos;oliver&apos;, 0.56673325570428668),
 (&apos;australia&apos;, 0.56580775818334383),
 (&apos;understanding&apos;, 0.56531380905006046),
 (&apos;players&apos;, 0.56509525370004821),
 (&apos;knowing&apos;, 0.56489284503626647),
 (&apos;rogers&apos;, 0.56421349718405212),
 (&apos;suspenseful&apos;, 0.56368911332305849),
 (&apos;variety&apos;, 0.56368911332305849),
 (&apos;true&apos;, 0.56281525180810066),
 (&apos;jr&apos;, 0.56220982311246936),
 (&apos;psychological&apos;, 0.56108745854687891),
 (&apos;sent&apos;, 0.55961578793542266),
 (&apos;grand&apos;, 0.55961578793542266),
 (&apos;branagh&apos;, 0.55961578793542266),
 (&apos;reminiscent&apos;, 0.55961578793542266),
 (&apos;performing&apos;, 0.55961578793542266),
 (&apos;wealth&apos;, 0.55961578793542266),
 (&apos;overwhelming&apos;, 0.55961578793542266),
 (&apos;odds&apos;, 0.55961578793542266),
 (&apos;brothers&apos;, 0.55891181043362848),
 (&apos;howard&apos;, 0.55811089675600245),
 (&apos;david&apos;, 0.55693122256475369),
 (&apos;generation&apos;, 0.55628799784274796),
 (&apos;grow&apos;, 0.55612538299565417),
 (&apos;survival&apos;, 0.55594605904646033),
 (&apos;mainstream&apos;, 0.55574731115750231),
 (&apos;dick&apos;, 0.55431073570572953),
 (&apos;charm&apos;, 0.55288175575407861),
 (&apos;kirk&apos;, 0.55278982286502287),
 (&apos;twists&apos;, 0.55244729845681018),
 (&apos;gangster&apos;, 0.55206858230003986),
 (&apos;jeff&apos;, 0.55179306225421365),
 (&apos;family&apos;, 0.55116244510065526),
 (&apos;tend&apos;, 0.55053307336110335),
 (&apos;thanks&apos;, 0.55049088015842218),
 (&apos;world&apos;, 0.54744234723432639),
 (&apos;sutherland&apos;, 0.54743536937855164),
 (&apos;life&apos;, 0.54695514434959924),
 (&apos;disc&apos;, 0.54654370636806993),
 (&apos;bug&apos;, 0.54654370636806993),
 (&apos;tribute&apos;, 0.5455111817538808),
 (&apos;europe&apos;, 0.54522705048332309),
 (&apos;sacrifice&apos;, 0.54430155296238014),
 (&apos;color&apos;, 0.54405127139431109),
 (&apos;superior&apos;, 0.54333490233128523),
 (&apos;york&apos;, 0.54318235866536513),
 (&apos;pulls&apos;, 0.54266622962164945),
 (&apos;jackson&apos;, 0.54232429082536171),
 (&apos;hearts&apos;, 0.54232429082536171),
 (&apos;enjoy&apos;, 0.54124285135906114),
 (&apos;redemption&apos;, 0.54056759296472823),
 (&apos;madness&apos;, 0.540384426007535),
 (&apos;stands&apos;, 0.5389965007326869),
 (&apos;trial&apos;, 0.5389965007326869),
 (&apos;greek&apos;, 0.5389965007326869),
 (&apos;hamilton&apos;, 0.5389965007326869),
 (&apos;each&apos;, 0.5388212312554177),
 (&apos;faithful&apos;, 0.53773307668591508),
 (&apos;received&apos;, 0.5372768098531604),
 (&apos;documentaries&apos;, 0.53714293208336406),
 (&apos;jealous&apos;, 0.53714293208336406),
 (&apos;different&apos;, 0.53709860682460819),
 (&apos;describes&apos;, 0.53680111016925136),
 (&apos;shorts&apos;, 0.53596159703753288),
 (&apos;brilliance&apos;, 0.53551823635636209),
 (&apos;mountains&apos;, 0.53492317534505118),
 (&apos;share&apos;, 0.53408248593025787),
 (&apos;dealt&apos;, 0.53408248593025787),
 (&apos;providing&apos;, 0.53329847961804933),
 (&apos;explore&apos;, 0.53329847961804933),
 (&apos;series&apos;, 0.5325809226575603),
 (&apos;fellow&apos;, 0.5323318289869543),
 (&apos;loves&apos;, 0.53062825106217038),
 (&apos;revolution&apos;, 0.53062825106217038),
 (&apos;olivier&apos;, 0.53062825106217038),
 (&apos;roman&apos;, 0.53062825106217038),
 (&apos;century&apos;, 0.53002783074992665),
 (&apos;musical&apos;, 0.52966871156747064),
 (&apos;heroic&apos;, 0.52925932545482868),
 (&apos;approach&apos;, 0.52806743020049673),
 (&apos;ironically&apos;, 0.52806743020049673),
 (&apos;temple&apos;, 0.52806743020049673),
 (&apos;moves&apos;, 0.5279372642387119),
 (&apos;gift&apos;, 0.52702030968597136),
 (&apos;julie&apos;, 0.52609309589677911),
 (&apos;tells&apos;, 0.52415107836314001),
 (&apos;radio&apos;, 0.52394671172868779),
 (&apos;uncle&apos;, 0.52354439617376536),
 (&apos;union&apos;, 0.52324814376454787),
 (&apos;deep&apos;, 0.52309571635780505),
 (&apos;reminds&apos;, 0.52157841554225237),
 (&apos;famous&apos;, 0.52118841080153722),
 (&apos;jazz&apos;, 0.52053443789295151),
 (&apos;dennis&apos;, 0.51987545928590861),
 (&apos;epic&apos;, 0.51919387343650736),
 (&apos;adult&apos;, 0.519167695083386),
 (&apos;shows&apos;, 0.51915322220375304),
 (&apos;performed&apos;, 0.5191244265806858),
 (&apos;demons&apos;, 0.5191244265806858),
 (&apos;discovered&apos;, 0.51879379341516751),
 (&apos;eric&apos;, 0.51879379341516751),
 (&apos;youth&apos;, 0.5185626062681431),
 (&apos;human&apos;, 0.51851411224987087),
 (&apos;tarzan&apos;, 0.51813827061227724),
 (&apos;ourselves&apos;, 0.51794309153485463),
 (&apos;wwii&apos;, 0.51758240622887042),
 (&apos;passion&apos;, 0.5162164724008671),
 (&apos;desire&apos;, 0.51607497965213445),
 (&apos;pays&apos;, 0.51581316527702981),
 (&apos;dirty&apos;, 0.51557622652458857),
 (&apos;fox&apos;, 0.51557622652458857),
 (&apos;sympathetic&apos;, 0.51546600332249293),
 (&apos;symbolism&apos;, 0.51546600332249293),
 (&apos;attitude&apos;, 0.51530993621331933),
 (&apos;appearances&apos;, 0.51466440007315639),
 (&apos;jeremy&apos;, 0.51466440007315639),
 (&apos;fun&apos;, 0.51439068993048687),
 (&apos;south&apos;, 0.51420972175023116),
 (&apos;arrives&apos;, 0.51409894911095988),
 (&apos;present&apos;, 0.51341965894303732),
 (&apos;com&apos;, 0.51326167856387173),
 (&apos;smile&apos;, 0.51265880484765169),
 (&apos;alan&apos;, 0.51082562376599072),
 (&apos;ring&apos;, 0.51082562376599072),
 (&apos;visit&apos;, 0.51082562376599072),
 (&apos;fits&apos;, 0.51082562376599072),
 (&apos;provided&apos;, 0.51082562376599072),
 (&apos;carter&apos;, 0.51082562376599072),
 (&apos;aging&apos;, 0.51082562376599072),
 (&apos;countryside&apos;, 0.51082562376599072),
 (&apos;begins&apos;, 0.51015650363396647),
 (&apos;success&apos;, 0.50900578704900468),
 (&apos;japan&apos;, 0.50900578704900468),
 (&apos;accurate&apos;, 0.50895471583017893),
 (&apos;proud&apos;, 0.50800474742434931),
 (&apos;daily&apos;, 0.5075946031845443),
 (&apos;karloff&apos;, 0.50724780241810674),
 (&apos;atmospheric&apos;, 0.50724780241810674),
 (&apos;recently&apos;, 0.50714914903668207),
 (&apos;fu&apos;, 0.50704490092608467),
 (&apos;horrors&apos;, 0.50656122497953315),
 (&apos;finding&apos;, 0.50637127341661037),
 (&apos;lust&apos;, 0.5059356384717989),
 (&apos;hitchcock&apos;, 0.50574947073413001),
 (&apos;among&apos;, 0.50334004951332734),
 (&apos;viewing&apos;, 0.50302139827440906),
 (&apos;investigation&apos;, 0.50262885656181222),
 (&apos;shining&apos;, 0.50262885656181222),
 (&apos;duo&apos;, 0.5020919437972361),
 (&apos;cameron&apos;, 0.5020919437972361),
 (&apos;finds&apos;, 0.50128303100539795),
 (&apos;contemporary&apos;, 0.50077528791248915),
 (&apos;genuine&apos;, 0.50046283673044401),
 (&apos;frightening&apos;, 0.49995595152908684),
 (&apos;plays&apos;, 0.49975983848890226),
 (&apos;age&apos;, 0.49941323171424595),
 (&apos;position&apos;, 0.49899116611898781),
 (&apos;continues&apos;, 0.49863035067217237),
 (&apos;roles&apos;, 0.49839716550752178),
 (&apos;james&apos;, 0.49837216269470402),
 (&apos;individuals&apos;, 0.49824684155913052),
 (&apos;brought&apos;, 0.49783842823917956),
 (&apos;hilarious&apos;, 0.49714551986191058),
 (&apos;brutal&apos;, 0.49681488669639234),
 (&apos;appropriate&apos;, 0.49643688631389105),
 (&apos;dance&apos;, 0.49581998314812048),
 (&apos;league&apos;, 0.49578774640145024),
 (&apos;helping&apos;, 0.49578774640145024),
 (&apos;answers&apos;, 0.49578774640145024),
 (&apos;stunts&apos;, 0.49561620510246196),
 (&apos;traveling&apos;, 0.49532143723002542),
 (&apos;thoroughly&apos;, 0.49414593456733524),
 (&apos;depicted&apos;, 0.49317068852726992),
 (&apos;combination&apos;, 0.49247648509779424),
 (&apos;honor&apos;, 0.49247648509779424),
 (&apos;differences&apos;, 0.49247648509779424),
 (&apos;fully&apos;, 0.49213349075383811),
 (&apos;tracy&apos;, 0.49159426183810306),
 (&apos;battles&apos;, 0.49140753790888908),
 (&apos;possibility&apos;, 0.49112055268665822),
 (&apos;romance&apos;, 0.4901589869574316),
 (&apos;initially&apos;, 0.49002249613622745),
 (&apos;happy&apos;, 0.4898997500608791),
 (&apos;crime&apos;, 0.48977221456815834),
 (&apos;singing&apos;, 0.4893852925281213),
 (&apos;especially&apos;, 0.48901267837860624),
 (&apos;shakespeare&apos;, 0.48754793889664511),
 (&apos;hugh&apos;, 0.48729512635579658),
 (&apos;detail&apos;, 0.48609484250827351),
 (&apos;julia&apos;, 0.48550781578170082),
 (&apos;san&apos;, 0.48550781578170082),
 (&apos;guide&apos;, 0.48550781578170082),
 (&apos;desperation&apos;, 0.48550781578170082),
 (&apos;companion&apos;, 0.48550781578170082),
 (&apos;strongly&apos;, 0.48460242866688824),
 (&apos;necessary&apos;, 0.48302334245403883),
 (&apos;humanity&apos;, 0.48265474679929443),
 (&apos;drama&apos;, 0.48221998493060503),
 (&apos;nonetheless&apos;, 0.48183808689273838),
 (&apos;intrigue&apos;, 0.48183808689273838),
 (&apos;warming&apos;, 0.48183808689273838),
 (&apos;cuba&apos;, 0.48183808689273838),
 (&apos;planned&apos;, 0.47957308026188628),
 (&apos;pictures&apos;, 0.47929937011921681),
 (&apos;broadcast&apos;, 0.47849024312305422),
 (&apos;nine&apos;, 0.47803580094299974),
 (&apos;settings&apos;, 0.47743860773325364),
 (&apos;history&apos;, 0.47732966933780852),
 (&apos;ordinary&apos;, 0.47725880012690741),
 (&apos;trade&apos;, 0.47692407209030935),
 (&apos;official&apos;, 0.47608267532211779),
 (&apos;primary&apos;, 0.47608267532211779),
 (&apos;episode&apos;, 0.47529620261150429),
 (&apos;role&apos;, 0.47520268270188676),
 (&apos;spirit&apos;, 0.47477690799839323),
 (&apos;grey&apos;, 0.47409361449726067),
 (&apos;ways&apos;, 0.47323464982718205),
 (&apos;cup&apos;, 0.47260441094579297),
 (&apos;piano&apos;, 0.47260441094579297),
 (&apos;familiar&apos;, 0.47241617565111949),
 (&apos;sinister&apos;, 0.47198579044972683),
 (&apos;reveal&apos;, 0.47171449364936496),
 (&apos;max&apos;, 0.47150852042515579),
 (&apos;dated&apos;, 0.47121648567094482),
 (&apos;losing&apos;, 0.47000362924573563),
 (&apos;discovery&apos;, 0.47000362924573563),
 (&apos;vicious&apos;, 0.47000362924573563),
 (&apos;genuinely&apos;, 0.46871413841586385),
 (&apos;hatred&apos;, 0.46734051182625186),
 (&apos;mistaken&apos;, 0.46702300110759781),
 (&apos;dream&apos;, 0.46608972992459924),
 (&apos;challenge&apos;, 0.46608972992459924),
 (&apos;crisis&apos;, 0.46575733836428446),
 (&apos;photographed&apos;, 0.46488852857896512),
 (&apos;critics&apos;, 0.46430560813109778),
 (&apos;bird&apos;, 0.46430560813109778),
 (&apos;machines&apos;, 0.46430560813109778),
 (&apos;born&apos;, 0.46411383518967209),
 (&apos;detective&apos;, 0.4636633473511525),
 (&apos;higher&apos;, 0.46328467899699055),
 (&apos;remains&apos;, 0.46262352194811296),
 (&apos;inevitable&apos;, 0.46262352194811296),
 (&apos;soviet&apos;, 0.4618180446592961),
 (&apos;ryan&apos;, 0.46134556650262099),
 (&apos;african&apos;, 0.46112595521371813),
 (&apos;smaller&apos;, 0.46081520319132935),
 (&apos;techniques&apos;, 0.46052488529119184),
 (&apos;information&apos;, 0.46034171833399862),
 (&apos;deserved&apos;, 0.45999798712841444),
 (&apos;lynch&apos;, 0.45953232937844013),
 (&apos;spielberg&apos;, 0.45953232937844013),
 (&apos;cynical&apos;, 0.45953232937844013),
 (&apos;tour&apos;, 0.45953232937844013),
 (&apos;francisco&apos;, 0.45953232937844013),
 (&apos;struggle&apos;, 0.45911782160048453),
 (&apos;language&apos;, 0.45902121257712653),
 (&apos;visual&apos;, 0.45823514408822852),
 (&apos;warner&apos;, 0.45724137763188427),
 (&apos;social&apos;, 0.45720078250735313),
 (&apos;reality&apos;, 0.45719346885019546),
 (&apos;hidden&apos;, 0.45675840249571492),
 (&apos;breaking&apos;, 0.45601738727099561),
 (&apos;sometimes&apos;, 0.45563021171182794),
 (&apos;modern&apos;, 0.45500247579345005),
 (&apos;surfing&apos;, 0.45425527227759638),
 (&apos;popular&apos;, 0.45410691533051023),
 (&apos;surprised&apos;, 0.4534409399850382),
 (&apos;follows&apos;, 0.45245361754408348),
 (&apos;keeps&apos;, 0.45234869400701483),
 (&apos;john&apos;, 0.4520909494482197),
 (&apos;mixed&apos;, 0.45198512374305722),
 (&apos;defeat&apos;, 0.45198512374305722),
 (&apos;justice&apos;, 0.45142724367280018),
 (&apos;treasure&apos;, 0.45083371313801535),
 (&apos;presents&apos;, 0.44973793178615257),
 (&apos;years&apos;, 0.44919197032104968),
 (&apos;chief&apos;, 0.44895022004790319),
 (&apos;shadows&apos;, 0.44802472252696035),
 (&apos;closely&apos;, 0.44701411102103689),
 (&apos;segments&apos;, 0.44701411102103689),
 (&apos;lose&apos;, 0.44658335503763702),
 (&apos;caine&apos;, 0.44628710262841953),
 (&apos;caught&apos;, 0.44610275383999071),
 (&apos;hamlet&apos;, 0.44558510189758965),
 (&apos;chinese&apos;, 0.44507424620321018),
 (&apos;welcome&apos;, 0.44438052435783792),
 (&apos;birth&apos;, 0.44368632092836219),
 (&apos;represents&apos;, 0.44320543609101143),
 (&apos;puts&apos;, 0.44279106572085081),
 (&apos;visuals&apos;, 0.44183275227903923),
 (&apos;fame&apos;, 0.44183275227903923),
 (&apos;closer&apos;, 0.44183275227903923),
 (&apos;web&apos;, 0.44183275227903923),
 (&apos;criminal&apos;, 0.4412745608048752),
 (&apos;minor&apos;, 0.4409224199448939),
 (&apos;jon&apos;, 0.44086703515908027),
 (&apos;liked&apos;, 0.44074991514020723),
 (&apos;restaurant&apos;, 0.44031183943833246),
 (&apos;de&apos;, 0.43983275161237217),
 (&apos;flaws&apos;, 0.43983275161237217),
 (&apos;searching&apos;, 0.4393666597838457),
 (&apos;rap&apos;, 0.43891304217570443),
 (&apos;light&apos;, 0.43884433018199892),
 (&apos;elizabeth&apos;, 0.43872232986464677),
 (&apos;marry&apos;, 0.43861731542506488),
 (&apos;learned&apos;, 0.43825493093115531),
 (&apos;controversial&apos;, 0.43825493093115531),
 (&apos;oz&apos;, 0.43825493093115531),
 (&apos;slowly&apos;, 0.43785660389939979),
 (&apos;comedic&apos;, 0.43721380642274466),
 (&apos;wayne&apos;, 0.43721380642274466),
 (&apos;thrilling&apos;, 0.43721380642274466),
 (&apos;bridge&apos;, 0.43721380642274466),
 (&apos;married&apos;, 0.43658501682196887),
 (&apos;nazi&apos;, 0.4361020775700542),
 (&apos;murder&apos;, 0.4353180712578455),
 (&apos;physical&apos;, 0.4353180712578455),
 (&apos;johnny&apos;, 0.43483971678806865),
 (&apos;michelle&apos;, 0.43445264498141672),
 (&apos;wallace&apos;, 0.43403848055222038),
 (&apos;comedies&apos;, 0.43395706390247063),
 (&apos;silent&apos;, 0.43395706390247063),
 (&apos;played&apos;, 0.43387244114515305),
 (&apos;international&apos;, 0.43363598507486073),
 (&apos;vision&apos;, 0.43286408229627887),
 (&apos;intelligent&apos;, 0.43196704885367099),
 (&apos;shop&apos;, 0.43078291609245434),
 (&apos;also&apos;, 0.43036720209769169),
 (&apos;levels&apos;, 0.4302451371066513),
 (&apos;miss&apos;, 0.43006426712153217),
 (&apos;movement&apos;, 0.4295626596872249),
 ...]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># words most frequently seen in a review with a "NEGATIVE" label</span></div><div class="line">list(reversed(pos_neg_ratios.most_common()))[<span class="number">0</span>:<span class="number">30</span>]</div></pre></td></tr></table></figure>
<pre><code>[(&apos;boll&apos;, -4.0778152602708904),
 (&apos;uwe&apos;, -3.9218753018711578),
 (&apos;seagal&apos;, -3.3202501058581921),
 (&apos;unwatchable&apos;, -3.0269848170580955),
 (&apos;stinker&apos;, -2.9876839403711624),
 (&apos;mst&apos;, -2.7753833211707968),
 (&apos;incoherent&apos;, -2.7641396677532537),
 (&apos;unfunny&apos;, -2.5545257844967644),
 (&apos;waste&apos;, -2.4907515123361046),
 (&apos;blah&apos;, -2.4475792789485005),
 (&apos;horrid&apos;, -2.3715779644809971),
 (&apos;pointless&apos;, -2.3451073877136341),
 (&apos;atrocious&apos;, -2.3187369339642556),
 (&apos;redeeming&apos;, -2.2667790015910296),
 (&apos;prom&apos;, -2.2601040980178784),
 (&apos;drivel&apos;, -2.2476029585766928),
 (&apos;lousy&apos;, -2.2118080125207054),
 (&apos;worst&apos;, -2.1930856334332267),
 (&apos;laughable&apos;, -2.172468615469592),
 (&apos;awful&apos;, -2.1385076866397488),
 (&apos;poorly&apos;, -2.1326133844207011),
 (&apos;wasting&apos;, -2.1178155545614512),
 (&apos;remotely&apos;, -2.111046881095167),
 (&apos;existent&apos;, -2.0024805005437076),
 (&apos;boredom&apos;, -1.9241486572738005),
 (&apos;miserably&apos;, -1.9216610938019989),
 (&apos;sucks&apos;, -1.9166645809588516),
 (&apos;uninspired&apos;, -1.9131499212248517),
 (&apos;lame&apos;, -1.9117232884159072),
 (&apos;insult&apos;, -1.9085323769376259)]
</code></pre><h1 id="Transforming-Text-into-Numbers"><a href="#Transforming-Text-into-Numbers" class="headerlink" title="Transforming Text into Numbers"></a>Transforming Text into Numbers</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</div><div class="line"></div><div class="line">review = <span class="string">"This was a horrible, terrible movie."</span></div><div class="line"></div><div class="line">Image(filename=<span class="string">'sentiment_network.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_18_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">review = <span class="string">"The movie was excellent"</span></div><div class="line"></div><div class="line">Image(filename=<span class="string">'sentiment_network_pos.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_19_0.png" alt="png"></p>
<h1 id="Project-2-Creating-the-Input-Output-Data"><a href="#Project-2-Creating-the-Input-Output-Data" class="headerlink" title="Project 2: Creating the Input/Output Data"></a>Project 2: Creating the Input/Output Data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">vocab = set(total_counts.keys())</div><div class="line">vocab_size = len(vocab)</div><div class="line">print(vocab_size)</div></pre></td></tr></table></figure>
<pre><code>74074
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">list(vocab)</div></pre></td></tr></table></figure>
<pre><code>[&apos;&apos;,
 &apos;werewoves&apos;,
 &apos;endowments&apos;,
 &apos;palace&apos;,
 &apos;persiflage&apos;,
 &apos;slasherville&apos;,
 &apos;locally&apos;,
 &apos;unrecycled&apos;,
 &apos;spearhead&apos;,
 &apos;allyson&apos;,
 &apos;manhating&apos;,
 &apos;bartok&apos;,
 &apos;gretorexes&apos;,
 &apos;soaks&apos;,
 &apos;protestations&apos;,
 &apos;superimposes&apos;,
 &apos;theirry&apos;,
 &apos;yaqui&apos;,
 &apos;contrives&apos;,
 &apos;accessorizing&apos;,
 &apos;arg&apos;,
 &apos;sanguine&apos;,
 &apos;batouch&apos;,
 &apos;asked&apos;,
 &apos;animals&apos;,
 &apos;cockpits&apos;,
 &apos;gorilla&apos;,
 &apos;diculous&apos;,
 &apos;establishing&apos;,
 &apos;kagemusha&apos;,
 &apos;sketches&apos;,
 &apos;rebuilt&apos;,
 &apos;perniciously&apos;,
 &apos;socioeconomic&apos;,
 &apos;ladylike&apos;,
 &apos;prognostication&apos;,
 &apos;blech&apos;,
 &apos;sugarbabe&apos;,
 &apos;desk&apos;,
 &apos;fez&apos;,
 &apos;accents&apos;,
 &apos;speach&apos;,
 &apos;rooster&apos;,
 &apos;effort&apos;,
 &apos;bodega&apos;,
 &apos;dong&apos;,
 &apos;preordained&apos;,
 &apos;dubliners&apos;,
 &apos;vili&apos;,
 &apos;imperatives&apos;,
 &apos;artifices&apos;,
 &apos;wieder&apos;,
 &apos;climate&apos;,
 &apos;whoopdedoodles&apos;,
 &apos;quatermass&apos;,
 &apos;inveterate&apos;,
 &apos;memorandum&apos;,
 &apos;crucially&apos;,
 &apos;bulimics&apos;,
 &apos;misdrawing&apos;,
 &apos;plympton&apos;,
 &apos;fireballs&apos;,
 &apos;verdant&apos;,
 &apos;testi&apos;,
 &apos;undeservingly&apos;,
 &apos;lusted&apos;,
 &apos;shylock&apos;,
 &apos;disinfecting&apos;,
 &apos;boxer&apos;,
 &apos;givney&apos;,
 &apos;hs&apos;,
 &apos;loser&apos;,
 &apos;civics&apos;,
 &apos;volcano&apos;,
 &apos;jur&apos;,
 &apos;mohnish&apos;,
 &apos;candidates&apos;,
 &apos;assemble&apos;,
 &apos;simi&apos;,
 &apos;resort&apos;,
 &apos;hessling&apos;,
 &apos;starbase&apos;,
 &apos;orgolini&apos;,
 &apos;starrett&apos;,
 &apos;weaker&apos;,
 &apos;transcending&apos;,
 &apos;levitate&apos;,
 &apos;spurns&apos;,
 &apos;contradictory&apos;,
 &apos;cambreau&apos;,
 &apos;latvia&apos;,
 &apos;kirkpatrick&apos;,
 &apos;betty&apos;,
 &apos;agnostic&apos;,
 &apos;sosa&apos;,
 &apos;kanji&apos;,
 &apos;swill&apos;,
 &apos;millinium&apos;,
 &apos;macgregor&apos;,
 &apos;brd&apos;,
 &apos;ariete&apos;,
 &apos;assassins&apos;,
 &apos;disscusion&apos;,
 &apos;legislative&apos;,
 &apos;dwars&apos;,
 &apos;controller&apos;,
 &apos;hadass&apos;,
 &apos;vega&apos;,
 &apos;bends&apos;,
 &apos;glock&apos;,
 &apos;spacewalk&apos;,
 &apos;va&apos;,
 &apos;offa&apos;,
 &apos;winfield&apos;,
 &apos;somewhat&apos;,
 &apos;yates&apos;,
 &apos;vinyl&apos;,
 &apos;complicity&apos;,
 &apos;bela&apos;,
 &apos;squishes&apos;,
 &apos;rippings&apos;,
 &apos;eyed&apos;,
 &apos;amatuerish&apos;,
 &apos;desilva&apos;,
 &apos;christmass&apos;,
 &apos;briley&apos;,
 &apos;bakhtyari&apos;,
 &apos;unmasked&apos;,
 &apos;huffman&apos;,
 &apos;fallacious&apos;,
 &apos;problem&apos;,
 &apos;sieger&apos;,
 &apos;koma&apos;,
 &apos;grovelling&apos;,
 &apos;incl&apos;,
 &apos;farlinger&apos;,
 &apos;teasers&apos;,
 &apos;huff&apos;,
 &apos;untried&apos;,
 &apos;crocker&apos;,
 &apos;dansu&apos;,
 &apos;scammers&apos;,
 &apos;popsicle&apos;,
 &apos;arthritic&apos;,
 &apos;grubs&apos;,
 &apos;exemplar&apos;,
 &apos;racial&apos;,
 &apos;verbiage&apos;,
 &apos;saloshin&apos;,
 &apos;painlessly&apos;,
 &apos;harewood&apos;,
 &apos;shart&apos;,
 &apos;keepers&apos;,
 &apos;archrivals&apos;,
 &apos;longish&apos;,
 &apos;batmobile&apos;,
 &apos;shakespearian&apos;,
 &apos;bestselling&apos;,
 &apos;spewing&apos;,
 &apos;midlands&apos;,
 &apos;trattoria&apos;,
 &apos;greenaway&apos;,
 &apos;gestapo&apos;,
 &apos;ed&apos;,
 &apos;huns&apos;,
 &apos;bloch&apos;,
 &apos;mashall&apos;,
 &apos;versy&apos;,
 &apos;david&apos;,
 &apos;sicilian&apos;,
 &apos;propositioned&apos;,
 &apos;eighty&apos;,
 &apos;carridine&apos;,
 &apos;delicates&apos;,
 &apos;veering&apos;,
 &apos;columbus&apos;,
 &apos;dunning&apos;,
 &apos;mercantile&apos;,
 &apos;rape&apos;,
 &apos;purely&apos;,
 &apos;rediscovered&apos;,
 &apos;abstinence&apos;,
 &apos;clunes&apos;,
 &apos;emerson&apos;,
 &apos;judgments&apos;,
 &apos;lawful&apos;,
 &apos;celebration&apos;,
 &apos;affirmative&apos;,
 &apos;sedately&apos;,
 &apos;sng&apos;,
 &apos;inuindo&apos;,
 &apos;mosely&apos;,
 &apos;bungalow&apos;,
 &apos;ninga&apos;,
 &apos;dripped&apos;,
 &apos;itallian&apos;,
 &apos;himalaya&apos;,
 &apos;shikoku&apos;,
 &apos;braik&apos;,
 &apos;grousing&apos;,
 &apos;nair&apos;,
 &apos;forrester&apos;,
 &apos;elemental&apos;,
 &apos;allegations&apos;,
 &apos;delilah&apos;,
 &apos;boneheaded&apos;,
 &apos;baltimoreans&apos;,
 &apos;dunebuggies&apos;,
 &apos;taguchi&apos;,
 &apos;coleseum&apos;,
 &apos;saratoga&apos;,
 &apos;ninotchka&apos;,
 &apos;afganistan&apos;,
 &apos;genorisity&apos;,
 &apos;haff&apos;,
 &apos;jennilee&apos;,
 &apos;jesues&apos;,
 &apos;dwarfs&apos;,
 &apos;enchilada&apos;,
 &apos;feminist&apos;,
 &apos;ghettoisation&apos;,
 &apos;handlebar&apos;,
 &apos;antagonistic&apos;,
 &apos;marian&apos;,
 &apos;crichton&apos;,
 &apos;ryo&apos;,
 &apos;mean&apos;,
 &apos;inheritance&apos;,
 &apos;presently&apos;,
 &apos;pear&apos;,
 &apos;inequality&apos;,
 &apos;stately&apos;,
 &apos;nooo&apos;,
 &apos;obscurities&apos;,
 &apos;determinedly&apos;,
 &apos;solemn&apos;,
 &apos;sullenly&apos;,
 &apos;machism&apos;,
 &apos;tingled&apos;,
 &apos;maschera&apos;,
 &apos;tristran&apos;,
 &apos;mendoza&apos;,
 &apos;baked&apos;,
 &apos;jonatha&apos;,
 &apos;lowly&apos;,
 &apos;halliwell&apos;,
 &apos;msted&apos;,
 &apos;rodann&apos;,
 &apos;hunkered&apos;,
 &apos;cashmere&apos;,
 &apos;chevalia&apos;,
 &apos;jakub&apos;,
 &apos;dobermann&apos;,
 &apos;overexxagerating&apos;,
 &apos;pfennig&apos;,
 &apos;fisted&apos;,
 &apos;mcelwee&apos;,
 &apos;chief&apos;,
 &apos;parlor&apos;,
 &apos;browbeating&apos;,
 &apos;parasol&apos;,
 &apos;negligible&apos;,
 &apos;kira&apos;,
 &apos;monceau&apos;,
 &apos;blew&apos;,
 &apos;odete&apos;,
 &apos;muco&apos;,
 &apos;predominantly&apos;,
 &apos;levon&apos;,
 &apos;discourage&apos;,
 &apos;fragmented&apos;,
 &apos;vandermey&apos;,
 &apos;etude&apos;,
 &apos;mitch&apos;,
 &apos;sandbag&apos;,
 &apos;bending&apos;,
 &apos;dizzying&apos;,
 &apos;mover&apos;,
 &apos;rewired&apos;,
 &apos;awww&apos;,
 &apos;di&apos;,
 &apos;bejesus&apos;,
 &apos;wallet&apos;,
 &apos;uprooting&apos;,
 &apos;atari&apos;,
 &apos;dreamlike&apos;,
 &apos;exacted&apos;,
 &apos;harbouring&apos;,
 &apos;indiscreet&apos;,
 &apos;turks&apos;,
 &apos;gems&apos;,
 &apos;hoboken&apos;,
 &apos;yalom&apos;,
 &apos;rooftop&apos;,
 &apos;howit&apos;,
 &apos;tolson&apos;,
 &apos;tulane&apos;,
 &apos;reductive&apos;,
 &apos;catharthic&apos;,
 &apos;famarialy&apos;,
 &apos;sista&apos;,
 &apos;ghidorah&apos;,
 &apos;ngoombujarra&apos;,
 &apos;intently&apos;,
 &apos;jlu&apos;,
 &apos;kyrptonite&apos;,
 &apos;hilda&apos;,
 &apos;census&apos;,
 &apos;baguette&apos;,
 &apos;mondrians&apos;,
 &apos;advisable&apos;,
 &apos;mcnee&apos;,
 &apos;candlelit&apos;,
 &apos;affability&apos;,
 &apos;intercut&apos;,
 &apos;installations&apos;,
 &apos;elliptical&apos;,
 &apos;washer&apos;,
 &apos;colt&apos;,
 &apos;pevensie&apos;,
 &apos;outshined&apos;,
 &apos;despotic&apos;,
 &apos;suares&apos;,
 &apos;privates&apos;,
 &apos;scrabble&apos;,
 &apos;milliardo&apos;,
 &apos;booting&apos;,
 &apos;rowan&apos;,
 &apos;golmaal&apos;,
 &apos;pueblos&apos;,
 &apos;msf&apos;,
 &apos;giulietta&apos;,
 &apos;phili&apos;,
 &apos;pleaseee&apos;,
 &apos;connecticute&apos;,
 &apos;rosnelski&apos;,
 &apos;tenebra&apos;,
 &apos;bako&apos;,
 &apos;blessings&apos;,
 &apos;smudge&apos;,
 &apos;cya&apos;,
 &apos;pummel&apos;,
 &apos;brocks&apos;,
 &apos;homere&apos;,
 &apos;propellant&apos;,
 &apos;deliveried&apos;,
 &apos;finisham&apos;,
 &apos;newsradio&apos;,
 &apos;bernie&apos;,
 &apos;gouden&apos;,
 &apos;enchant&apos;,
 &apos;bessie&apos;,
 &apos;semisubmerged&apos;,
 &apos;extraterrestrial&apos;,
 &apos;believably&apos;,
 &apos;accomplice&apos;,
 &apos;dooku&apos;,
 &apos;baja&apos;,
 &apos;met&apos;,
 &apos;circulate&apos;,
 &apos;disobeyed&apos;,
 &apos;quakerly&apos;,
 &apos;overstyling&apos;,
 &apos;softens&apos;,
 &apos;units&apos;,
 &apos;shaye&apos;,
 &apos;starters&apos;,
 &apos;gripes&apos;,
 &apos;nightmarish&apos;,
 &apos;patriotic&apos;,
 &apos;goodtimes&apos;,
 &apos;stroheim&apos;,
 &apos;debit&apos;,
 &apos;prissies&apos;,
 &apos;woebegone&apos;,
 &apos;deputies&apos;,
 &apos;awkwardness&apos;,
 &apos;obama&apos;,
 &apos;tarazu&apos;,
 &apos;kendra&apos;,
 &apos;patriots&apos;,
 &apos;helpfuls&apos;,
 &apos;mightily&apos;,
 &apos;polemical&apos;,
 &apos;unruly&apos;,
 &apos;planing&apos;,
 &apos;paperhouse&apos;,
 &apos;sororities&apos;,
 &apos;pym&apos;,
 &apos;therin&apos;,
 &apos;tarkovsky&apos;,
 &apos;rdiger&apos;,
 &apos;resembling&apos;,
 &apos;gimmicks&apos;,
 &apos;iler&apos;,
 &apos;lineal&apos;,
 &apos;taming&apos;,
 &apos;mortenson&apos;,
 &apos;waugh&apos;,
 &apos;furies&apos;,
 &apos;grufford&apos;,
 &apos;hammill&apos;,
 &apos;plunkett&apos;,
 &apos;paterson&apos;,
 &apos;konishita&apos;,
 &apos;immorality&apos;,
 &apos;angelos&apos;,
 &apos;kebbel&apos;,
 &apos;tamiroff&apos;,
 &apos;boen&apos;,
 &apos;rivalry&apos;,
 &apos;ethnic&apos;,
 &apos;funner&apos;,
 &apos;troops&apos;,
 &apos;deadeningly&apos;,
 &apos;watcha&apos;,
 &apos;dhiraj&apos;,
 &apos;haranguing&apos;,
 &apos;dejas&apos;,
 &apos;weasely&apos;,
 &apos;category&apos;,
 &apos;laughable&apos;,
 &apos;gramps&apos;,
 &apos;safdar&apos;,
 &apos;calorie&apos;,
 &apos;scandi&apos;,
 &apos;cannon&apos;,
 &apos;maliciously&apos;,
 &apos;bothered&apos;,
 &apos;troi&apos;,
 &apos;couleur&apos;,
 &apos;visionary&apos;,
 &apos;fizzles&apos;,
 &apos;evangalizing&apos;,
 &apos;reeves&apos;,
 &apos;bombadier&apos;,
 &apos;bowlegged&apos;,
 &apos;custody&apos;,
 &apos;weta&apos;,
 &apos;archambault&apos;,
 &apos;warlords&apos;,
 &apos;makeout&apos;,
 &apos;bonbons&apos;,
 &apos;importances&apos;,
 &apos;baruchel&apos;,
 &apos;floyd&apos;,
 &apos;infirm&apos;,
 &apos;bloodwaters&apos;,
 &apos;ashford&apos;,
 &apos;colleagues&apos;,
 &apos;discern&apos;,
 &apos;thunderjet&apos;,
 &apos;pullers&apos;,
 &apos;evos&apos;,
 &apos;celebrations&apos;,
 &apos;seely&apos;,
 &apos;nasty&apos;,
 &apos;keach&apos;,
 &apos;tonge&apos;,
 &apos;senki&apos;,
 &apos;approxiamtely&apos;,
 &apos;unable&apos;,
 &apos;rayburn&apos;,
 &apos;britons&apos;,
 &apos;christoph&apos;,
 &apos;proctor&apos;,
 &apos;tapped&apos;,
 &apos;lenz&apos;,
 &apos;vengeant&apos;,
 &apos;exaggerating&apos;,
 &apos;mle&apos;,
 &apos;declaims&apos;,
 &apos;hight&apos;,
 &apos;repetoir&apos;,
 &apos;yolu&apos;,
 &apos;smarty&apos;,
 &apos;steels&apos;,
 &apos;openness&apos;,
 &apos;coached&apos;,
 &apos;archiving&apos;,
 &apos;horrendous&apos;,
 &apos;engages&apos;,
 &apos;loosing&apos;,
 &apos;anchorpoint&apos;,
 &apos;fecal&apos;,
 &apos;gracefully&apos;,
 &apos;tapioca&apos;,
 &apos;bizniss&apos;,
 &apos;overhyped&apos;,
 &apos;shortland&apos;,
 &apos;cleansed&apos;,
 &apos;negativity&apos;,
 &apos;gushy&apos;,
 &apos;mortitz&apos;,
 &apos;stripper&apos;,
 &apos;woke&apos;,
 &apos;slayers&apos;,
 &apos;uncensored&apos;,
 &apos;textiles&apos;,
 &apos;louda&apos;,
 &apos;castrati&apos;,
 &apos;altmanesque&apos;,
 &apos;yes&apos;,
 &apos;huntress&apos;,
 &apos;urging&apos;,
 &apos;tua&apos;,
 &apos;sentient&apos;,
 &apos;kellogg&apos;,
 &apos;cheerful&apos;,
 &apos;swanks&apos;,
 &apos;shor&apos;,
 &apos;cheapo&apos;,
 &apos;flourishing&apos;,
 &apos;tap&apos;,
 &apos;kph&apos;,
 &apos;bobbidi&apos;,
 &apos;tangos&apos;,
 &apos;honey&apos;,
 &apos;oswald&apos;,
 &apos;philippians&apos;,
 &apos;payroll&apos;,
 &apos;chooses&apos;,
 &apos;archtypes&apos;,
 &apos;generators&apos;,
 &apos;grillo&apos;,
 &apos;horrorible&apos;,
 &apos;yellowing&apos;,
 &apos;vancouver&apos;,
 &apos;thet&apos;,
 &apos;babtise&apos;,
 &apos;participates&apos;,
 &apos;uriah&apos;,
 &apos;loust&apos;,
 &apos;ravishingly&apos;,
 &apos;punishing&apos;,
 &apos;jhoom&apos;,
 &apos;lulling&apos;,
 &apos;stetting&apos;,
 &apos;wierd&apos;,
 &apos;truce&apos;,
 &apos;peerce&apos;,
 &apos;transpose&apos;,
 &apos;unplanned&apos;,
 &apos;unmistakeably&apos;,
 &apos;approval&apos;,
 &apos;amontillado&apos;,
 &apos;een&apos;,
 &apos;lefties&apos;,
 &apos;tentatives&apos;,
 &apos;mysteriousness&apos;,
 &apos;mid&apos;,
 &apos;technicians&apos;,
 &apos;wich&apos;,
 &apos;englund&apos;,
 &apos;freespirited&apos;,
 &apos;kun&apos;,
 &apos;discourses&apos;,
 &apos;nyily&apos;,
 &apos;honorably&apos;,
 &apos;hankerchief&apos;,
 &apos;nugget&apos;,
 &apos;nationalism&apos;,
 &apos;reveals&apos;,
 &apos;lamppost&apos;,
 &apos;tempra&apos;,
 &apos;sanctimoniousness&apos;,
 &apos;wardrobes&apos;,
 &apos;visa&apos;,
 &apos;lenses&apos;,
 &apos;johars&apos;,
 &apos;prefers&apos;,
 &apos;webster&apos;,
 &apos;marcuzzo&apos;,
 &apos;licensable&apos;,
 &apos;brilliancy&apos;,
 &apos;gumbas&apos;,
 &apos;jacoby&apos;,
 &apos;twine&apos;,
 &apos;entices&apos;,
 &apos;unpremeditated&apos;,
 &apos;jin&apos;,
 &apos;affirmatively&apos;,
 &apos;joyful&apos;,
 &apos;plotkurt&apos;,
 &apos;danniele&apos;,
 &apos;rpond&apos;,
 &apos;flare&apos;,
 &apos;lester&apos;,
 &apos;toying&apos;,
 &apos;having&apos;,
 &apos;anorexia&apos;,
 &apos;hoof&apos;,
 &apos;stillman&apos;,
 &apos;hows&apos;,
 &apos;contrite&apos;,
 &apos;hersholt&apos;,
 &apos;utterance&apos;,
 &apos;superflous&apos;,
 &apos;orders&apos;,
 &apos;pamelyn&apos;,
 &apos;traumatized&apos;,
 &apos;poder&apos;,
 &apos;virtuality&apos;,
 &apos;reaper&apos;,
 &apos;trini&apos;,
 &apos;phantasm&apos;,
 &apos;fbp&apos;,
 &apos;nuked&apos;,
 &apos;siegfried&apos;,
 &apos;ralph&apos;,
 &apos;erwin&apos;,
 &apos;rhymer&apos;,
 &apos;christien&apos;,
 &apos;sidekick&apos;,
 &apos;grasshopper&apos;,
 &apos;steryotypes&apos;,
 &apos;donnagio&apos;,
 &apos;denny&apos;,
 &apos;fraudulent&apos;,
 &apos;weisse&apos;,
 &apos;yoji&apos;,
 &apos;adapters&apos;,
 &apos;andalthough&apos;,
 &apos;fee&apos;,
 &apos;attorney&apos;,
 &apos;holliday&apos;,
 &apos;prerequisite&apos;,
 &apos;ives&apos;,
 &apos;yvaine&apos;,
 &apos;smaller&apos;,
 &apos;satired&apos;,
 &apos;ghillie&apos;,
 &apos;hagelin&apos;,
 &apos;upsurge&apos;,
 &apos;empirical&apos;,
 &apos;smap&apos;,
 &apos;kirk&apos;,
 &apos;conservatism&apos;,
 &apos;wesley&apos;,
 &apos;becuz&apos;,
 &apos;fantasia&apos;,
 &apos;treadstone&apos;,
 &apos;berdalh&apos;,
 &apos;reaganomics&apos;,
 &apos;schwarzenberg&apos;,
 &apos;housemann&apos;,
 &apos;jumpstart&apos;,
 &apos;glamorise&apos;,
 &apos;braves&apos;,
 &apos;simply&apos;,
 &apos;which&apos;,
 &apos;knifes&apos;,
 &apos;ramblings&apos;,
 &apos;bused&apos;,
 &apos;lombardo&apos;,
 &apos;refresher&apos;,
 &apos;evenings&apos;,
 &apos;openings&apos;,
 &apos;rings&apos;,
 &apos;reverend&apos;,
 &apos;blurry&apos;,
 &apos;baldy&apos;,
 &apos;acing&apos;,
 &apos;mollys&apos;,
 &apos;meditteranean&apos;,
 &apos;workday&apos;,
 &apos;apologies&apos;,
 &apos;empathise&apos;,
 &apos;outs&apos;,
 &apos;hmmmmmmmm&apos;,
 &apos;enquiry&apos;,
 &apos;detector&apos;,
 &apos;copying&apos;,
 &apos;outlive&apos;,
 &apos;gangsta&apos;,
 &apos;koyaanisqatsi&apos;,
 &apos;entrenches&apos;,
 &apos;author&apos;,
 &apos;undistinguished&apos;,
 &apos;izzard&apos;,
 &apos;orgue&apos;,
 &apos;negotiator&apos;,
 &apos;behaviorally&apos;,
 &apos;eyebrowed&apos;,
 &apos;maximizes&apos;,
 &apos;pilippinos&apos;,
 &apos;recurred&apos;,
 &apos;bullt&apos;,
 &apos;infinnerty&apos;,
 &apos;suspicious&apos;,
 &apos;uncooked&apos;,
 &apos;these&apos;,
 &apos;ozaki&apos;,
 &apos;sweden&apos;,
 &apos;petition&apos;,
 &apos;opium&apos;,
 &apos;complacency&apos;,
 &apos;deux&apos;,
 &apos;kramer&apos;,
 &apos;opt&apos;,
 &apos;auras&apos;,
 &apos;shyamalan&apos;,
 &apos;lamore&apos;,
 &apos;sunbathing&apos;,
 &apos;toxins&apos;,
 &apos;limned&apos;,
 &apos;khali&apos;,
 &apos;jefferey&apos;,
 &apos;interviewee&apos;,
 &apos;righted&apos;,
 &apos;grandmammy&apos;,
 &apos;wol&apos;,
 &apos;verica&apos;,
 &apos;footwork&apos;,
 &apos;doug&apos;,
 &apos;euthanasiarist&apos;,
 &apos;repeating&apos;,
 &apos;debutante&apos;,
 &apos;trusts&apos;,
 &apos;righto&apos;,
 &apos;phyllida&apos;,
 &apos;upa&apos;,
 &apos;doogie&apos;,
 &apos;gig&apos;,
 &apos;violins&apos;,
 &apos;ardor&apos;,
 &apos;ould&apos;,
 &apos;stymieing&apos;,
 &apos;libs&apos;,
 &apos;alejo&apos;,
 &apos;sick&apos;,
 &apos;propensities&apos;,
 &apos;occasions&apos;,
 &apos;spiderman&apos;,
 &apos;limousines&apos;,
 &apos;hearkening&apos;,
 &apos;reinstated&apos;,
 &apos;concede&apos;,
 &apos;vineyard&apos;,
 &apos;image&apos;,
 &apos;waxed&apos;,
 &apos;inuyasha&apos;,
 &apos;paralyzed&apos;,
 &apos;notches&apos;,
 &apos;latifah&apos;,
 &apos;mediation&apos;,
 &apos;cozies&apos;,
 &apos;spirit&apos;,
 &apos;fathoms&apos;,
 &apos;uecker&apos;,
 &apos;hoochie&apos;,
 &apos;akria&apos;,
 &apos;praises&apos;,
 &apos;wiring&apos;,
 &apos;pastparticularly&apos;,
 &apos;ghastliness&apos;,
 &apos;artiness&apos;,
 &apos;gruner&apos;,
 &apos;admirals&apos;,
 &apos;egger&apos;,
 &apos;extract&apos;,
 &apos;guiltlessly&apos;,
 &apos;pie&apos;,
 &apos;audaciousness&apos;,
 &apos;stallonethat&apos;,
 &apos;balconys&apos;,
 &apos;cassi&apos;,
 &apos;definable&apos;,
 &apos;rote&apos;,
 &apos;assaulted&apos;,
 &apos;schmoeller&apos;,
 &apos;cancer&apos;,
 &apos;equality&apos;,
 &apos;kruk&apos;,
 &apos;whoah&apos;,
 &apos;dalai&apos;,
 &apos;tuareg&apos;,
 &apos;split&apos;,
 &apos;bollywood&apos;,
 &apos;mates&apos;,
 &apos;supports&apos;,
 &apos;whiskers&apos;,
 &apos;meres&apos;,
 &apos;plasticine&apos;,
 &apos;bartel&apos;,
 &apos;phrase&apos;,
 &apos;poldark&apos;,
 &apos;pylon&apos;,
 &apos;undefined&apos;,
 &apos;videographer&apos;,
 &apos;blithesome&apos;,
 &apos;prendergast&apos;,
 &apos;goddard&apos;,
 &apos;spectular&apos;,
 &apos;fof&apos;,
 &apos;kiddie&apos;,
 &apos;accelerating&apos;,
 &apos;secreted&apos;,
 &apos;manslaughter&apos;,
 &apos;akimbo&apos;,
 &apos;privacy&apos;,
 &apos;michigan&apos;,
 &apos;ambiguities&apos;,
 &apos;belabors&apos;,
 &apos;mol&apos;,
 &apos;disemboweled&apos;,
 &apos;creely&apos;,
 &apos;nosebleed&apos;,
 &apos;autobiography&apos;,
 &apos;dispelled&apos;,
 &apos;lancie&apos;,
 &apos;revolutionaries&apos;,
 &apos;allende&apos;,
 &apos;jacy&apos;,
 &apos;kostic&apos;,
 &apos;tormei&apos;,
 &apos;chiefly&apos;,
 &apos;atmospheric&apos;,
 &apos;europa&apos;,
 &apos;judmila&apos;,
 &apos;extremal&apos;,
 &apos;decaprio&apos;,
 &apos;amore&apos;,
 &apos;cockneys&apos;,
 &apos;chong&apos;,
 &apos;coordinates&apos;,
 &apos;ctomvelu&apos;,
 &apos;scums&apos;,
 &apos;valleyspeak&apos;,
 &apos;minstrel&apos;,
 &apos;shoddier&apos;,
 &apos;combusted&apos;,
 &apos;tirade&apos;,
 &apos;marketplaces&apos;,
 &apos;reflex&apos;,
 &apos;rjt&apos;,
 &apos;deckard&apos;,
 &apos;godfathers&apos;,
 &apos;sibling&apos;,
 &apos;erupted&apos;,
 &apos;wasnt&apos;,
 &apos;lollipop&apos;,
 &apos;narcotics&apos;,
 &apos;showdowns&apos;,
 &apos;excess&apos;,
 &apos;taught&apos;,
 &apos;persuade&apos;,
 &apos;homer&apos;,
 &apos;binysh&apos;,
 &apos;ravaging&apos;,
 &apos;minutest&apos;,
 &apos;yomada&apos;,
 &apos;leckie&apos;,
 &apos;snazzy&apos;,
 &apos;rafting&apos;,
 &apos;grendelif&apos;,
 &apos;nemeses&apos;,
 &apos;westmore&apos;,
 &apos;sty&apos;,
 &apos;puertorricans&apos;,
 &apos;zaara&apos;,
 &apos;timemachine&apos;,
 &apos;similarities&apos;,
 &apos;colera&apos;,
 &apos;firefall&apos;,
 &apos;winked&apos;,
 &apos;painkiller&apos;,
 &apos;leaflets&apos;,
 &apos;tehran&apos;,
 &apos;hooker&apos;,
 &apos;appalingly&apos;,
 &apos;humility&apos;,
 &apos;illegitimate&apos;,
 &apos;coer&apos;,
 &apos;responisible&apos;,
 &apos;conceded&apos;,
 &apos;scarves&apos;,
 &apos;dawid&apos;,
 &apos;overflows&apos;,
 &apos;annuder&apos;,
 &apos;nickelodean&apos;,
 &apos;comanche&apos;,
 &apos;betrail&apos;,
 &apos;pillage&apos;,
 &apos;daffy&apos;,
 &apos;dobson&apos;,
 &apos;tessier&apos;,
 &apos;egoism&apos;,
 &apos;meanie&apos;,
 &apos;trancers&apos;,
 &apos;sequences&apos;,
 &apos;viciente&apos;,
 &apos;redlich&apos;,
 &apos;filmfrderung&apos;,
 &apos;leveled&apos;,
 &apos;performer&apos;,
 &apos;opponent&apos;,
 &apos;appears&apos;,
 &apos;squeaks&apos;,
 &apos;peripheral&apos;,
 &apos;blimey&apos;,
 &apos;glass&apos;,
 &apos;captors&apos;,
 &apos;strains&apos;,
 &apos;codenamealexa&apos;,
 &apos;tooo&apos;,
 &apos;aiello&apos;,
 &apos;matines&apos;,
 &apos;calibre&apos;,
 &apos;tighten&apos;,
 &apos;papercuts&apos;,
 &apos;necrotic&apos;,
 &apos;hums&apos;,
 &apos;kavner&apos;,
 &apos;employers&apos;,
 &apos;troy&apos;,
 &apos;almerayeda&apos;,
 &apos;barnet&apos;,
 &apos;nicotero&apos;,
 &apos;rush&apos;,
 &apos;ahehehe&apos;,
 &apos;dui&apos;,
 &apos;bleeps&apos;,
 &apos;heroe&apos;,
 &apos;gangreen&apos;,
 &apos;paintbrush&apos;,
 &apos;dowager&apos;,
 &apos;khakkee&apos;,
 &apos;chariots&apos;,
 &apos;benfer&apos;,
 &apos;mcneely&apos;,
 &apos;quelled&apos;,
 &apos;blockheads&apos;,
 &apos;dufy&apos;,
 &apos;badmen&apos;,
 &apos;dondaro&apos;,
 &apos;nachoo&apos;,
 &apos;intercedes&apos;,
 &apos;looksand&apos;,
 &apos;hasidic&apos;,
 &apos;will&apos;,
 &apos;practicable&apos;,
 &apos;reading&apos;,
 &apos;manufacture&apos;,
 &apos;bao&apos;,
 &apos;cigarette&apos;,
 &apos;chomps&apos;,
 &apos;subverting&apos;,
 &apos;reichdeutch&apos;,
 &apos;dexter&apos;,
 &apos;hrishitta&apos;,
 &apos;splitting&apos;,
 &apos;uproarious&apos;,
 &apos;ametuer&apos;,
 &apos;speedway&apos;,
 &apos;worser&apos;,
 &apos;brisco&apos;,
 &apos;stream&apos;,
 &apos;etre&apos;,
 &apos;lengths&apos;,
 &apos;chimpnaut&apos;,
 &apos;corny&apos;,
 &apos;stirring&apos;,
 &apos;tremendous&apos;,
 &apos;tually&apos;,
 &apos;mnage&apos;,
 &apos;ashitaka&apos;,
 &apos;crossbows&apos;,
 &apos;hackery&apos;,
 &apos;riker&apos;,
 &apos;twelve&apos;,
 &apos;freshner&apos;,
 &apos;bobbie&apos;,
 &apos;percussion&apos;,
 &apos;overpopulation&apos;,
 &apos;eeeekkk&apos;,
 &apos;centaury&apos;,
 &apos;summitting&apos;,
 &apos;andbest&apos;,
 &apos;pumping&apos;,
 &apos;somnolent&apos;,
 &apos;infatuation&apos;,
 &apos;shakesphere&apos;,
 &apos;ingred&apos;,
 &apos;moon&apos;,
 &apos;keven&apos;,
 &apos;sanguisuga&apos;,
 &apos;quivers&apos;,
 &apos;equalling&apos;,
 &apos;vaugely&apos;,
 &apos;supervising&apos;,
 &apos;dissolved&apos;,
 &apos;cheshire&apos;,
 &apos;retribution&apos;,
 &apos;cartoons&apos;,
 &apos;maisie&apos;,
 &apos;reptiles&apos;,
 &apos;rsther&apos;,
 &apos;erratically&apos;,
 &apos;hoyt&apos;,
 ...]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">layer_0 = np.zeros((<span class="number">1</span>,vocab_size))</div><div class="line">layer_0</div></pre></td></tr></table></figure>
<pre><code>array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</div><div class="line">Image(filename=<span class="string">'sentiment_network.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_24_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">word2index = &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i,word <span class="keyword">in</span> enumerate(vocab):</div><div class="line">    word2index[word] = i</div><div class="line">word2index</div></pre></td></tr></table></figure>
<pre><code>{&apos;&apos;: 0,
 &apos;werewoves&apos;: 1,
 &apos;endowments&apos;: 2,
 &apos;palace&apos;: 3,
 &apos;persiflage&apos;: 4,
 &apos;slasherville&apos;: 5,
 &apos;locally&apos;: 6,
 &apos;unrecycled&apos;: 7,
 &apos;spearhead&apos;: 8,
 &apos;allyson&apos;: 9,
 &apos;manhating&apos;: 10,
 &apos;bartok&apos;: 11,
 &apos;gretorexes&apos;: 12,
 &apos;soaks&apos;: 13,
 &apos;protestations&apos;: 14,
 &apos;superimposes&apos;: 15,
 &apos;theirry&apos;: 16,
 &apos;yaqui&apos;: 17,
 &apos;contrives&apos;: 18,
 &apos;accessorizing&apos;: 19,
 &apos;arg&apos;: 20,
 &apos;sanguine&apos;: 21,
 &apos;batouch&apos;: 22,
 &apos;asked&apos;: 23,
 &apos;animals&apos;: 24,
 &apos;cockpits&apos;: 25,
 &apos;gorilla&apos;: 26,
 &apos;diculous&apos;: 27,
 &apos;establishing&apos;: 28,
 &apos;kagemusha&apos;: 29,
 &apos;sketches&apos;: 30,
 &apos;rebuilt&apos;: 31,
 &apos;perniciously&apos;: 32,
 &apos;socioeconomic&apos;: 33,
 &apos;ladylike&apos;: 34,
 &apos;prognostication&apos;: 35,
 &apos;blech&apos;: 36,
 &apos;sugarbabe&apos;: 37,
 &apos;desk&apos;: 38,
 &apos;fez&apos;: 39,
 &apos;accents&apos;: 40,
 &apos;speach&apos;: 41,
 &apos;rooster&apos;: 42,
 &apos;effort&apos;: 43,
 &apos;bodega&apos;: 44,
 &apos;dong&apos;: 45,
 &apos;preordained&apos;: 46,
 &apos;dubliners&apos;: 47,
 &apos;vili&apos;: 48,
 &apos;imperatives&apos;: 49,
 &apos;artifices&apos;: 50,
 &apos;wieder&apos;: 51,
 &apos;climate&apos;: 52,
 &apos;whoopdedoodles&apos;: 53,
 &apos;quatermass&apos;: 54,
 &apos;inveterate&apos;: 55,
 &apos;memorandum&apos;: 56,
 &apos;crucially&apos;: 57,
 &apos;bulimics&apos;: 58,
 &apos;misdrawing&apos;: 59,
 &apos;plympton&apos;: 60,
 &apos;fireballs&apos;: 61,
 &apos;verdant&apos;: 62,
 &apos;testi&apos;: 63,
 &apos;undeservingly&apos;: 64,
 &apos;lusted&apos;: 65,
 &apos;shylock&apos;: 66,
 &apos;disinfecting&apos;: 67,
 &apos;boxer&apos;: 68,
 &apos;givney&apos;: 69,
 &apos;hs&apos;: 70,
 &apos;loser&apos;: 71,
 &apos;civics&apos;: 72,
 &apos;volcano&apos;: 73,
 &apos;jur&apos;: 74,
 &apos;mohnish&apos;: 75,
 &apos;candidates&apos;: 76,
 &apos;assemble&apos;: 77,
 &apos;simi&apos;: 78,
 &apos;resort&apos;: 79,
 &apos;hessling&apos;: 80,
 &apos;starbase&apos;: 81,
 &apos;orgolini&apos;: 82,
 &apos;starrett&apos;: 83,
 &apos;weaker&apos;: 84,
 &apos;transcending&apos;: 85,
 &apos;levitate&apos;: 86,
 &apos;spurns&apos;: 87,
 &apos;contradictory&apos;: 88,
 &apos;cambreau&apos;: 89,
 &apos;latvia&apos;: 90,
 &apos;kirkpatrick&apos;: 91,
 &apos;betty&apos;: 92,
 &apos;agnostic&apos;: 93,
 &apos;sosa&apos;: 94,
 &apos;kanji&apos;: 95,
 &apos;swill&apos;: 96,
 &apos;millinium&apos;: 97,
 &apos;macgregor&apos;: 98,
 &apos;brd&apos;: 99,
 &apos;ariete&apos;: 100,
 &apos;assassins&apos;: 101,
 &apos;disscusion&apos;: 102,
 &apos;legislative&apos;: 103,
 &apos;dwars&apos;: 104,
 &apos;controller&apos;: 105,
 &apos;hadass&apos;: 106,
 &apos;vega&apos;: 107,
 &apos;bends&apos;: 108,
 &apos;glock&apos;: 109,
 &apos;spacewalk&apos;: 110,
 &apos;va&apos;: 111,
 &apos;offa&apos;: 112,
 &apos;winfield&apos;: 113,
 &apos;somewhat&apos;: 114,
 &apos;yates&apos;: 115,
 &apos;vinyl&apos;: 116,
 &apos;complicity&apos;: 117,
 &apos;bela&apos;: 118,
 &apos;squishes&apos;: 119,
 &apos;rippings&apos;: 120,
 &apos;eyed&apos;: 121,
 &apos;amatuerish&apos;: 122,
 &apos;desilva&apos;: 123,
 &apos;christmass&apos;: 124,
 &apos;briley&apos;: 125,
 &apos;bakhtyari&apos;: 126,
 &apos;unmasked&apos;: 127,
 &apos;huffman&apos;: 128,
 &apos;fallacious&apos;: 129,
 &apos;problem&apos;: 130,
 &apos;sieger&apos;: 131,
 &apos;koma&apos;: 132,
 &apos;grovelling&apos;: 133,
 &apos;incl&apos;: 134,
 &apos;farlinger&apos;: 135,
 &apos;teasers&apos;: 136,
 &apos;huff&apos;: 137,
 &apos;untried&apos;: 138,
 &apos;crocker&apos;: 139,
 &apos;dansu&apos;: 140,
 &apos;scammers&apos;: 141,
 &apos;popsicle&apos;: 142,
 &apos;arthritic&apos;: 143,
 &apos;grubs&apos;: 144,
 &apos;exemplar&apos;: 145,
 &apos;racial&apos;: 146,
 &apos;verbiage&apos;: 147,
 &apos;saloshin&apos;: 148,
 &apos;painlessly&apos;: 149,
 &apos;harewood&apos;: 150,
 &apos;shart&apos;: 151,
 &apos;keepers&apos;: 152,
 &apos;archrivals&apos;: 153,
 &apos;longish&apos;: 154,
 &apos;batmobile&apos;: 155,
 &apos;shakespearian&apos;: 156,
 &apos;bestselling&apos;: 157,
 &apos;spewing&apos;: 158,
 &apos;midlands&apos;: 159,
 &apos;trattoria&apos;: 160,
 &apos;greenaway&apos;: 161,
 &apos;gestapo&apos;: 162,
 &apos;ed&apos;: 163,
 &apos;huns&apos;: 164,
 &apos;bloch&apos;: 165,
 &apos;mashall&apos;: 166,
 &apos;versy&apos;: 167,
 &apos;david&apos;: 168,
 &apos;sicilian&apos;: 169,
 &apos;propositioned&apos;: 170,
 &apos;eighty&apos;: 171,
 &apos;carridine&apos;: 172,
 &apos;delicates&apos;: 173,
 &apos;veering&apos;: 174,
 &apos;columbus&apos;: 175,
 &apos;dunning&apos;: 176,
 &apos;mercantile&apos;: 177,
 &apos;rape&apos;: 178,
 &apos;purely&apos;: 179,
 &apos;rediscovered&apos;: 180,
 &apos;abstinence&apos;: 181,
 &apos;clunes&apos;: 182,
 &apos;emerson&apos;: 183,
 &apos;judgments&apos;: 184,
 &apos;lawful&apos;: 185,
 &apos;celebration&apos;: 186,
 &apos;affirmative&apos;: 187,
 &apos;sedately&apos;: 188,
 &apos;sng&apos;: 189,
 &apos;inuindo&apos;: 190,
 &apos;mosely&apos;: 191,
 &apos;bungalow&apos;: 192,
 &apos;ninga&apos;: 193,
 &apos;dripped&apos;: 194,
 &apos;itallian&apos;: 195,
 &apos;himalaya&apos;: 196,
 &apos;shikoku&apos;: 197,
 &apos;braik&apos;: 198,
 &apos;grousing&apos;: 199,
 &apos;nair&apos;: 200,
 &apos;forrester&apos;: 201,
 &apos;elemental&apos;: 202,
 &apos;allegations&apos;: 203,
 &apos;delilah&apos;: 204,
 &apos;boneheaded&apos;: 205,
 &apos;baltimoreans&apos;: 206,
 &apos;dunebuggies&apos;: 207,
 &apos;taguchi&apos;: 208,
 &apos;coleseum&apos;: 209,
 &apos;saratoga&apos;: 210,
 &apos;ninotchka&apos;: 211,
 &apos;afganistan&apos;: 212,
 &apos;genorisity&apos;: 213,
 &apos;haff&apos;: 214,
 &apos;jennilee&apos;: 215,
 &apos;jesues&apos;: 216,
 &apos;dwarfs&apos;: 217,
 &apos;enchilada&apos;: 218,
 &apos;feminist&apos;: 219,
 &apos;ghettoisation&apos;: 220,
 &apos;handlebar&apos;: 221,
 &apos;antagonistic&apos;: 222,
 &apos;marian&apos;: 223,
 &apos;crichton&apos;: 224,
 &apos;ryo&apos;: 225,
 &apos;mean&apos;: 226,
 &apos;inheritance&apos;: 227,
 &apos;presently&apos;: 228,
 &apos;pear&apos;: 229,
 &apos;inequality&apos;: 230,
 &apos;stately&apos;: 231,
 &apos;nooo&apos;: 232,
 &apos;obscurities&apos;: 233,
 &apos;determinedly&apos;: 234,
 &apos;solemn&apos;: 235,
 &apos;sullenly&apos;: 236,
 &apos;machism&apos;: 237,
 &apos;tingled&apos;: 238,
 &apos;maschera&apos;: 239,
 &apos;tristran&apos;: 240,
 &apos;mendoza&apos;: 241,
 &apos;baked&apos;: 242,
 &apos;jonatha&apos;: 243,
 &apos;lowly&apos;: 244,
 &apos;halliwell&apos;: 245,
 &apos;msted&apos;: 246,
 &apos;rodann&apos;: 247,
 &apos;hunkered&apos;: 248,
 &apos;cashmere&apos;: 249,
 &apos;chevalia&apos;: 250,
 &apos;jakub&apos;: 251,
 &apos;dobermann&apos;: 252,
 &apos;overexxagerating&apos;: 253,
 &apos;pfennig&apos;: 254,
 &apos;fisted&apos;: 255,
 &apos;mcelwee&apos;: 256,
 &apos;chief&apos;: 257,
 &apos;parlor&apos;: 258,
 &apos;browbeating&apos;: 259,
 &apos;parasol&apos;: 260,
 &apos;negligible&apos;: 261,
 &apos;kira&apos;: 262,
 &apos;monceau&apos;: 263,
 &apos;blew&apos;: 264,
 &apos;odete&apos;: 265,
 &apos;muco&apos;: 266,
 &apos;predominantly&apos;: 267,
 &apos;levon&apos;: 268,
 &apos;discourage&apos;: 269,
 &apos;fragmented&apos;: 270,
 &apos;vandermey&apos;: 271,
 &apos;etude&apos;: 272,
 &apos;mitch&apos;: 273,
 &apos;sandbag&apos;: 274,
 &apos;bending&apos;: 275,
 &apos;dizzying&apos;: 276,
 &apos;mover&apos;: 277,
 &apos;rewired&apos;: 278,
 &apos;awww&apos;: 279,
 &apos;di&apos;: 280,
 &apos;bejesus&apos;: 281,
 &apos;wallet&apos;: 282,
 &apos;uprooting&apos;: 283,
 &apos;atari&apos;: 284,
 &apos;dreamlike&apos;: 285,
 &apos;exacted&apos;: 286,
 &apos;harbouring&apos;: 287,
 &apos;indiscreet&apos;: 288,
 &apos;turks&apos;: 289,
 &apos;gems&apos;: 290,
 &apos;hoboken&apos;: 291,
 &apos;yalom&apos;: 292,
 &apos;rooftop&apos;: 293,
 &apos;howit&apos;: 294,
 &apos;tolson&apos;: 295,
 &apos;tulane&apos;: 296,
 &apos;reductive&apos;: 297,
 &apos;catharthic&apos;: 298,
 &apos;famarialy&apos;: 299,
 &apos;sista&apos;: 300,
 &apos;ghidorah&apos;: 301,
 &apos;ngoombujarra&apos;: 302,
 &apos;intently&apos;: 303,
 &apos;jlu&apos;: 304,
 &apos;kyrptonite&apos;: 305,
 &apos;hilda&apos;: 306,
 &apos;census&apos;: 307,
 &apos;baguette&apos;: 308,
 &apos;mondrians&apos;: 309,
 &apos;advisable&apos;: 310,
 &apos;mcnee&apos;: 311,
 &apos;candlelit&apos;: 312,
 &apos;affability&apos;: 313,
 &apos;intercut&apos;: 314,
 &apos;installations&apos;: 315,
 &apos;elliptical&apos;: 316,
 &apos;washer&apos;: 317,
 &apos;colt&apos;: 318,
 &apos;pevensie&apos;: 319,
 &apos;outshined&apos;: 320,
 &apos;despotic&apos;: 321,
 &apos;suares&apos;: 322,
 &apos;privates&apos;: 323,
 &apos;scrabble&apos;: 324,
 &apos;milliardo&apos;: 325,
 &apos;booting&apos;: 326,
 &apos;rowan&apos;: 327,
 &apos;golmaal&apos;: 328,
 &apos;pueblos&apos;: 329,
 &apos;msf&apos;: 330,
 &apos;giulietta&apos;: 331,
 &apos;phili&apos;: 332,
 &apos;pleaseee&apos;: 333,
 &apos;connecticute&apos;: 334,
 &apos;rosnelski&apos;: 335,
 &apos;tenebra&apos;: 336,
 &apos;bako&apos;: 337,
 &apos;blessings&apos;: 338,
 &apos;smudge&apos;: 339,
 &apos;cya&apos;: 340,
 &apos;pummel&apos;: 341,
 &apos;brocks&apos;: 342,
 &apos;homere&apos;: 343,
 &apos;propellant&apos;: 344,
 &apos;deliveried&apos;: 345,
 &apos;finisham&apos;: 346,
 &apos;newsradio&apos;: 347,
 &apos;bernie&apos;: 348,
 &apos;gouden&apos;: 349,
 &apos;enchant&apos;: 350,
 &apos;bessie&apos;: 351,
 &apos;semisubmerged&apos;: 352,
 &apos;extraterrestrial&apos;: 353,
 &apos;believably&apos;: 354,
 &apos;accomplice&apos;: 355,
 &apos;dooku&apos;: 356,
 &apos;baja&apos;: 357,
 &apos;met&apos;: 358,
 &apos;circulate&apos;: 359,
 &apos;disobeyed&apos;: 360,
 &apos;quakerly&apos;: 361,
 &apos;overstyling&apos;: 362,
 &apos;softens&apos;: 363,
 &apos;units&apos;: 364,
 &apos;shaye&apos;: 365,
 &apos;starters&apos;: 366,
 &apos;gripes&apos;: 367,
 &apos;nightmarish&apos;: 368,
 &apos;patriotic&apos;: 369,
 &apos;goodtimes&apos;: 370,
 &apos;stroheim&apos;: 371,
 &apos;debit&apos;: 372,
 &apos;prissies&apos;: 373,
 &apos;woebegone&apos;: 374,
 &apos;deputies&apos;: 375,
 &apos;awkwardness&apos;: 376,
 &apos;obama&apos;: 377,
 &apos;tarazu&apos;: 378,
 &apos;kendra&apos;: 379,
 &apos;patriots&apos;: 380,
 &apos;helpfuls&apos;: 381,
 &apos;mightily&apos;: 382,
 &apos;polemical&apos;: 383,
 &apos;unruly&apos;: 384,
 &apos;planing&apos;: 385,
 &apos;paperhouse&apos;: 386,
 &apos;sororities&apos;: 387,
 &apos;pym&apos;: 388,
 &apos;therin&apos;: 389,
 &apos;tarkovsky&apos;: 390,
 &apos;rdiger&apos;: 391,
 &apos;resembling&apos;: 392,
 &apos;gimmicks&apos;: 393,
 &apos;iler&apos;: 394,
 &apos;lineal&apos;: 395,
 &apos;taming&apos;: 396,
 &apos;mortenson&apos;: 397,
 &apos;waugh&apos;: 398,
 &apos;furies&apos;: 399,
 &apos;grufford&apos;: 400,
 &apos;hammill&apos;: 401,
 &apos;plunkett&apos;: 402,
 &apos;paterson&apos;: 403,
 &apos;konishita&apos;: 404,
 &apos;immorality&apos;: 405,
 &apos;angelos&apos;: 406,
 &apos;kebbel&apos;: 407,
 &apos;tamiroff&apos;: 408,
 &apos;boen&apos;: 409,
 &apos;rivalry&apos;: 410,
 &apos;ethnic&apos;: 411,
 &apos;funner&apos;: 412,
 &apos;troops&apos;: 413,
 &apos;deadeningly&apos;: 414,
 &apos;watcha&apos;: 415,
 &apos;dhiraj&apos;: 416,
 &apos;haranguing&apos;: 417,
 &apos;dejas&apos;: 418,
 &apos;weasely&apos;: 419,
 &apos;category&apos;: 420,
 &apos;laughable&apos;: 421,
 &apos;gramps&apos;: 422,
 &apos;safdar&apos;: 423,
 &apos;calorie&apos;: 424,
 &apos;scandi&apos;: 425,
 &apos;cannon&apos;: 426,
 &apos;maliciously&apos;: 427,
 &apos;bothered&apos;: 428,
 &apos;troi&apos;: 429,
 &apos;couleur&apos;: 430,
 &apos;visionary&apos;: 431,
 &apos;fizzles&apos;: 432,
 &apos;evangalizing&apos;: 433,
 &apos;reeves&apos;: 434,
 &apos;bombadier&apos;: 435,
 &apos;bowlegged&apos;: 436,
 &apos;custody&apos;: 437,
 &apos;weta&apos;: 438,
 &apos;archambault&apos;: 439,
 &apos;warlords&apos;: 440,
 &apos;makeout&apos;: 441,
 &apos;bonbons&apos;: 442,
 &apos;importances&apos;: 443,
 &apos;baruchel&apos;: 444,
 &apos;floyd&apos;: 445,
 &apos;infirm&apos;: 446,
 &apos;bloodwaters&apos;: 447,
 &apos;ashford&apos;: 448,
 &apos;colleagues&apos;: 449,
 &apos;discern&apos;: 450,
 &apos;thunderjet&apos;: 451,
 &apos;pullers&apos;: 452,
 &apos;evos&apos;: 453,
 &apos;celebrations&apos;: 454,
 &apos;seely&apos;: 455,
 &apos;nasty&apos;: 456,
 &apos;keach&apos;: 457,
 &apos;tonge&apos;: 458,
 &apos;senki&apos;: 459,
 &apos;approxiamtely&apos;: 460,
 &apos;unable&apos;: 461,
 &apos;rayburn&apos;: 462,
 &apos;britons&apos;: 463,
 &apos;christoph&apos;: 464,
 &apos;proctor&apos;: 465,
 &apos;tapped&apos;: 466,
 &apos;lenz&apos;: 467,
 &apos;vengeant&apos;: 468,
 &apos;exaggerating&apos;: 469,
 &apos;mle&apos;: 470,
 &apos;declaims&apos;: 471,
 &apos;hight&apos;: 472,
 &apos;repetoir&apos;: 473,
 &apos;yolu&apos;: 474,
 &apos;smarty&apos;: 475,
 &apos;steels&apos;: 476,
 &apos;openness&apos;: 477,
 &apos;coached&apos;: 478,
 &apos;archiving&apos;: 479,
 &apos;horrendous&apos;: 480,
 &apos;engages&apos;: 481,
 &apos;loosing&apos;: 482,
 &apos;anchorpoint&apos;: 483,
 &apos;fecal&apos;: 484,
 &apos;gracefully&apos;: 485,
 &apos;tapioca&apos;: 486,
 &apos;bizniss&apos;: 487,
 &apos;overhyped&apos;: 488,
 &apos;shortland&apos;: 489,
 &apos;cleansed&apos;: 490,
 &apos;negativity&apos;: 491,
 &apos;gushy&apos;: 492,
 &apos;mortitz&apos;: 493,
 &apos;stripper&apos;: 494,
 &apos;woke&apos;: 495,
 &apos;slayers&apos;: 496,
 &apos;uncensored&apos;: 497,
 &apos;textiles&apos;: 498,
 &apos;louda&apos;: 499,
 &apos;castrati&apos;: 500,
 &apos;altmanesque&apos;: 501,
 &apos;yes&apos;: 502,
 &apos;huntress&apos;: 503,
 &apos;urging&apos;: 504,
 &apos;tua&apos;: 505,
 &apos;sentient&apos;: 506,
 &apos;kellogg&apos;: 507,
 &apos;cheerful&apos;: 508,
 &apos;swanks&apos;: 509,
 &apos;shor&apos;: 510,
 &apos;cheapo&apos;: 511,
 &apos;flourishing&apos;: 512,
 &apos;tap&apos;: 513,
 &apos;kph&apos;: 514,
 &apos;bobbidi&apos;: 515,
 &apos;tangos&apos;: 516,
 &apos;honey&apos;: 517,
 &apos;oswald&apos;: 518,
 &apos;philippians&apos;: 519,
 &apos;payroll&apos;: 520,
 &apos;chooses&apos;: 521,
 &apos;archtypes&apos;: 522,
 &apos;generators&apos;: 523,
 &apos;grillo&apos;: 524,
 &apos;horrorible&apos;: 525,
 &apos;yellowing&apos;: 526,
 &apos;vancouver&apos;: 527,
 &apos;thet&apos;: 528,
 &apos;babtise&apos;: 529,
 &apos;participates&apos;: 530,
 &apos;uriah&apos;: 531,
 &apos;loust&apos;: 532,
 &apos;ravishingly&apos;: 533,
 &apos;punishing&apos;: 534,
 &apos;jhoom&apos;: 535,
 &apos;lulling&apos;: 536,
 &apos;stetting&apos;: 537,
 &apos;wierd&apos;: 538,
 &apos;truce&apos;: 539,
 &apos;peerce&apos;: 540,
 &apos;transpose&apos;: 541,
 &apos;unplanned&apos;: 542,
 &apos;unmistakeably&apos;: 543,
 &apos;approval&apos;: 544,
 &apos;amontillado&apos;: 545,
 &apos;een&apos;: 546,
 &apos;lefties&apos;: 547,
 &apos;tentatives&apos;: 548,
 &apos;mysteriousness&apos;: 549,
 &apos;mid&apos;: 550,
 &apos;technicians&apos;: 551,
 &apos;wich&apos;: 552,
 &apos;englund&apos;: 553,
 &apos;freespirited&apos;: 554,
 &apos;kun&apos;: 555,
 &apos;discourses&apos;: 556,
 &apos;nyily&apos;: 557,
 &apos;honorably&apos;: 558,
 &apos;hankerchief&apos;: 559,
 &apos;nugget&apos;: 560,
 &apos;nationalism&apos;: 561,
 &apos;reveals&apos;: 562,
 &apos;lamppost&apos;: 563,
 &apos;tempra&apos;: 564,
 &apos;sanctimoniousness&apos;: 565,
 &apos;wardrobes&apos;: 566,
 &apos;visa&apos;: 567,
 &apos;lenses&apos;: 568,
 &apos;johars&apos;: 569,
 &apos;prefers&apos;: 570,
 &apos;webster&apos;: 571,
 &apos;marcuzzo&apos;: 572,
 &apos;licensable&apos;: 573,
 &apos;brilliancy&apos;: 574,
 &apos;gumbas&apos;: 575,
 &apos;jacoby&apos;: 576,
 &apos;twine&apos;: 577,
 &apos;entices&apos;: 578,
 &apos;unpremeditated&apos;: 579,
 &apos;jin&apos;: 580,
 &apos;affirmatively&apos;: 581,
 &apos;joyful&apos;: 582,
 &apos;plotkurt&apos;: 583,
 &apos;danniele&apos;: 584,
 &apos;rpond&apos;: 585,
 &apos;flare&apos;: 586,
 &apos;lester&apos;: 587,
 &apos;toying&apos;: 588,
 &apos;having&apos;: 589,
 &apos;anorexia&apos;: 590,
 &apos;hoof&apos;: 591,
 &apos;stillman&apos;: 592,
 &apos;hows&apos;: 593,
 &apos;contrite&apos;: 594,
 &apos;hersholt&apos;: 595,
 &apos;utterance&apos;: 596,
 &apos;superflous&apos;: 597,
 &apos;orders&apos;: 598,
 &apos;pamelyn&apos;: 599,
 &apos;traumatized&apos;: 600,
 &apos;poder&apos;: 601,
 &apos;virtuality&apos;: 602,
 &apos;reaper&apos;: 603,
 &apos;trini&apos;: 604,
 &apos;phantasm&apos;: 605,
 &apos;fbp&apos;: 606,
 &apos;nuked&apos;: 607,
 &apos;siegfried&apos;: 608,
 &apos;ralph&apos;: 609,
 &apos;erwin&apos;: 610,
 &apos;rhymer&apos;: 611,
 &apos;christien&apos;: 612,
 &apos;sidekick&apos;: 613,
 &apos;grasshopper&apos;: 614,
 &apos;steryotypes&apos;: 615,
 &apos;donnagio&apos;: 616,
 &apos;denny&apos;: 617,
 &apos;fraudulent&apos;: 618,
 &apos;weisse&apos;: 619,
 &apos;yoji&apos;: 620,
 &apos;adapters&apos;: 621,
 &apos;andalthough&apos;: 622,
 &apos;fee&apos;: 623,
 &apos;attorney&apos;: 624,
 &apos;holliday&apos;: 625,
 &apos;prerequisite&apos;: 626,
 &apos;ives&apos;: 627,
 &apos;yvaine&apos;: 628,
 &apos;smaller&apos;: 629,
 &apos;satired&apos;: 630,
 &apos;ghillie&apos;: 631,
 &apos;hagelin&apos;: 632,
 &apos;upsurge&apos;: 633,
 &apos;empirical&apos;: 634,
 &apos;smap&apos;: 635,
 &apos;kirk&apos;: 636,
 &apos;conservatism&apos;: 637,
 &apos;wesley&apos;: 638,
 &apos;becuz&apos;: 639,
 &apos;fantasia&apos;: 640,
 &apos;treadstone&apos;: 641,
 &apos;berdalh&apos;: 642,
 &apos;reaganomics&apos;: 643,
 &apos;schwarzenberg&apos;: 644,
 &apos;housemann&apos;: 645,
 &apos;jumpstart&apos;: 646,
 &apos;glamorise&apos;: 647,
 &apos;braves&apos;: 648,
 &apos;simply&apos;: 649,
 &apos;which&apos;: 650,
 &apos;knifes&apos;: 651,
 &apos;ramblings&apos;: 652,
 &apos;bused&apos;: 653,
 &apos;lombardo&apos;: 654,
 &apos;refresher&apos;: 655,
 &apos;evenings&apos;: 656,
 &apos;openings&apos;: 657,
 &apos;rings&apos;: 658,
 &apos;reverend&apos;: 659,
 &apos;blurry&apos;: 660,
 &apos;baldy&apos;: 661,
 &apos;acing&apos;: 662,
 &apos;mollys&apos;: 663,
 &apos;meditteranean&apos;: 664,
 &apos;workday&apos;: 665,
 &apos;apologies&apos;: 666,
 &apos;empathise&apos;: 667,
 &apos;outs&apos;: 668,
 &apos;hmmmmmmmm&apos;: 669,
 &apos;enquiry&apos;: 670,
 &apos;detector&apos;: 671,
 &apos;copying&apos;: 672,
 &apos;outlive&apos;: 673,
 &apos;gangsta&apos;: 674,
 &apos;koyaanisqatsi&apos;: 675,
 &apos;entrenches&apos;: 676,
 &apos;author&apos;: 677,
 &apos;undistinguished&apos;: 678,
 &apos;izzard&apos;: 679,
 &apos;orgue&apos;: 680,
 &apos;negotiator&apos;: 681,
 &apos;behaviorally&apos;: 682,
 &apos;eyebrowed&apos;: 683,
 &apos;maximizes&apos;: 684,
 &apos;pilippinos&apos;: 685,
 &apos;recurred&apos;: 686,
 &apos;bullt&apos;: 687,
 &apos;infinnerty&apos;: 688,
 &apos;suspicious&apos;: 689,
 &apos;uncooked&apos;: 690,
 &apos;these&apos;: 691,
 &apos;ozaki&apos;: 692,
 &apos;sweden&apos;: 693,
 &apos;petition&apos;: 694,
 &apos;opium&apos;: 695,
 &apos;complacency&apos;: 696,
 &apos;deux&apos;: 697,
 &apos;kramer&apos;: 698,
 &apos;opt&apos;: 699,
 &apos;auras&apos;: 700,
 &apos;shyamalan&apos;: 701,
 &apos;lamore&apos;: 702,
 &apos;sunbathing&apos;: 703,
 &apos;toxins&apos;: 704,
 &apos;limned&apos;: 705,
 &apos;khali&apos;: 706,
 &apos;jefferey&apos;: 707,
 &apos;interviewee&apos;: 708,
 &apos;righted&apos;: 709,
 &apos;grandmammy&apos;: 710,
 &apos;wol&apos;: 711,
 &apos;verica&apos;: 712,
 &apos;footwork&apos;: 713,
 &apos;doug&apos;: 714,
 &apos;euthanasiarist&apos;: 715,
 &apos;repeating&apos;: 716,
 &apos;debutante&apos;: 717,
 &apos;trusts&apos;: 718,
 &apos;righto&apos;: 719,
 &apos;phyllida&apos;: 720,
 &apos;upa&apos;: 721,
 &apos;doogie&apos;: 722,
 &apos;gig&apos;: 723,
 &apos;violins&apos;: 724,
 &apos;ardor&apos;: 725,
 &apos;ould&apos;: 726,
 &apos;stymieing&apos;: 727,
 &apos;libs&apos;: 728,
 &apos;alejo&apos;: 729,
 &apos;sick&apos;: 730,
 &apos;propensities&apos;: 731,
 &apos;occasions&apos;: 732,
 &apos;spiderman&apos;: 733,
 &apos;limousines&apos;: 734,
 &apos;hearkening&apos;: 735,
 &apos;reinstated&apos;: 736,
 &apos;concede&apos;: 737,
 &apos;vineyard&apos;: 738,
 &apos;image&apos;: 739,
 &apos;waxed&apos;: 740,
 &apos;inuyasha&apos;: 741,
 &apos;paralyzed&apos;: 742,
 &apos;notches&apos;: 743,
 &apos;latifah&apos;: 744,
 &apos;mediation&apos;: 745,
 &apos;cozies&apos;: 746,
 &apos;spirit&apos;: 747,
 &apos;fathoms&apos;: 748,
 &apos;uecker&apos;: 749,
 &apos;hoochie&apos;: 750,
 &apos;akria&apos;: 751,
 &apos;praises&apos;: 752,
 &apos;wiring&apos;: 753,
 &apos;pastparticularly&apos;: 754,
 &apos;ghastliness&apos;: 755,
 &apos;artiness&apos;: 756,
 &apos;gruner&apos;: 757,
 &apos;admirals&apos;: 758,
 &apos;egger&apos;: 759,
 &apos;extract&apos;: 760,
 &apos;guiltlessly&apos;: 761,
 &apos;pie&apos;: 762,
 &apos;audaciousness&apos;: 763,
 &apos;stallonethat&apos;: 764,
 &apos;balconys&apos;: 765,
 &apos;cassi&apos;: 766,
 &apos;definable&apos;: 767,
 &apos;rote&apos;: 768,
 &apos;assaulted&apos;: 769,
 &apos;schmoeller&apos;: 770,
 &apos;cancer&apos;: 771,
 &apos;equality&apos;: 772,
 &apos;kruk&apos;: 773,
 &apos;whoah&apos;: 774,
 &apos;dalai&apos;: 775,
 &apos;tuareg&apos;: 776,
 &apos;split&apos;: 777,
 &apos;bollywood&apos;: 778,
 &apos;mates&apos;: 779,
 &apos;supports&apos;: 780,
 &apos;whiskers&apos;: 781,
 &apos;meres&apos;: 782,
 &apos;plasticine&apos;: 783,
 &apos;bartel&apos;: 784,
 &apos;phrase&apos;: 785,
 &apos;poldark&apos;: 786,
 &apos;pylon&apos;: 787,
 &apos;undefined&apos;: 788,
 &apos;videographer&apos;: 789,
 &apos;blithesome&apos;: 790,
 &apos;prendergast&apos;: 791,
 &apos;goddard&apos;: 792,
 &apos;spectular&apos;: 793,
 &apos;fof&apos;: 794,
 &apos;kiddie&apos;: 795,
 &apos;accelerating&apos;: 796,
 &apos;secreted&apos;: 797,
 &apos;manslaughter&apos;: 798,
 &apos;akimbo&apos;: 799,
 &apos;privacy&apos;: 800,
 &apos;michigan&apos;: 801,
 &apos;ambiguities&apos;: 802,
 &apos;belabors&apos;: 803,
 &apos;mol&apos;: 804,
 &apos;disemboweled&apos;: 805,
 &apos;creely&apos;: 806,
 &apos;nosebleed&apos;: 807,
 &apos;autobiography&apos;: 808,
 &apos;dispelled&apos;: 809,
 &apos;lancie&apos;: 810,
 &apos;revolutionaries&apos;: 811,
 &apos;allende&apos;: 812,
 &apos;jacy&apos;: 813,
 &apos;kostic&apos;: 814,
 &apos;tormei&apos;: 815,
 &apos;chiefly&apos;: 816,
 &apos;atmospheric&apos;: 817,
 &apos;europa&apos;: 818,
 &apos;judmila&apos;: 819,
 &apos;extremal&apos;: 820,
 &apos;decaprio&apos;: 821,
 &apos;amore&apos;: 822,
 &apos;cockneys&apos;: 823,
 &apos;chong&apos;: 824,
 &apos;coordinates&apos;: 825,
 &apos;ctomvelu&apos;: 826,
 &apos;scums&apos;: 827,
 &apos;valleyspeak&apos;: 828,
 &apos;minstrel&apos;: 829,
 &apos;shoddier&apos;: 830,
 &apos;combusted&apos;: 831,
 &apos;tirade&apos;: 832,
 &apos;marketplaces&apos;: 833,
 &apos;reflex&apos;: 834,
 &apos;rjt&apos;: 835,
 &apos;deckard&apos;: 836,
 &apos;godfathers&apos;: 837,
 &apos;sibling&apos;: 838,
 &apos;erupted&apos;: 839,
 &apos;wasnt&apos;: 840,
 &apos;lollipop&apos;: 841,
 &apos;narcotics&apos;: 842,
 &apos;showdowns&apos;: 843,
 &apos;excess&apos;: 844,
 &apos;taught&apos;: 845,
 &apos;persuade&apos;: 846,
 &apos;homer&apos;: 847,
 &apos;binysh&apos;: 848,
 &apos;ravaging&apos;: 849,
 &apos;minutest&apos;: 850,
 &apos;yomada&apos;: 851,
 &apos;leckie&apos;: 852,
 &apos;snazzy&apos;: 853,
 &apos;rafting&apos;: 854,
 &apos;grendelif&apos;: 855,
 &apos;nemeses&apos;: 856,
 &apos;westmore&apos;: 857,
 &apos;sty&apos;: 858,
 &apos;puertorricans&apos;: 859,
 &apos;zaara&apos;: 860,
 &apos;timemachine&apos;: 861,
 &apos;similarities&apos;: 862,
 &apos;colera&apos;: 863,
 &apos;firefall&apos;: 864,
 &apos;winked&apos;: 865,
 &apos;painkiller&apos;: 866,
 &apos;leaflets&apos;: 867,
 &apos;tehran&apos;: 868,
 &apos;hooker&apos;: 869,
 &apos;appalingly&apos;: 870,
 &apos;humility&apos;: 871,
 &apos;illegitimate&apos;: 872,
 &apos;coer&apos;: 873,
 &apos;responisible&apos;: 874,
 &apos;conceded&apos;: 875,
 &apos;scarves&apos;: 876,
 &apos;dawid&apos;: 877,
 &apos;overflows&apos;: 878,
 &apos;annuder&apos;: 879,
 &apos;nickelodean&apos;: 880,
 &apos;comanche&apos;: 881,
 &apos;betrail&apos;: 882,
 &apos;pillage&apos;: 883,
 &apos;daffy&apos;: 884,
 &apos;dobson&apos;: 885,
 &apos;tessier&apos;: 886,
 &apos;egoism&apos;: 887,
 &apos;meanie&apos;: 888,
 &apos;trancers&apos;: 889,
 &apos;sequences&apos;: 890,
 &apos;viciente&apos;: 891,
 &apos;redlich&apos;: 892,
 &apos;filmfrderung&apos;: 893,
 &apos;leveled&apos;: 894,
 &apos;performer&apos;: 895,
 &apos;opponent&apos;: 896,
 &apos;appears&apos;: 897,
 &apos;squeaks&apos;: 898,
 &apos;peripheral&apos;: 899,
 &apos;blimey&apos;: 900,
 &apos;glass&apos;: 901,
 &apos;captors&apos;: 902,
 &apos;strains&apos;: 903,
 &apos;codenamealexa&apos;: 904,
 &apos;tooo&apos;: 905,
 &apos;aiello&apos;: 906,
 &apos;matines&apos;: 907,
 &apos;calibre&apos;: 908,
 &apos;tighten&apos;: 909,
 &apos;papercuts&apos;: 910,
 &apos;necrotic&apos;: 911,
 &apos;hums&apos;: 912,
 &apos;kavner&apos;: 913,
 &apos;employers&apos;: 914,
 &apos;troy&apos;: 915,
 &apos;almerayeda&apos;: 916,
 &apos;barnet&apos;: 917,
 &apos;nicotero&apos;: 918,
 &apos;rush&apos;: 919,
 &apos;ahehehe&apos;: 920,
 &apos;dui&apos;: 921,
 &apos;bleeps&apos;: 922,
 &apos;heroe&apos;: 923,
 &apos;gangreen&apos;: 924,
 &apos;paintbrush&apos;: 925,
 &apos;dowager&apos;: 926,
 &apos;khakkee&apos;: 927,
 &apos;chariots&apos;: 928,
 &apos;benfer&apos;: 929,
 &apos;mcneely&apos;: 930,
 &apos;quelled&apos;: 931,
 &apos;blockheads&apos;: 932,
 &apos;dufy&apos;: 933,
 &apos;badmen&apos;: 934,
 &apos;dondaro&apos;: 935,
 &apos;nachoo&apos;: 936,
 &apos;intercedes&apos;: 937,
 &apos;looksand&apos;: 938,
 &apos;hasidic&apos;: 939,
 &apos;will&apos;: 940,
 &apos;practicable&apos;: 941,
 &apos;reading&apos;: 942,
 &apos;manufacture&apos;: 943,
 &apos;bao&apos;: 944,
 &apos;cigarette&apos;: 945,
 &apos;chomps&apos;: 946,
 &apos;subverting&apos;: 947,
 &apos;reichdeutch&apos;: 948,
 &apos;dexter&apos;: 949,
 &apos;hrishitta&apos;: 950,
 &apos;splitting&apos;: 951,
 &apos;uproarious&apos;: 952,
 &apos;ametuer&apos;: 953,
 &apos;speedway&apos;: 954,
 &apos;worser&apos;: 955,
 &apos;brisco&apos;: 956,
 &apos;stream&apos;: 957,
 &apos;etre&apos;: 958,
 &apos;lengths&apos;: 959,
 &apos;chimpnaut&apos;: 960,
 &apos;corny&apos;: 961,
 &apos;stirring&apos;: 962,
 &apos;tremendous&apos;: 963,
 &apos;tually&apos;: 964,
 &apos;mnage&apos;: 965,
 &apos;ashitaka&apos;: 966,
 &apos;crossbows&apos;: 967,
 &apos;hackery&apos;: 968,
 &apos;riker&apos;: 969,
 &apos;twelve&apos;: 970,
 &apos;freshner&apos;: 971,
 &apos;bobbie&apos;: 972,
 &apos;percussion&apos;: 973,
 &apos;overpopulation&apos;: 974,
 &apos;eeeekkk&apos;: 975,
 &apos;centaury&apos;: 976,
 &apos;summitting&apos;: 977,
 &apos;andbest&apos;: 978,
 &apos;pumping&apos;: 979,
 &apos;somnolent&apos;: 980,
 &apos;infatuation&apos;: 981,
 &apos;shakesphere&apos;: 982,
 &apos;ingred&apos;: 983,
 &apos;moon&apos;: 984,
 &apos;keven&apos;: 985,
 &apos;sanguisuga&apos;: 986,
 &apos;quivers&apos;: 987,
 &apos;equalling&apos;: 988,
 &apos;vaugely&apos;: 989,
 &apos;supervising&apos;: 990,
 &apos;dissolved&apos;: 991,
 &apos;cheshire&apos;: 992,
 &apos;retribution&apos;: 993,
 &apos;cartoons&apos;: 994,
 &apos;maisie&apos;: 995,
 &apos;reptiles&apos;: 996,
 &apos;rsther&apos;: 997,
 &apos;erratically&apos;: 998,
 &apos;hoyt&apos;: 999,
 ...}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_input_layer</span><span class="params">(review)</span>:</span></div><div class="line">    </div><div class="line">    <span class="keyword">global</span> layer_0</div><div class="line">    </div><div class="line">    <span class="comment"># clear out previous state, reset the layer to be all 0s</span></div><div class="line">    layer_0 *= <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">        layer_0[<span class="number">0</span>][word2index[word]] += <span class="number">1</span></div><div class="line"></div><div class="line">update_input_layer(reviews[<span class="number">0</span>])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_0</div></pre></td></tr></table></figure>
<pre><code>array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_target_for_label</span><span class="params">(label)</span>:</span></div><div class="line">    <span class="keyword">if</span>(label == <span class="string">'POSITIVE'</span>):</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">labels[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<pre><code>&apos;POSITIVE&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">get_target_for_label(labels[<span class="number">0</span>])</div></pre></td></tr></table></figure>
<pre><code>1
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">labels[<span class="number">1</span>]</div></pre></td></tr></table></figure>
<pre><code>&apos;NEGATIVE&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">get_target_for_label(labels[<span class="number">1</span>])</div></pre></td></tr></table></figure>
<pre><code>0
</code></pre><h1 id="Project-3-Building-a-Neural-Network"><a href="#Project-3-Building-a-Neural-Network" class="headerlink" title="Project 3: Building a Neural Network"></a>Project 3: Building a Neural Network</h1><ul>
<li>Start with your neural network from the last chapter</li>
<li>3 layer neural network</li>
<li>no non-linearity in hidden layer</li>
<li>use our functions to create the training data</li>
<li>create a “pre_process_data” function to create vocabulary for our training data generating functions</li>
<li>modify “train” to train over the entire corpus</li>
</ul>
<h3 id="Where-to-Get-Help-if-You-Need-it-1"><a href="#Where-to-Get-Help-if-You-Need-it-1" class="headerlink" title="Where to Get Help if You Need it"></a>Where to Get Help if You Need it</h3><ul>
<li>Re-watch previous week’s Udacity Lectures</li>
<li>Chapters 3-5 - <a href="https://www.manning.com/books/grokking-deep-learning" target="_blank" rel="external">Grokking Deep Learning</a> - (40% Off: <strong>traskud17</strong>)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># Let's tweak our network from before to model these phenomena</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SentimentNetwork</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, reviews,labels,hidden_nodes = <span class="number">10</span>, learning_rate = <span class="number">0.1</span>)</span>:</span></div><div class="line">       </div><div class="line">        <span class="comment"># set our random number generator </span></div><div class="line">        np.random.seed(<span class="number">1</span>)</div><div class="line">    </div><div class="line">        self.pre_process_data(reviews, labels)</div><div class="line">        </div><div class="line">        self.init_network(len(self.review_vocab),hidden_nodes, <span class="number">1</span>, learning_rate)</div><div class="line">        </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span><span class="params">(self, reviews, labels)</span>:</span></div><div class="line">        </div><div class="line">        review_vocab = set()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> reviews:</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">                review_vocab.add(word)</div><div class="line">        self.review_vocab = list(review_vocab)</div><div class="line">        </div><div class="line">        label_vocab = set()</div><div class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels:</div><div class="line">            label_vocab.add(label)</div><div class="line">        </div><div class="line">        self.label_vocab = list(label_vocab)</div><div class="line">        </div><div class="line">        self.review_vocab_size = len(self.review_vocab)</div><div class="line">        self.label_vocab_size = len(self.label_vocab)</div><div class="line">        </div><div class="line">        self.word2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(self.review_vocab):</div><div class="line">            self.word2index[word] = i</div><div class="line">        </div><div class="line">        self.label2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(self.label_vocab):</div><div class="line">            self.label2index[label] = i</div><div class="line">         </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">(self, input_nodes, hidden_nodes, output_nodes, learning_rate)</span>:</span></div><div class="line">        <span class="comment"># Set number of nodes in input, hidden and output layers.</span></div><div class="line">        self.input_nodes = input_nodes</div><div class="line">        self.hidden_nodes = hidden_nodes</div><div class="line">        self.output_nodes = output_nodes</div><div class="line"></div><div class="line">        <span class="comment"># Initialize weights</span></div><div class="line">        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))</div><div class="line">    </div><div class="line">        self.weights_1_2 = np.random.normal(<span class="number">0.0</span>, self.output_nodes**<span class="number">-0.5</span>, </div><div class="line">                                                (self.hidden_nodes, self.output_nodes))</div><div class="line">        </div><div class="line">        self.learning_rate = learning_rate</div><div class="line">        </div><div class="line">        self.layer_0 = np.zeros((<span class="number">1</span>,input_nodes))</div><div class="line">    </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_input_layer</span><span class="params">(self,review)</span>:</span></div><div class="line"></div><div class="line">        <span class="comment"># clear out previous state, reset the layer to be all 0s</span></div><div class="line">        self.layer_0 *= <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">            <span class="keyword">if</span>(word <span class="keyword">in</span> self.word2index.keys()):</div><div class="line">                self.layer_0[<span class="number">0</span>][self.word2index[word]] += <span class="number">1</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_target_for_label</span><span class="params">(self,label)</span>:</span></div><div class="line">        <span class="keyword">if</span>(label == <span class="string">'POSITIVE'</span>):</div><div class="line">            <span class="keyword">return</span> <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(self,x)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid_output_2_derivative</span><span class="params">(self,output)</span>:</span></div><div class="line">        <span class="keyword">return</span> output * (<span class="number">1</span> - output)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, training_reviews, training_labels)</span>:</span></div><div class="line">        </div><div class="line">        <span class="keyword">assert</span>(len(training_reviews) == len(training_labels))</div><div class="line">        </div><div class="line">        correct_so_far = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_reviews)):</div><div class="line">            </div><div class="line">            review = training_reviews[i]</div><div class="line">            label = training_labels[i]</div><div class="line">            </div><div class="line">            <span class="comment">#### Implement the forward pass here ####</span></div><div class="line">            <span class="comment">### Forward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># Input Layer</span></div><div class="line">            self.update_input_layer(review)</div><div class="line"></div><div class="line">            <span class="comment"># Hidden layer</span></div><div class="line">            layer_1 = self.layer_0.dot(self.weights_0_1)</div><div class="line"></div><div class="line">            <span class="comment"># Output layer</span></div><div class="line">            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))</div><div class="line"></div><div class="line">            <span class="comment">#### Implement the backward pass here ####</span></div><div class="line">            <span class="comment">### Backward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Output error</span></div><div class="line">            layer_2_error = layer_2 - self.get_target_for_label(label) <span class="comment"># Output layer error is the difference between desired target and actual output.</span></div><div class="line">            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)</div><div class="line"></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Backpropagated error</span></div><div class="line">            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) <span class="comment"># errors propagated to the hidden layer</span></div><div class="line">            layer_1_delta = layer_1_error <span class="comment"># hidden layer gradients - no nonlinearity so it's the same as the error</span></div><div class="line"></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Update the weights</span></div><div class="line">            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate <span class="comment"># update hidden-to-output weights with gradient descent step</span></div><div class="line">            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate <span class="comment"># update input-to-hidden weights with gradient descent step</span></div><div class="line"></div><div class="line">            <span class="keyword">if</span>(np.abs(layer_2_error) &lt; <span class="number">0.5</span>):</div><div class="line">                correct_so_far += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(training_reviews)))[:<span class="number">4</span>] + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] + <span class="string">" #Correct:"</span> + str(correct_so_far) + <span class="string">" #Trained:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Training Accuracy:"</span> + str(correct_so_far * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">            <span class="keyword">if</span>(i % <span class="number">2500</span> == <span class="number">0</span>):</div><div class="line">                print(<span class="string">""</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self, testing_reviews, testing_labels)</span>:</span></div><div class="line">        </div><div class="line">        correct = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testing_reviews)):</div><div class="line">            pred = self.run(testing_reviews[i])</div><div class="line">            <span class="keyword">if</span>(pred == testing_labels[i]):</div><div class="line">                correct += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(testing_reviews)))[:<span class="number">4</span>] \</div><div class="line">                             + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] \</div><div class="line">                            + <span class="string">"% #Correct:"</span> + str(correct) + <span class="string">" #Tested:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Testing Accuracy:"</span> + str(correct * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, review)</span>:</span></div><div class="line">        </div><div class="line">        <span class="comment"># Input Layer</span></div><div class="line">        self.update_input_layer(review.lower())</div><div class="line"></div><div class="line">        <span class="comment"># Hidden layer</span></div><div class="line">        layer_1 = self.layer_0.dot(self.weights_0_1)</div><div class="line"></div><div class="line">        <span class="comment"># Output layer</span></div><div class="line">        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))</div><div class="line">        </div><div class="line">        <span class="keyword">if</span>(layer_2[<span class="number">0</span>] &gt; <span class="number">0.5</span>):</div><div class="line">            <span class="keyword">return</span> <span class="string">"POSITIVE"</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">"NEGATIVE"</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], learning_rate=<span class="number">0.1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># evaluate our model before training (just to show how horrible it is)</span></div><div class="line">mlp.test(reviews[<span class="number">-1000</span>:],labels[<span class="number">-1000</span>:])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):1242.% #Correct:500 #Tested:1000 Testing Accuracy:50.0%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># train the network</span></div><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%
Progress:10.4% Speed(reviews/sec):167.7 #Correct:1250 #Trained:2501 Training Accuracy:49.9%
Progress:20.8% Speed(reviews/sec):170.2 #Correct:2500 #Trained:5001 Training Accuracy:49.9%
Progress:31.2% Speed(reviews/sec):169.9 #Correct:3750 #Trained:7501 Training Accuracy:49.9%
Progress:41.6% Speed(reviews/sec):171.3 #Correct:5000 #Trained:10001 Training Accuracy:49.9%
Progress:52.0% Speed(reviews/sec):170.0 #Correct:6250 #Trained:12501 Training Accuracy:49.9%
Progress:62.5% Speed(reviews/sec):170.8 #Correct:7500 #Trained:15001 Training Accuracy:49.9%
Progress:72.9% Speed(reviews/sec):171.4 #Correct:8750 #Trained:17501 Training Accuracy:49.9%
Progress:83.3% Speed(reviews/sec):171.7 #Correct:10000 #Trained:20001 Training Accuracy:49.9%
Progress:93.7% Speed(reviews/sec):172.6 #Correct:11250 #Trained:22501 Training Accuracy:49.9%
Progress:99.9% Speed(reviews/sec):172.5 #Correct:11999 #Trained:24000 Training Accuracy:49.9%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], learning_rate=<span class="number">0.01</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># train the network</span></div><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%
Progress:10.4% Speed(reviews/sec):149.0 #Correct:1247 #Trained:2501 Training Accuracy:49.8%
Progress:20.8% Speed(reviews/sec):145.3 #Correct:2497 #Trained:5001 Training Accuracy:49.9%
Progress:31.2% Speed(reviews/sec):144.0 #Correct:3747 #Trained:7501 Training Accuracy:49.9%
Progress:41.6% Speed(reviews/sec):141.8 #Correct:4997 #Trained:10001 Training Accuracy:49.9%
Progress:52.0% Speed(reviews/sec):137.0 #Correct:6247 #Trained:12501 Training Accuracy:49.9%
Progress:62.5% Speed(reviews/sec):137.7 #Correct:7489 #Trained:15001 Training Accuracy:49.9%
Progress:72.9% Speed(reviews/sec):137.1 #Correct:8740 #Trained:17501 Training Accuracy:49.9%
Progress:83.3% Speed(reviews/sec):138.1 #Correct:9990 #Trained:20001 Training Accuracy:49.9%
Progress:93.7% Speed(reviews/sec):138.9 #Correct:11240 #Trained:22501 Training Accuracy:49.9%
Progress:99.9% Speed(reviews/sec):139.4 #Correct:11989 #Trained:24000 Training Accuracy:49.9%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], learning_rate=<span class="number">0.001</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># train the network</span></div><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%
Progress:10.4% Speed(reviews/sec):147.5 #Correct:1267 #Trained:2501 Training Accuracy:50.6%
Progress:20.8% Speed(reviews/sec):147.3 #Correct:2608 #Trained:5001 Training Accuracy:52.1%
Progress:31.2% Speed(reviews/sec):147.3 #Correct:4021 #Trained:7501 Training Accuracy:53.6%
Progress:41.6% Speed(reviews/sec):147.3 #Correct:5497 #Trained:10001 Training Accuracy:54.9%
Progress:52.0% Speed(reviews/sec):147.3 #Correct:7071 #Trained:12501 Training Accuracy:56.5%
Progress:62.5% Speed(reviews/sec):146.9 #Correct:8632 #Trained:15001 Training Accuracy:57.5%
Progress:72.9% Speed(reviews/sec):146.9 #Correct:10228 #Trained:17501 Training Accuracy:58.4%
Progress:83.3% Speed(reviews/sec):146.9 #Correct:11880 #Trained:20001 Training Accuracy:59.3%
Progress:93.7% Speed(reviews/sec):147.0 #Correct:13580 #Trained:22501 Training Accuracy:60.3%
Progress:99.9% Speed(reviews/sec):146.9 #Correct:14658 #Trained:24000 Training Accuracy:61.0%
</code></pre><h1 id="Understanding-Neural-Noise"><a href="#Understanding-Neural-Noise" class="headerlink" title="Understanding Neural Noise"></a>Understanding Neural Noise</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</div><div class="line">Image(filename=<span class="string">'sentiment_network.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_45_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_input_layer</span><span class="params">(review)</span>:</span></div><div class="line">    </div><div class="line">    <span class="keyword">global</span> layer_0</div><div class="line">    </div><div class="line">    <span class="comment"># clear out previous state, reset the layer to be all 0s</span></div><div class="line">    layer_0 *= <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">        layer_0[<span class="number">0</span>][word2index[word]] += <span class="number">1</span></div><div class="line"></div><div class="line">update_input_layer(reviews[<span class="number">0</span>])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_0</div></pre></td></tr></table></figure>
<pre><code>array([[ 18.,   0.,   0., ...,   0.,   0.,   0.]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">review_counter = Counter()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> word <span class="keyword">in</span> reviews[<span class="number">0</span>].split(<span class="string">" "</span>):</div><div class="line">    review_counter[word] += <span class="number">1</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">review_counter.most_common()</div></pre></td></tr></table></figure>
<pre><code>[(&apos;.&apos;, 27),
 (&apos;&apos;, 18),
 (&apos;the&apos;, 9),
 (&apos;to&apos;, 6),
 (&apos;high&apos;, 5),
 (&apos;i&apos;, 5),
 (&apos;bromwell&apos;, 4),
 (&apos;is&apos;, 4),
 (&apos;a&apos;, 4),
 (&apos;teachers&apos;, 4),
 (&apos;that&apos;, 4),
 (&apos;of&apos;, 4),
 (&apos;it&apos;, 2),
 (&apos;at&apos;, 2),
 (&apos;as&apos;, 2),
 (&apos;school&apos;, 2),
 (&apos;my&apos;, 2),
 (&apos;in&apos;, 2),
 (&apos;me&apos;, 2),
 (&apos;students&apos;, 2),
 (&apos;their&apos;, 2),
 (&apos;student&apos;, 2),
 (&apos;cartoon&apos;, 1),
 (&apos;comedy&apos;, 1),
 (&apos;ran&apos;, 1),
 (&apos;same&apos;, 1),
 (&apos;time&apos;, 1),
 (&apos;some&apos;, 1),
 (&apos;other&apos;, 1),
 (&apos;programs&apos;, 1),
 (&apos;about&apos;, 1),
 (&apos;life&apos;, 1),
 (&apos;such&apos;, 1),
 (&apos;years&apos;, 1),
 (&apos;teaching&apos;, 1),
 (&apos;profession&apos;, 1),
 (&apos;lead&apos;, 1),
 (&apos;believe&apos;, 1),
 (&apos;s&apos;, 1),
 (&apos;satire&apos;, 1),
 (&apos;much&apos;, 1),
 (&apos;closer&apos;, 1),
 (&apos;reality&apos;, 1),
 (&apos;than&apos;, 1),
 (&apos;scramble&apos;, 1),
 (&apos;survive&apos;, 1),
 (&apos;financially&apos;, 1),
 (&apos;insightful&apos;, 1),
 (&apos;who&apos;, 1),
 (&apos;can&apos;, 1),
 (&apos;see&apos;, 1),
 (&apos;right&apos;, 1),
 (&apos;through&apos;, 1),
 (&apos;pathetic&apos;, 1),
 (&apos;pomp&apos;, 1),
 (&apos;pettiness&apos;, 1),
 (&apos;whole&apos;, 1),
 (&apos;situation&apos;, 1),
 (&apos;all&apos;, 1),
 (&apos;remind&apos;, 1),
 (&apos;schools&apos;, 1),
 (&apos;knew&apos;, 1),
 (&apos;and&apos;, 1),
 (&apos;when&apos;, 1),
 (&apos;saw&apos;, 1),
 (&apos;episode&apos;, 1),
 (&apos;which&apos;, 1),
 (&apos;repeatedly&apos;, 1),
 (&apos;tried&apos;, 1),
 (&apos;burn&apos;, 1),
 (&apos;down&apos;, 1),
 (&apos;immediately&apos;, 1),
 (&apos;recalled&apos;, 1),
 (&apos;classic&apos;, 1),
 (&apos;line&apos;, 1),
 (&apos;inspector&apos;, 1),
 (&apos;m&apos;, 1),
 (&apos;here&apos;, 1),
 (&apos;sack&apos;, 1),
 (&apos;one&apos;, 1),
 (&apos;your&apos;, 1),
 (&apos;welcome&apos;, 1),
 (&apos;expect&apos;, 1),
 (&apos;many&apos;, 1),
 (&apos;adults&apos;, 1),
 (&apos;age&apos;, 1),
 (&apos;think&apos;, 1),
 (&apos;far&apos;, 1),
 (&apos;fetched&apos;, 1),
 (&apos;what&apos;, 1),
 (&apos;pity&apos;, 1),
 (&apos;isn&apos;, 1),
 (&apos;t&apos;, 1)]
</code></pre><h1 id="Project-4-Reducing-Noise-in-our-Input-Data"><a href="#Project-4-Reducing-Noise-in-our-Input-Data" class="headerlink" title="Project 4: Reducing Noise in our Input Data"></a>Project 4: Reducing Noise in our Input Data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># Let's tweak our network from before to model these phenomena</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SentimentNetwork</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, reviews,labels,hidden_nodes = <span class="number">10</span>, learning_rate = <span class="number">0.1</span>)</span>:</span></div><div class="line">       </div><div class="line">        <span class="comment"># set our random number generator </span></div><div class="line">        np.random.seed(<span class="number">1</span>)</div><div class="line">    </div><div class="line">        self.pre_process_data(reviews, labels)</div><div class="line">        </div><div class="line">        self.init_network(len(self.review_vocab),hidden_nodes, <span class="number">1</span>, learning_rate)</div><div class="line">        </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span><span class="params">(self, reviews, labels)</span>:</span></div><div class="line">        </div><div class="line">        review_vocab = set()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> reviews:</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">                review_vocab.add(word)</div><div class="line">        self.review_vocab = list(review_vocab)</div><div class="line">        </div><div class="line">        label_vocab = set()</div><div class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels:</div><div class="line">            label_vocab.add(label)</div><div class="line">        </div><div class="line">        self.label_vocab = list(label_vocab)</div><div class="line">        </div><div class="line">        self.review_vocab_size = len(self.review_vocab)</div><div class="line">        self.label_vocab_size = len(self.label_vocab)</div><div class="line">        </div><div class="line">        self.word2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(self.review_vocab):</div><div class="line">            self.word2index[word] = i</div><div class="line">        </div><div class="line">        self.label2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(self.label_vocab):</div><div class="line">            self.label2index[label] = i</div><div class="line">         </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">(self, input_nodes, hidden_nodes, output_nodes, learning_rate)</span>:</span></div><div class="line">        <span class="comment"># Set number of nodes in input, hidden and output layers.</span></div><div class="line">        self.input_nodes = input_nodes</div><div class="line">        self.hidden_nodes = hidden_nodes</div><div class="line">        self.output_nodes = output_nodes</div><div class="line"></div><div class="line">        <span class="comment"># Initialize weights</span></div><div class="line">        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))</div><div class="line">    </div><div class="line">        self.weights_1_2 = np.random.normal(<span class="number">0.0</span>, self.output_nodes**<span class="number">-0.5</span>, </div><div class="line">                                                (self.hidden_nodes, self.output_nodes))</div><div class="line">        </div><div class="line">        self.learning_rate = learning_rate</div><div class="line">        </div><div class="line">        self.layer_0 = np.zeros((<span class="number">1</span>,input_nodes))</div><div class="line">    </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_input_layer</span><span class="params">(self,review)</span>:</span></div><div class="line"></div><div class="line">        <span class="comment"># clear out previous state, reset the layer to be all 0s</span></div><div class="line">        self.layer_0 *= <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">            <span class="keyword">if</span>(word <span class="keyword">in</span> self.word2index.keys()):</div><div class="line">                self.layer_0[<span class="number">0</span>][self.word2index[word]] = <span class="number">1</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_target_for_label</span><span class="params">(self,label)</span>:</span></div><div class="line">        <span class="keyword">if</span>(label == <span class="string">'POSITIVE'</span>):</div><div class="line">            <span class="keyword">return</span> <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(self,x)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid_output_2_derivative</span><span class="params">(self,output)</span>:</span></div><div class="line">        <span class="keyword">return</span> output * (<span class="number">1</span> - output)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, training_reviews, training_labels)</span>:</span></div><div class="line">        </div><div class="line">        <span class="keyword">assert</span>(len(training_reviews) == len(training_labels))</div><div class="line">        </div><div class="line">        correct_so_far = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_reviews)):</div><div class="line">            </div><div class="line">            review = training_reviews[i]</div><div class="line">            label = training_labels[i]</div><div class="line">            </div><div class="line">            <span class="comment">#### Implement the forward pass here ####</span></div><div class="line">            <span class="comment">### Forward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># Input Layer</span></div><div class="line">            self.update_input_layer(review)</div><div class="line"></div><div class="line">            <span class="comment"># Hidden layer</span></div><div class="line">            layer_1 = self.layer_0.dot(self.weights_0_1)</div><div class="line"></div><div class="line">            <span class="comment"># Output layer</span></div><div class="line">            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))</div><div class="line"></div><div class="line">            <span class="comment">#### Implement the backward pass here ####</span></div><div class="line">            <span class="comment">### Backward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Output error</span></div><div class="line">            layer_2_error = layer_2 - self.get_target_for_label(label) <span class="comment"># Output layer error is the difference between desired target and actual output.</span></div><div class="line">            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)</div><div class="line"></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Backpropagated error</span></div><div class="line">            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) <span class="comment"># errors propagated to the hidden layer</span></div><div class="line">            layer_1_delta = layer_1_error <span class="comment"># hidden layer gradients - no nonlinearity so it's the same as the error</span></div><div class="line"></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Update the weights</span></div><div class="line">            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate <span class="comment"># update hidden-to-output weights with gradient descent step</span></div><div class="line">            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate <span class="comment"># update input-to-hidden weights with gradient descent step</span></div><div class="line"></div><div class="line">            <span class="keyword">if</span>(np.abs(layer_2_error) &lt; <span class="number">0.5</span>):</div><div class="line">                correct_so_far += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(training_reviews)))[:<span class="number">4</span>] + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] + <span class="string">" #Correct:"</span> + str(correct_so_far) + <span class="string">" #Trained:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Training Accuracy:"</span> + str(correct_so_far * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">            <span class="keyword">if</span>(i % <span class="number">2500</span> == <span class="number">0</span>):</div><div class="line">                print(<span class="string">""</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self, testing_reviews, testing_labels)</span>:</span></div><div class="line">        </div><div class="line">        correct = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testing_reviews)):</div><div class="line">            pred = self.run(testing_reviews[i])</div><div class="line">            <span class="keyword">if</span>(pred == testing_labels[i]):</div><div class="line">                correct += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(testing_reviews)))[:<span class="number">4</span>] \</div><div class="line">                             + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] \</div><div class="line">                            + <span class="string">"% #Correct:"</span> + str(correct) + <span class="string">" #Tested:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Testing Accuracy:"</span> + str(correct * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, review)</span>:</span></div><div class="line">        </div><div class="line">        <span class="comment"># Input Layer</span></div><div class="line">        self.update_input_layer(review.lower())</div><div class="line"></div><div class="line">        <span class="comment"># Hidden layer</span></div><div class="line">        layer_1 = self.layer_0.dot(self.weights_0_1)</div><div class="line"></div><div class="line">        <span class="comment"># Output layer</span></div><div class="line">        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))</div><div class="line">        </div><div class="line">        <span class="keyword">if</span>(layer_2[<span class="number">0</span>] &gt; <span class="number">0.5</span>):</div><div class="line">            <span class="keyword">return</span> <span class="string">"POSITIVE"</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">"NEGATIVE"</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], learning_rate=<span class="number">0.1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%
Progress:10.4% Speed(reviews/sec):150.5 #Correct:1770 #Trained:2501 Training Accuracy:70.7%
Progress:20.8% Speed(reviews/sec):150.5 #Correct:3719 #Trained:5001 Training Accuracy:74.3%
Progress:31.2% Speed(reviews/sec):150.2 #Correct:5812 #Trained:7501 Training Accuracy:77.4%
Progress:41.6% Speed(reviews/sec):150.3 #Correct:7932 #Trained:10001 Training Accuracy:79.3%
Progress:52.0% Speed(reviews/sec):150.3 #Correct:10058 #Trained:12501 Training Accuracy:80.4%
Progress:62.5% Speed(reviews/sec):150.2 #Correct:12192 #Trained:15001 Training Accuracy:81.2%
Progress:72.9% Speed(reviews/sec):149.9 #Correct:14313 #Trained:17501 Training Accuracy:81.7%
Progress:83.3% Speed(reviews/sec):149.9 #Correct:16486 #Trained:20001 Training Accuracy:82.4%
Progress:93.7% Speed(reviews/sec):150.0 #Correct:18672 #Trained:22501 Training Accuracy:82.9%
Progress:99.9% Speed(reviews/sec):150.1 #Correct:19999 #Trained:24000 Training Accuracy:83.3%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># evaluate our model before training (just to show how horrible it is)</span></div><div class="line">mlp.test(reviews[<span class="number">-1000</span>:],labels[<span class="number">-1000</span>:])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):1621.% #Correct:858 #Tested:1000 Testing Accuracy:85.8%
</code></pre><h1 id="Analyzing-Inefficiencies-in-our-Network"><a href="#Analyzing-Inefficiencies-in-our-Network" class="headerlink" title="Analyzing Inefficiencies in our Network"></a>Analyzing Inefficiencies in our Network</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Image(filename=<span class="string">'sentiment_network_sparse.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_57_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_0 = np.zeros(<span class="number">10</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_0</div></pre></td></tr></table></figure>
<pre><code>array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">layer_0[<span class="number">4</span>] = <span class="number">1</span></div><div class="line">layer_0[<span class="number">9</span>] = <span class="number">1</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_0</div></pre></td></tr></table></figure>
<pre><code>array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">weights_0_1 = np.random.randn(<span class="number">10</span>,<span class="number">5</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_0.dot(weights_0_1)</div></pre></td></tr></table></figure>
<pre><code>array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">indices = [<span class="number">4</span>,<span class="number">9</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_1 = np.zeros(<span class="number">5</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> index <span class="keyword">in</span> indices:</div><div class="line">    layer_1 += (weights_0_1[index])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">layer_1</div></pre></td></tr></table></figure>
<pre><code>array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Image(filename=<span class="string">'sentiment_network_sparse_2.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_68_0.png" alt="png"></p>
<h1 id="Project-5-Making-our-Network-More-Efficient"><a href="#Project-5-Making-our-Network-More-Efficient" class="headerlink" title="Project 5: Making our Network More Efficient"></a>Project 5: Making our Network More Efficient</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="comment"># Let's tweak our network from before to model these phenomena</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SentimentNetwork</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, reviews,labels,hidden_nodes = <span class="number">10</span>, learning_rate = <span class="number">0.1</span>)</span>:</span></div><div class="line">       </div><div class="line">        np.random.seed(<span class="number">1</span>)</div><div class="line">    </div><div class="line">        self.pre_process_data(reviews)</div><div class="line">        </div><div class="line">        self.init_network(len(self.review_vocab),hidden_nodes, <span class="number">1</span>, learning_rate)</div><div class="line">        </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span><span class="params">(self,reviews)</span>:</span></div><div class="line">        </div><div class="line">        review_vocab = set()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> reviews:</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">                review_vocab.add(word)</div><div class="line">        self.review_vocab = list(review_vocab)</div><div class="line">        </div><div class="line">        label_vocab = set()</div><div class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels:</div><div class="line">            label_vocab.add(label)</div><div class="line">        </div><div class="line">        self.label_vocab = list(label_vocab)</div><div class="line">        </div><div class="line">        self.review_vocab_size = len(self.review_vocab)</div><div class="line">        self.label_vocab_size = len(self.label_vocab)</div><div class="line">        </div><div class="line">        self.word2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(self.review_vocab):</div><div class="line">            self.word2index[word] = i</div><div class="line">        </div><div class="line">        self.label2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(self.label_vocab):</div><div class="line">            self.label2index[label] = i</div><div class="line">         </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">(self, input_nodes, hidden_nodes, output_nodes, learning_rate)</span>:</span></div><div class="line">        <span class="comment"># Set number of nodes in input, hidden and output layers.</span></div><div class="line">        self.input_nodes = input_nodes</div><div class="line">        self.hidden_nodes = hidden_nodes</div><div class="line">        self.output_nodes = output_nodes</div><div class="line"></div><div class="line">        <span class="comment"># Initialize weights</span></div><div class="line">        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))</div><div class="line">    </div><div class="line">        self.weights_1_2 = np.random.normal(<span class="number">0.0</span>, self.output_nodes**<span class="number">-0.5</span>, </div><div class="line">                                                (self.hidden_nodes, self.output_nodes))</div><div class="line">        </div><div class="line">        self.learning_rate = learning_rate</div><div class="line">        </div><div class="line">        self.layer_0 = np.zeros((<span class="number">1</span>,input_nodes))</div><div class="line">        self.layer_1 = np.zeros((<span class="number">1</span>,hidden_nodes))</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(self,x)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid_output_2_derivative</span><span class="params">(self,output)</span>:</span></div><div class="line">        <span class="keyword">return</span> output * (<span class="number">1</span> - output)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_input_layer</span><span class="params">(self,review)</span>:</span></div><div class="line"></div><div class="line">        <span class="comment"># clear out previous state, reset the layer to be all 0s</span></div><div class="line">        self.layer_0 *= <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">            self.layer_0[<span class="number">0</span>][self.word2index[word]] = <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_target_for_label</span><span class="params">(self,label)</span>:</span></div><div class="line">        <span class="keyword">if</span>(label == <span class="string">'POSITIVE'</span>):</div><div class="line">            <span class="keyword">return</span> <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, training_reviews_raw, training_labels)</span>:</span></div><div class="line">        </div><div class="line">        training_reviews = list()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> training_reviews_raw:</div><div class="line">            indices = set()</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">                <span class="keyword">if</span>(word <span class="keyword">in</span> self.word2index.keys()):</div><div class="line">                    indices.add(self.word2index[word])</div><div class="line">            training_reviews.append(list(indices))</div><div class="line">        </div><div class="line">        <span class="keyword">assert</span>(len(training_reviews) == len(training_labels))</div><div class="line">        </div><div class="line">        correct_so_far = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_reviews)):</div><div class="line">            </div><div class="line">            review = training_reviews[i]</div><div class="line">            label = training_labels[i]</div><div class="line">            </div><div class="line">            <span class="comment">#### Implement the forward pass here ####</span></div><div class="line">            <span class="comment">### Forward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># Input Layer</span></div><div class="line"></div><div class="line">            <span class="comment"># Hidden layer</span></div><div class="line"><span class="comment">#             layer_1 = self.layer_0.dot(self.weights_0_1)</span></div><div class="line">            self.layer_1 *= <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> review:</div><div class="line">                self.layer_1 += self.weights_0_1[index]</div><div class="line">            </div><div class="line">            <span class="comment"># Output layer</span></div><div class="line">            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</div><div class="line"></div><div class="line">            <span class="comment">#### Implement the backward pass here ####</span></div><div class="line">            <span class="comment">### Backward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># Output error</span></div><div class="line">            layer_2_error = layer_2 - self.get_target_for_label(label) <span class="comment"># Output layer error is the difference between desired target and actual output.</span></div><div class="line">            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)</div><div class="line"></div><div class="line">            <span class="comment"># Backpropagated error</span></div><div class="line">            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) <span class="comment"># errors propagated to the hidden layer</span></div><div class="line">            layer_1_delta = layer_1_error <span class="comment"># hidden layer gradients - no nonlinearity so it's the same as the error</span></div><div class="line"></div><div class="line">            <span class="comment"># Update the weights</span></div><div class="line">            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate <span class="comment"># update hidden-to-output weights with gradient descent step</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> review:</div><div class="line">                self.weights_0_1[index] -= layer_1_delta[<span class="number">0</span>] * self.learning_rate <span class="comment"># update input-to-hidden weights with gradient descent step</span></div><div class="line"></div><div class="line">            <span class="keyword">if</span>(np.abs(layer_2_error) &lt; <span class="number">0.5</span>):</div><div class="line">                correct_so_far += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(training_reviews)))[:<span class="number">4</span>] + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] + <span class="string">" #Correct:"</span> + str(correct_so_far) + <span class="string">" #Trained:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Training Accuracy:"</span> + str(correct_so_far * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">        </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self, testing_reviews, testing_labels)</span>:</span></div><div class="line">        </div><div class="line">        correct = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testing_reviews)):</div><div class="line">            pred = self.run(testing_reviews[i])</div><div class="line">            <span class="keyword">if</span>(pred == testing_labels[i]):</div><div class="line">                correct += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(testing_reviews)))[:<span class="number">4</span>] \</div><div class="line">                             + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] \</div><div class="line">                            + <span class="string">"% #Correct:"</span> + str(correct) + <span class="string">" #Tested:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Testing Accuracy:"</span> + str(correct * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, review)</span>:</span></div><div class="line">        </div><div class="line">        <span class="comment"># Input Layer</span></div><div class="line"></div><div class="line"></div><div class="line">        <span class="comment"># Hidden layer</span></div><div class="line">        self.layer_1 *= <span class="number">0</span></div><div class="line">        unique_indices = set()</div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> review.lower().split(<span class="string">" "</span>):</div><div class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> self.word2index.keys():</div><div class="line">                unique_indices.add(self.word2index[word])</div><div class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> unique_indices:</div><div class="line">            self.layer_1 += self.weights_0_1[index]</div><div class="line">        </div><div class="line">        <span class="comment"># Output layer</span></div><div class="line">        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</div><div class="line">        </div><div class="line">        <span class="keyword">if</span>(layer_2[<span class="number">0</span>] &gt; <span class="number">0.5</span>):</div><div class="line">            <span class="keyword">return</span> <span class="string">"POSITIVE"</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">"NEGATIVE"</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], learning_rate=<span class="number">0.1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):2564. #Correct:20113 #Trained:24000 Training Accuracy:83.8%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># evaluate our model before training (just to show how horrible it is)</span></div><div class="line">mlp.test(reviews[<span class="number">-1000</span>:],labels[<span class="number">-1000</span>:])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):2995.% #Correct:853 #Tested:1000 Testing Accuracy:85.3%
</code></pre><h1 id="Further-Noise-Reduction"><a href="#Further-Noise-Reduction" class="headerlink" title="Further Noise Reduction"></a>Further Noise Reduction</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Image(filename=<span class="string">'sentiment_network_sparse_2.png'</span>)</div></pre></td></tr></table></figure>
<p><img src="/assets/img/neural_network/output_75_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># words most frequently seen in a review with a "POSITIVE" label</span></div><div class="line">pos_neg_ratios.most_common()</div></pre></td></tr></table></figure>
<pre><code>[(&apos;edie&apos;, 4.6913478822291435),
 (&apos;paulie&apos;, 4.0775374439057197),
 (&apos;felix&apos;, 3.1527360223636558),
 (&apos;polanski&apos;, 2.8233610476132043),
 (&apos;matthau&apos;, 2.8067217286092401),
 (&apos;victoria&apos;, 2.6810215287142909),
 (&apos;mildred&apos;, 2.6026896854443837),
 (&apos;gandhi&apos;, 2.5389738710582761),
 (&apos;flawless&apos;, 2.451005098112319),
 (&apos;superbly&apos;, 2.2600254785752498),
 (&apos;perfection&apos;, 2.1594842493533721),
 (&apos;astaire&apos;, 2.1400661634962708),
 (&apos;captures&apos;, 2.0386195471595809),
 (&apos;voight&apos;, 2.0301704926730531),
 (&apos;wonderfully&apos;, 2.0218960560332353),
 (&apos;powell&apos;, 1.9783454248084671),
 (&apos;brosnan&apos;, 1.9547990964725592),
 (&apos;lily&apos;, 1.9203768470501485),
 (&apos;bakshi&apos;, 1.9029851043382795),
 (&apos;lincoln&apos;, 1.9014583864844796),
 (&apos;refreshing&apos;, 1.8551812956655511),
 (&apos;breathtaking&apos;, 1.8481124057791867),
 (&apos;bourne&apos;, 1.8478489358790986),
 (&apos;lemmon&apos;, 1.8458266904983307),
 (&apos;delightful&apos;, 1.8002701588959635),
 (&apos;flynn&apos;, 1.7996646487351682),
 (&apos;andrews&apos;, 1.7764919970972666),
 (&apos;homer&apos;, 1.7692866133759964),
 (&apos;beautifully&apos;, 1.7626953362841438),
 (&apos;soccer&apos;, 1.7578579175523736),
 (&apos;elvira&apos;, 1.7397031072720019),
 (&apos;underrated&apos;, 1.7197859696029656),
 (&apos;gripping&apos;, 1.7165360479904674),
 (&apos;superb&apos;, 1.7091514458966952),
 (&apos;delight&apos;, 1.6714733033535532),
 (&apos;welles&apos;, 1.6677068205580761),
 (&apos;sadness&apos;, 1.663505133704376),
 (&apos;sinatra&apos;, 1.6389967146756448),
 (&apos;touching&apos;, 1.637217476541176),
 (&apos;timeless&apos;, 1.62924053973028),
 (&apos;macy&apos;, 1.6211339521972916),
 (&apos;unforgettable&apos;, 1.6177367152487956),
 (&apos;favorites&apos;, 1.6158688027643908),
 (&apos;stewart&apos;, 1.6119987332957739),
 (&apos;sullivan&apos;, 1.6094379124341003),
 (&apos;extraordinary&apos;, 1.6094379124341003),
 (&apos;hartley&apos;, 1.6094379124341003),
 (&apos;brilliantly&apos;, 1.5950491749820008),
 (&apos;friendship&apos;, 1.5677652160335325),
 (&apos;wonderful&apos;, 1.5645425925262093),
 (&apos;palma&apos;, 1.5553706911638245),
 (&apos;magnificent&apos;, 1.54663701119507),
 (&apos;finest&apos;, 1.5462590108125689),
 (&apos;jackie&apos;, 1.5439233053234738),
 (&apos;ritter&apos;, 1.5404450409471491),
 (&apos;tremendous&apos;, 1.5184661342283736),
 (&apos;freedom&apos;, 1.5091151908062312),
 (&apos;fantastic&apos;, 1.5048433868558566),
 (&apos;terrific&apos;, 1.5026699370083942),
 (&apos;noir&apos;, 1.493925025312256),
 (&apos;sidney&apos;, 1.493925025312256),
 (&apos;outstanding&apos;, 1.4910053152089213),
 (&apos;pleasantly&apos;, 1.4894785973551214),
 (&apos;mann&apos;, 1.4894785973551214),
 (&apos;nancy&apos;, 1.488077055429833),
 (&apos;marie&apos;, 1.4825711915553104),
 (&apos;marvelous&apos;, 1.4739999415389962),
 (&apos;excellent&apos;, 1.4647538505723599),
 (&apos;ruth&apos;, 1.4596256342054401),
 (&apos;stanwyck&apos;, 1.4412101187160054),
 (&apos;widmark&apos;, 1.4350845252893227),
 (&apos;splendid&apos;, 1.4271163556401458),
 (&apos;chan&apos;, 1.423108334242607),
 (&apos;exceptional&apos;, 1.4201959127955721),
 (&apos;tender&apos;, 1.410986973710262),
 (&apos;gentle&apos;, 1.4078005663408544),
 (&apos;poignant&apos;, 1.4022947024663317),
 (&apos;gem&apos;, 1.3932148039644643),
 (&apos;amazing&apos;, 1.3919815802404802),
 (&apos;chilling&apos;, 1.3862943611198906),
 (&apos;fisher&apos;, 1.3862943611198906),
 (&apos;davies&apos;, 1.3862943611198906),
 (&apos;captivating&apos;, 1.3862943611198906),
 (&apos;darker&apos;, 1.3652409519220583),
 (&apos;april&apos;, 1.3499267169490159),
 (&apos;kelly&apos;, 1.3461743673304654),
 (&apos;blake&apos;, 1.3418425985490567),
 (&apos;overlooked&apos;, 1.329135947279942),
 (&apos;ralph&apos;, 1.32818673031261),
 (&apos;bette&apos;, 1.3156767939059373),
 (&apos;hoffman&apos;, 1.3150668518315229),
 (&apos;cole&apos;, 1.3121863889661687),
 (&apos;shines&apos;, 1.3049487216659381),
 (&apos;powerful&apos;, 1.2999662776313934),
 (&apos;notch&apos;, 1.2950456896547455),
 (&apos;remarkable&apos;, 1.2883688239495823),
 (&apos;pitt&apos;, 1.286210902562908),
 (&apos;winters&apos;, 1.2833463918674481),
 (&apos;vivid&apos;, 1.2762934659055623),
 (&apos;gritty&apos;, 1.2757524867200667),
 (&apos;giallo&apos;, 1.2745029551317739),
 (&apos;portrait&apos;, 1.2704625455947689),
 (&apos;innocence&apos;, 1.2694300209805796),
 (&apos;psychiatrist&apos;, 1.2685113254635072),
 (&apos;favorite&apos;, 1.2668956297860055),
 (&apos;ensemble&apos;, 1.2656663733312759),
 (&apos;stunning&apos;, 1.2622417124499117),
 (&apos;burns&apos;, 1.259880436264232),
 (&apos;garbo&apos;, 1.258954938743289),
 (&apos;barbara&apos;, 1.2580400255962119),
 (&apos;philip&apos;, 1.2527629684953681),
 (&apos;panic&apos;, 1.2527629684953681),
 (&apos;holly&apos;, 1.2527629684953681),
 (&apos;carol&apos;, 1.2481440226390734),
 (&apos;perfect&apos;, 1.246742480713785),
 (&apos;appreciated&apos;, 1.2462482874741743),
 (&apos;favourite&apos;, 1.2411123512753928),
 (&apos;journey&apos;, 1.2367626271489269),
 (&apos;rural&apos;, 1.235471471385307),
 (&apos;bond&apos;, 1.2321436812926323),
 (&apos;builds&apos;, 1.2305398317106577),
 (&apos;brilliant&apos;, 1.2287554137664785),
 (&apos;brooklyn&apos;, 1.2286654169163074),
 (&apos;von&apos;, 1.225175011976539),
 (&apos;recommended&apos;, 1.2163953243244932),
 (&apos;unfolds&apos;, 1.2163953243244932),
 (&apos;daniel&apos;, 1.20215296760895),
 (&apos;perfectly&apos;, 1.1971931173405572),
 (&apos;crafted&apos;, 1.1962507582320256),
 (&apos;prince&apos;, 1.1939224684724346),
 (&apos;troubled&apos;, 1.192138346678933),
 (&apos;consequences&apos;, 1.1865810616140668),
 (&apos;haunting&apos;, 1.1814999484738773),
 (&apos;cinderella&apos;, 1.180052620608284),
 (&apos;alexander&apos;, 1.1759989522835299),
 (&apos;emotions&apos;, 1.1753049094563641),
 (&apos;boxing&apos;, 1.1735135968412274),
 (&apos;subtle&apos;, 1.1734135017508081),
 (&apos;curtis&apos;, 1.1649873576129823),
 (&apos;rare&apos;, 1.1566438362402944),
 (&apos;loved&apos;, 1.1563661500586044),
 (&apos;daughters&apos;, 1.1526795099383853),
 (&apos;courage&apos;, 1.1438688802562305),
 (&apos;dentist&apos;, 1.1426722784621401),
 (&apos;highly&apos;, 1.1420208631618658),
 (&apos;nominated&apos;, 1.1409146683587992),
 (&apos;tony&apos;, 1.1397491942285991),
 (&apos;draws&apos;, 1.1325138403437911),
 (&apos;everyday&apos;, 1.1306150197542835),
 (&apos;contrast&apos;, 1.1284652518177909),
 (&apos;cried&apos;, 1.1213405397456659),
 (&apos;fabulous&apos;, 1.1210851445201684),
 (&apos;ned&apos;, 1.120591195386885),
 (&apos;fay&apos;, 1.120591195386885),
 (&apos;emma&apos;, 1.1184149159642893),
 (&apos;sensitive&apos;, 1.113318436057805),
 (&apos;smooth&apos;, 1.1089750757036563),
 (&apos;dramas&apos;, 1.1080910326226534),
 (&apos;today&apos;, 1.1050431789984001),
 (&apos;helps&apos;, 1.1023091505494358),
 (&apos;inspiring&apos;, 1.0986122886681098),
 (&apos;jimmy&apos;, 1.0937696641923216),
 (&apos;awesome&apos;, 1.0931328229034842),
 (&apos;unique&apos;, 1.0881409888008142),
 (&apos;tragic&apos;, 1.0871835928444868),
 (&apos;intense&apos;, 1.0870514662670339),
 (&apos;stellar&apos;, 1.0857088838322018),
 (&apos;rival&apos;, 1.0822184788924332),
 (&apos;provides&apos;, 1.0797081340289569),
 (&apos;depression&apos;, 1.0782034170369026),
 (&apos;shy&apos;, 1.0775588794702773),
 (&apos;carrie&apos;, 1.076139432816051),
 (&apos;blend&apos;, 1.0753554265038423),
 (&apos;hank&apos;, 1.0736109864626924),
 (&apos;diana&apos;, 1.0726368022648489),
 (&apos;adorable&apos;, 1.0726368022648489),
 (&apos;unexpected&apos;, 1.0722255334949147),
 (&apos;achievement&apos;, 1.0668635903535293),
 (&apos;bettie&apos;, 1.0663514264498881),
 (&apos;happiness&apos;, 1.0632729222228008),
 (&apos;glorious&apos;, 1.0608719606852626),
 (&apos;davis&apos;, 1.0541605260972757),
 (&apos;terrifying&apos;, 1.0525211814678428),
 (&apos;beauty&apos;, 1.050410186850232),
 (&apos;ideal&apos;, 1.0479685558493548),
 (&apos;fears&apos;, 1.0467872208035236),
 (&apos;hong&apos;, 1.0438040521731147),
 (&apos;seasons&apos;, 1.0433496099930604),
 (&apos;fascinating&apos;, 1.0414538748281612),
 (&apos;carries&apos;, 1.0345904299031787),
 (&apos;satisfying&apos;, 1.0321225473992768),
 (&apos;definite&apos;, 1.0319209141694374),
 (&apos;touched&apos;, 1.0296194171811581),
 (&apos;greatest&apos;, 1.0248947127715422),
 (&apos;creates&apos;, 1.0241097613701886),
 (&apos;aunt&apos;, 1.023388867430522),
 (&apos;walter&apos;, 1.022328983918479),
 (&apos;spectacular&apos;, 1.0198314108149955),
 (&apos;portrayal&apos;, 1.0189810189761024),
 (&apos;ann&apos;, 1.0127808528183286),
 (&apos;enterprise&apos;, 1.0116009116784799),
 (&apos;musicals&apos;, 1.0096648026516135),
 (&apos;deeply&apos;, 1.0094845087721023),
 (&apos;incredible&apos;, 1.0061677561461084),
 (&apos;mature&apos;, 1.0060195018402847),
 (&apos;triumph&apos;, 0.99682959435816731),
 (&apos;margaret&apos;, 0.99682959435816731),
 (&apos;navy&apos;, 0.99493385919326827),
 (&apos;harry&apos;, 0.99176919305006062),
 (&apos;lucas&apos;, 0.990398704027877),
 (&apos;sweet&apos;, 0.98966110487955483),
 (&apos;joey&apos;, 0.98794672078059009),
 (&apos;oscar&apos;, 0.98721905111049713),
 (&apos;balance&apos;, 0.98649499054740353),
 (&apos;warm&apos;, 0.98485340331145166),
 (&apos;ages&apos;, 0.98449898190068863),
 (&apos;guilt&apos;, 0.98082925301172619),
 (&apos;glover&apos;, 0.98082925301172619),
 (&apos;carrey&apos;, 0.98082925301172619),
 (&apos;learns&apos;, 0.97881108885548895),
 (&apos;unusual&apos;, 0.97788374278196932),
 (&apos;sons&apos;, 0.97777581552483595),
 (&apos;complex&apos;, 0.97761897738147796),
 (&apos;essence&apos;, 0.97753435711487369),
 (&apos;brazil&apos;, 0.9769153536905899),
 (&apos;widow&apos;, 0.97650959186720987),
 (&apos;solid&apos;, 0.97537964824416146),
 (&apos;beautiful&apos;, 0.97326301262841053),
 (&apos;holmes&apos;, 0.97246100334120955),
 (&apos;awe&apos;, 0.97186058302896583),
 (&apos;vhs&apos;, 0.97116734209998934),
 (&apos;eerie&apos;, 0.97116734209998934),
 (&apos;lonely&apos;, 0.96873720724669754),
 (&apos;grim&apos;, 0.96873720724669754),
 (&apos;sport&apos;, 0.96825047080486615),
 (&apos;debut&apos;, 0.96508089604358704),
 (&apos;destiny&apos;, 0.96343751029985703),
 (&apos;thrillers&apos;, 0.96281074750904794),
 (&apos;tears&apos;, 0.95977584381389391),
 (&apos;rose&apos;, 0.95664202739772253),
 (&apos;feelings&apos;, 0.95551144502743635),
 (&apos;ginger&apos;, 0.95551144502743635),
 (&apos;winning&apos;, 0.95471810900804055),
 (&apos;stanley&apos;, 0.95387344302319799),
 (&apos;cox&apos;, 0.95343027882361187),
 (&apos;paris&apos;, 0.95278479030472663),
 (&apos;heart&apos;, 0.95238806924516806),
 (&apos;hooked&apos;, 0.95155887071161305),
 (&apos;comfortable&apos;, 0.94803943018873538),
 (&apos;mgm&apos;, 0.94446160884085151),
 (&apos;masterpiece&apos;, 0.94155039863339296),
 (&apos;themes&apos;, 0.94118828349588235),
 (&apos;danny&apos;, 0.93967118051821874),
 (&apos;anime&apos;, 0.93378388932167222),
 (&apos;perry&apos;, 0.93328830824272613),
 (&apos;joy&apos;, 0.93301752567946861),
 (&apos;lovable&apos;, 0.93081883243706487),
 (&apos;mysteries&apos;, 0.92953595862417571),
 (&apos;hal&apos;, 0.92953595862417571),
 (&apos;louis&apos;, 0.92871325187271225),
 (&apos;charming&apos;, 0.92520609553210742),
 (&apos;urban&apos;, 0.92367083917177761),
 (&apos;allows&apos;, 0.92183091224977043),
 (&apos;impact&apos;, 0.91815814604895041),
 (&apos;italy&apos;, 0.91629073187415511),
 (&apos;gradually&apos;, 0.91629073187415511),
 (&apos;lifestyle&apos;, 0.91629073187415511),
 (&apos;spy&apos;, 0.91289514287301687),
 (&apos;treat&apos;, 0.91193342650519937),
 (&apos;subsequent&apos;, 0.91056005716517008),
 (&apos;kennedy&apos;, 0.90981821736853763),
 (&apos;loving&apos;, 0.90967549275543591),
 (&apos;surprising&apos;, 0.90937028902958128),
 (&apos;quiet&apos;, 0.90648673177753425),
 (&apos;winter&apos;, 0.90624039602065365),
 (&apos;reveals&apos;, 0.90490540964902977),
 (&apos;raw&apos;, 0.90445627422715225),
 (&apos;funniest&apos;, 0.90078654533818991),
 (&apos;pleased&apos;, 0.89994159387262562),
 (&apos;norman&apos;, 0.89994159387262562),
 (&apos;thief&apos;, 0.89874642222324552),
 (&apos;season&apos;, 0.89827222637147675),
 (&apos;secrets&apos;, 0.89794159320595857),
 (&apos;colorful&apos;, 0.89705936994626756),
 (&apos;highest&apos;, 0.8967461358011849),
 (&apos;compelling&apos;, 0.89462923509297576),
 (&apos;danes&apos;, 0.89248008318043659),
 (&apos;castle&apos;, 0.88967708335606499),
 (&apos;kudos&apos;, 0.88889175768604067),
 (&apos;great&apos;, 0.88810470901464589),
 (&apos;baseball&apos;, 0.88730319500090271),
 (&apos;subtitles&apos;, 0.88730319500090271),
 (&apos;bleak&apos;, 0.88730319500090271),
 (&apos;winner&apos;, 0.88643776872447388),
 (&apos;tragedy&apos;, 0.88563699078315261),
 (&apos;todd&apos;, 0.88551907320740142),
 (&apos;nicely&apos;, 0.87924946019380601),
 (&apos;arthur&apos;, 0.87546873735389985),
 (&apos;essential&apos;, 0.87373111745535925),
 (&apos;gorgeous&apos;, 0.8731725250935497),
 (&apos;fonda&apos;, 0.87294029100054127),
 (&apos;eastwood&apos;, 0.87139541196626402),
 (&apos;focuses&apos;, 0.87082835779739776),
 (&apos;enjoyed&apos;, 0.87070195951624607),
 (&apos;natural&apos;, 0.86997924506912838),
 (&apos;intensity&apos;, 0.86835126958503595),
 (&apos;witty&apos;, 0.86824103423244681),
 (&apos;rob&apos;, 0.8642954367557748),
 (&apos;worlds&apos;, 0.86377269759070874),
 (&apos;health&apos;, 0.86113891179907498),
 (&apos;magical&apos;, 0.85953791528170564),
 (&apos;deeper&apos;, 0.85802182375017932),
 (&apos;lucy&apos;, 0.85618680780444956),
 (&apos;moving&apos;, 0.85566611005772031),
 (&apos;lovely&apos;, 0.85290640004681306),
 (&apos;purple&apos;, 0.8513711857748395),
 (&apos;memorable&apos;, 0.84801189112086062),
 (&apos;sings&apos;, 0.84729786038720367),
 (&apos;craig&apos;, 0.84342938360928321),
 (&apos;modesty&apos;, 0.84342938360928321),
 (&apos;relate&apos;, 0.84326559685926517),
 (&apos;episodes&apos;, 0.84223712084137292),
 (&apos;strong&apos;, 0.84167135777060931),
 (&apos;smith&apos;, 0.83959811108590054),
 (&apos;tear&apos;, 0.83704136022001441),
 (&apos;apartment&apos;, 0.83333115290549531),
 (&apos;princess&apos;, 0.83290912293510388),
 (&apos;disagree&apos;, 0.83290912293510388),
 (&apos;kung&apos;, 0.83173334384609199),
 (&apos;adventure&apos;, 0.83150561393278388),
 (&apos;columbo&apos;, 0.82667857318446791),
 (&apos;jake&apos;, 0.82667857318446791),
 (&apos;adds&apos;, 0.82485652591452319),
 (&apos;hart&apos;, 0.82472353834866463),
 (&apos;strength&apos;, 0.82417544296634937),
 (&apos;realizes&apos;, 0.82360006895738058),
 (&apos;dave&apos;, 0.8232003088081431),
 (&apos;childhood&apos;, 0.82208086393583857),
 (&apos;forbidden&apos;, 0.81989888619908913),
 (&apos;tight&apos;, 0.81883539572344199),
 (&apos;surreal&apos;, 0.8178506590609026),
 (&apos;manager&apos;, 0.81770990320170756),
 (&apos;dancer&apos;, 0.81574950265227764),
 (&apos;studios&apos;, 0.81093021621632877),
 (&apos;con&apos;, 0.81093021621632877),
 (&apos;miike&apos;, 0.80821651034473263),
 (&apos;realistic&apos;, 0.80807714723392232),
 (&apos;explicit&apos;, 0.80792269515237358),
 (&apos;kurt&apos;, 0.8060875917405409),
 (&apos;traditional&apos;, 0.80535917116687328),
 (&apos;deals&apos;, 0.80535917116687328),
 (&apos;holds&apos;, 0.80493858654806194),
 (&apos;carl&apos;, 0.80437281567016972),
 (&apos;touches&apos;, 0.80396154690023547),
 (&apos;gene&apos;, 0.80314807577427383),
 (&apos;albert&apos;, 0.8027669055771679),
 (&apos;abc&apos;, 0.80234647252493729),
 (&apos;cry&apos;, 0.80011930011211307),
 (&apos;sides&apos;, 0.7995275841185171),
 (&apos;develops&apos;, 0.79850769621777162),
 (&apos;eyre&apos;, 0.79850769621777162),
 (&apos;dances&apos;, 0.79694397424158891),
 (&apos;oscars&apos;, 0.79633141679517616),
 (&apos;legendary&apos;, 0.79600456599965308),
 (&apos;hearted&apos;, 0.79492987486988764),
 (&apos;importance&apos;, 0.79492987486988764),
 (&apos;portraying&apos;, 0.79356592830699269),
 (&apos;impressed&apos;, 0.79258107754813223),
 (&apos;waters&apos;, 0.79112758892014912),
 (&apos;empire&apos;, 0.79078565012386137),
 (&apos;edge&apos;, 0.789774016249017),
 (&apos;jean&apos;, 0.78845736036427028),
 (&apos;environment&apos;, 0.78845736036427028),
 (&apos;sentimental&apos;, 0.7864791203521645),
 (&apos;captured&apos;, 0.78623760362595729),
 (&apos;styles&apos;, 0.78592891401091158),
 (&apos;daring&apos;, 0.78592891401091158),
 (&apos;frank&apos;, 0.78275933924963248),
 (&apos;tense&apos;, 0.78275933924963248),
 (&apos;backgrounds&apos;, 0.78275933924963248),
 (&apos;matches&apos;, 0.78275933924963248),
 (&apos;gothic&apos;, 0.78209466657644144),
 (&apos;sharp&apos;, 0.7814397877056235),
 (&apos;achieved&apos;, 0.78015855754957497),
 (&apos;court&apos;, 0.77947526404844247),
 (&apos;steals&apos;, 0.7789140023173704),
 (&apos;rules&apos;, 0.77844476107184035),
 (&apos;colors&apos;, 0.77684619943659217),
 (&apos;reunion&apos;, 0.77318988823348167),
 (&apos;covers&apos;, 0.77139937745969345),
 (&apos;tale&apos;, 0.77010822169607374),
 (&apos;rain&apos;, 0.7683706017975328),
 (&apos;denzel&apos;, 0.76804848873306297),
 (&apos;stays&apos;, 0.76787072675588186),
 (&apos;blob&apos;, 0.76725515271366718),
 (&apos;maria&apos;, 0.76214005204689672),
 (&apos;conventional&apos;, 0.76214005204689672),
 (&apos;fresh&apos;, 0.76158434211317383),
 (&apos;midnight&apos;, 0.76096977689870637),
 (&apos;landscape&apos;, 0.75852993982279704),
 (&apos;animated&apos;, 0.75768570169751648),
 (&apos;titanic&apos;, 0.75666058628227129),
 (&apos;sunday&apos;, 0.75666058628227129),
 (&apos;spring&apos;, 0.7537718023763802),
 (&apos;cagney&apos;, 0.7537718023763802),
 (&apos;enjoyable&apos;, 0.75246375771636476),
 (&apos;immensely&apos;, 0.75198768058287868),
 (&apos;sir&apos;, 0.7507762933965817),
 (&apos;nevertheless&apos;, 0.75067102469813185),
 (&apos;driven&apos;, 0.74994477895307854),
 (&apos;performances&apos;, 0.74883252516063137),
 (&apos;memories&apos;, 0.74721440183022114),
 (&apos;nowadays&apos;, 0.74721440183022114),
 (&apos;simple&apos;, 0.74641420974143258),
 (&apos;golden&apos;, 0.74533293373051557),
 (&apos;leslie&apos;, 0.74533293373051557),
 (&apos;lovers&apos;, 0.74497224842453125),
 (&apos;relationship&apos;, 0.74484232345601786),
 (&apos;supporting&apos;, 0.74357803418683721),
 (&apos;che&apos;, 0.74262723782331497),
 (&apos;packed&apos;, 0.7410032017375805),
 (&apos;trek&apos;, 0.74021469141793106),
 (&apos;provoking&apos;, 0.73840377214806618),
 (&apos;strikes&apos;, 0.73759894313077912),
 (&apos;depiction&apos;, 0.73682224406260699),
 (&apos;emotional&apos;, 0.73678211645681524),
 (&apos;secretary&apos;, 0.7366322924996842),
 (&apos;influenced&apos;, 0.73511137965897755),
 (&apos;florida&apos;, 0.73511137965897755),
 (&apos;germany&apos;, 0.73288750920945944),
 (&apos;brings&apos;, 0.73142936713096229),
 (&apos;lewis&apos;, 0.73129894652432159),
 (&apos;elderly&apos;, 0.73088750854279239),
 (&apos;owner&apos;, 0.72743625403857748),
 (&apos;streets&apos;, 0.72666987259858895),
 (&apos;henry&apos;, 0.72642196944481741),
 (&apos;portrays&apos;, 0.72593700338293632),
 (&apos;bears&apos;, 0.7252354951114458),
 (&apos;china&apos;, 0.72489587887452556),
 (&apos;anger&apos;, 0.72439972406404984),
 (&apos;society&apos;, 0.72433010799663333),
 (&apos;available&apos;, 0.72415741730250549),
 (&apos;best&apos;, 0.72347034060446314),
 (&apos;bugs&apos;, 0.72270598280148979),
 (&apos;magic&apos;, 0.71878961117328299),
 (&apos;delivers&apos;, 0.71846498854423513),
 (&apos;verhoeven&apos;, 0.71846498854423513),
 (&apos;jim&apos;, 0.71783979315031676),
 (&apos;donald&apos;, 0.71667767797013937),
 (&apos;endearing&apos;, 0.71465338578090898),
 (&apos;relationships&apos;, 0.71393795022901896),
 (&apos;greatly&apos;, 0.71256526641704687),
 (&apos;charlie&apos;, 0.71024161391924534),
 (&apos;brad&apos;, 0.71024161391924534),
 (&apos;simon&apos;, 0.70967648251115578),
 (&apos;effectively&apos;, 0.70914752190638641),
 (&apos;march&apos;, 0.70774597998109789),
 (&apos;atmosphere&apos;, 0.70744773070214162),
 (&apos;influence&apos;, 0.70733181555190172),
 (&apos;genius&apos;, 0.706392407309966),
 (&apos;emotionally&apos;, 0.70556970055850243),
 (&apos;ken&apos;, 0.70526854109229009),
 (&apos;identity&apos;, 0.70484322032313651),
 (&apos;sophisticated&apos;, 0.70470800296102132),
 (&apos;dan&apos;, 0.70457587638356811),
 (&apos;andrew&apos;, 0.70329955202396321),
 (&apos;india&apos;, 0.70144598337464037),
 (&apos;roy&apos;, 0.69970458110610434),
 (&apos;surprisingly&apos;, 0.6995780708902356),
 (&apos;sky&apos;, 0.69780919366575667),
 (&apos;romantic&apos;, 0.69664981111114743),
 (&apos;match&apos;, 0.69566924999265523),
 (&apos;meets&apos;, 0.69314718055994529),
 (&apos;cowboy&apos;, 0.69314718055994529),
 (&apos;wave&apos;, 0.69314718055994529),
 (&apos;bitter&apos;, 0.69314718055994529),
 (&apos;patient&apos;, 0.69314718055994529),
 (&apos;stylish&apos;, 0.69314718055994529),
 (&apos;britain&apos;, 0.69314718055994529),
 (&apos;affected&apos;, 0.69314718055994529),
 (&apos;beatty&apos;, 0.69314718055994529),
 (&apos;love&apos;, 0.69198533541937324),
 (&apos;paul&apos;, 0.68980827929443067),
 (&apos;andy&apos;, 0.68846333124751902),
 (&apos;performance&apos;, 0.68797386327972465),
 (&apos;patrick&apos;, 0.68645819240914863),
 (&apos;unlike&apos;, 0.68546468438792907),
 (&apos;brooks&apos;, 0.68433655087779044),
 (&apos;refuses&apos;, 0.68348526964820844),
 (&apos;award&apos;, 0.6824518914431974),
 (&apos;complaint&apos;, 0.6824518914431974),
 (&apos;ride&apos;, 0.68229716453587952),
 (&apos;dawson&apos;, 0.68171848473632257),
 (&apos;luke&apos;, 0.68158635815886937),
 (&apos;wells&apos;, 0.68087708796813096),
 (&apos;france&apos;, 0.6804081547825156),
 (&apos;sports&apos;, 0.68007509899259255),
 (&apos;handsome&apos;, 0.68007509899259255),
 (&apos;directs&apos;, 0.67875844310784572),
 (&apos;rebel&apos;, 0.67875844310784572),
 (&apos;greater&apos;, 0.67605274720064523),
 (&apos;dreams&apos;, 0.67599410133369586),
 (&apos;effective&apos;, 0.67565402311242806),
 (&apos;interpretation&apos;, 0.67479804189174875),
 (&apos;works&apos;, 0.67445504754779284),
 (&apos;brando&apos;, 0.67445504754779284),
 (&apos;noble&apos;, 0.6737290947028437),
 (&apos;paced&apos;, 0.67314651385327573),
 (&apos;le&apos;, 0.67067432470788668),
 (&apos;master&apos;, 0.67015766233524654),
 (&apos;h&apos;, 0.6696166831497512),
 (&apos;rings&apos;, 0.66904962898088483),
 (&apos;easy&apos;, 0.66895995494594152),
 (&apos;city&apos;, 0.66820823221269321),
 (&apos;sunshine&apos;, 0.66782937257565544),
 (&apos;succeeds&apos;, 0.66647893347778397),
 (&apos;relations&apos;, 0.664159643686693),
 (&apos;england&apos;, 0.66387679825983203),
 (&apos;glimpse&apos;, 0.66329421741026418),
 (&apos;aired&apos;, 0.66268797307523675),
 (&apos;sees&apos;, 0.66263163663399482),
 (&apos;both&apos;, 0.66248336767382998),
 (&apos;definitely&apos;, 0.66199789483898808),
 (&apos;imaginative&apos;, 0.66139848224536502),
 (&apos;appreciate&apos;, 0.66083893732728749),
 (&apos;tricks&apos;, 0.66071190480679143),
 (&apos;striking&apos;, 0.66071190480679143),
 (&apos;carefully&apos;, 0.65999497324304479),
 (&apos;complicated&apos;, 0.65981076029235353),
 (&apos;perspective&apos;, 0.65962448852130173),
 (&apos;trilogy&apos;, 0.65877953705573755),
 (&apos;future&apos;, 0.65834665141052828),
 (&apos;lion&apos;, 0.65742909795786608),
 (&apos;douglas&apos;, 0.65540685257709819),
 (&apos;victor&apos;, 0.65540685257709819),
 (&apos;inspired&apos;, 0.65459851044271034),
 (&apos;marriage&apos;, 0.65392646740666405),
 (&apos;demands&apos;, 0.65392646740666405),
 (&apos;father&apos;, 0.65172321672194655),
 (&apos;page&apos;, 0.65123628494430852),
 (&apos;instant&apos;, 0.65058756614114943),
 (&apos;era&apos;, 0.6495567444850836),
 (&apos;ruthless&apos;, 0.64934455790155243),
 (&apos;saga&apos;, 0.64934455790155243),
 (&apos;joan&apos;, 0.64891392558311978),
 (&apos;joseph&apos;, 0.64841128671855386),
 (&apos;workers&apos;, 0.64829661439459352),
 (&apos;fantasy&apos;, 0.64726757480925168),
 (&apos;distant&apos;, 0.64551913157069074),
 (&apos;accomplished&apos;, 0.64551913157069074),
 (&apos;manhattan&apos;, 0.64435701639051324),
 (&apos;personal&apos;, 0.64355023942057321),
 (&apos;meeting&apos;, 0.64313675998528386),
 (&apos;individual&apos;, 0.64313675998528386),
 (&apos;pushing&apos;, 0.64313675998528386),
 (&apos;pleasant&apos;, 0.64250344774119039),
 (&apos;brave&apos;, 0.64185388617239469),
 (&apos;william&apos;, 0.64083139119578469),
 (&apos;hudson&apos;, 0.64077919504262937),
 (&apos;friendly&apos;, 0.63949446706762514),
 (&apos;eccentric&apos;, 0.63907995928966954),
 (&apos;awards&apos;, 0.63875310849414646),
 (&apos;jack&apos;, 0.63838309514997038),
 (&apos;seeking&apos;, 0.63808740337691783),
 (&apos;divorce&apos;, 0.63757732940513456),
 (&apos;colonel&apos;, 0.63757732940513456),
 (&apos;jane&apos;, 0.63443957973316734),
 (&apos;keeping&apos;, 0.63414883979798953),
 (&apos;gives&apos;, 0.63383568159497883),
 (&apos;ted&apos;, 0.63342794585832296),
 (&apos;animation&apos;, 0.63208692379869902),
 (&apos;progress&apos;, 0.6317782341836532),
 (&apos;larger&apos;, 0.63127177684185776),
 (&apos;concert&apos;, 0.63127177684185776),
 (&apos;nation&apos;, 0.6296337748376194),
 (&apos;albeit&apos;, 0.62739580299716491),
 (&apos;adapted&apos;, 0.62613647027698516),
 (&apos;discovers&apos;, 0.62542900650499444),
 (&apos;classic&apos;, 0.62504956428050518),
 (&apos;segment&apos;, 0.62335141862440335),
 (&apos;morgan&apos;, 0.62303761437291871),
 (&apos;mouse&apos;, 0.62294292188669675),
 (&apos;impressive&apos;, 0.62211140744319349),
 (&apos;artist&apos;, 0.62168821657780038),
 (&apos;ultimate&apos;, 0.62168821657780038),
 (&apos;griffith&apos;, 0.62117368093485603),
 (&apos;drew&apos;, 0.62082651898031915),
 (&apos;emily&apos;, 0.62082651898031915),
 (&apos;moved&apos;, 0.6197197120051281),
 (&apos;families&apos;, 0.61903920840622351),
 (&apos;profound&apos;, 0.61903920840622351),
 (&apos;innocent&apos;, 0.61851219917136446),
 (&apos;versions&apos;, 0.61730910416844087),
 (&apos;eddie&apos;, 0.61691981517206107),
 (&apos;criticism&apos;, 0.61651395453902935),
 (&apos;nature&apos;, 0.61594514653194088),
 (&apos;recognized&apos;, 0.61518563909023349),
 (&apos;sexuality&apos;, 0.61467556511845012),
 (&apos;contract&apos;, 0.61400986000122149),
 (&apos;brian&apos;, 0.61344043794920278),
 (&apos;remembered&apos;, 0.6131044728864089),
 (&apos;determined&apos;, 0.6123858239154869),
 (&apos;offers&apos;, 0.61207935747116349),
 (&apos;pleasure&apos;, 0.61195702582993206),
 (&apos;washington&apos;, 0.61180154110599294),
 (&apos;images&apos;, 0.61159731359583758),
 (&apos;games&apos;, 0.61067095873570676),
 (&apos;academy&apos;, 0.60872983874736208),
 (&apos;fashioned&apos;, 0.60798937221963845),
 (&apos;melodrama&apos;, 0.60749173598145145),
 (&apos;rough&apos;, 0.60613580357031549),
 (&apos;charismatic&apos;, 0.60613580357031549),
 (&apos;peoples&apos;, 0.60613580357031549),
 (&apos;dealing&apos;, 0.60517840761398811),
 (&apos;fine&apos;, 0.60496962268013299),
 (&apos;tap&apos;, 0.60391604683200273),
 (&apos;trio&apos;, 0.60157998703445481),
 (&apos;russell&apos;, 0.60120968523425966),
 (&apos;figures&apos;, 0.60077386042893011),
 (&apos;ward&apos;, 0.60005675749393339),
 (&apos;shine&apos;, 0.59911823091166894),
 (&apos;brady&apos;, 0.59911823091166894),
 (&apos;job&apos;, 0.59845562125168661),
 (&apos;satisfied&apos;, 0.59652034487087369),
 (&apos;river&apos;, 0.59637962862495086),
 (&apos;brown&apos;, 0.595773016534769),
 (&apos;believable&apos;, 0.59566072133302495),
 (&apos;always&apos;, 0.59470710774669278),
 (&apos;bound&apos;, 0.59470710774669278),
 (&apos;hall&apos;, 0.5933967777928858),
 (&apos;cook&apos;, 0.5916777203950857),
 (&apos;claire&apos;, 0.59136448625000293),
 (&apos;broadway&apos;, 0.59033768669372433),
 (&apos;anna&apos;, 0.58778666490211906),
 (&apos;peace&apos;, 0.58628403501758408),
 (&apos;visually&apos;, 0.58539431926349916),
 (&apos;morality&apos;, 0.58525821854876026),
 (&apos;falk&apos;, 0.58525821854876026),
 (&apos;growing&apos;, 0.58466653756587539),
 (&apos;experiences&apos;, 0.58314628534561685),
 (&apos;stood&apos;, 0.58314628534561685),
 (&apos;touch&apos;, 0.58122926435596001),
 (&apos;lives&apos;, 0.5810976767513224),
 (&apos;kubrick&apos;, 0.58066919713325493),
 (&apos;timing&apos;, 0.58047401805583243),
 (&apos;expressions&apos;, 0.57981849525294216),
 (&apos;struggles&apos;, 0.57981849525294216),
 (&apos;authentic&apos;, 0.57848427223980559),
 (&apos;helen&apos;, 0.57763429343810091),
 (&apos;pre&apos;, 0.57700753064729182),
 (&apos;quirky&apos;, 0.5753641449035618),
 (&apos;young&apos;, 0.57531672344534313),
 (&apos;inner&apos;, 0.57454143815209846),
 (&apos;mexico&apos;, 0.57443087372056334),
 (&apos;clint&apos;, 0.57380042292737909),
 (&apos;sisters&apos;, 0.57286101468544337),
 (&apos;realism&apos;, 0.57226528899949558),
 (&apos;french&apos;, 0.5720692490067093),
 (&apos;personalities&apos;, 0.5720692490067093),
 (&apos;surprises&apos;, 0.57113222999698177),
 (&apos;adventures&apos;, 0.57113222999698177),
 (&apos;overcome&apos;, 0.5697681593994407),
 (&apos;timothy&apos;, 0.56953322459276867),
 (&apos;tales&apos;, 0.56909453188996639),
 (&apos;war&apos;, 0.56843317302781682),
 (&apos;civil&apos;, 0.5679840376059393),
 (&apos;countries&apos;, 0.56737779327091187),
 (&apos;streep&apos;, 0.56710645966458029),
 (&apos;tradition&apos;, 0.56685345523565323),
 (&apos;oliver&apos;, 0.56673325570428668),
 (&apos;australia&apos;, 0.56580775818334383),
 (&apos;understanding&apos;, 0.56531380905006046),
 (&apos;players&apos;, 0.56509525370004821),
 (&apos;knowing&apos;, 0.56489284503626647),
 (&apos;rogers&apos;, 0.56421349718405212),
 (&apos;suspenseful&apos;, 0.56368911332305849),
 (&apos;variety&apos;, 0.56368911332305849),
 (&apos;true&apos;, 0.56281525180810066),
 (&apos;jr&apos;, 0.56220982311246936),
 (&apos;psychological&apos;, 0.56108745854687891),
 (&apos;sent&apos;, 0.55961578793542266),
 (&apos;grand&apos;, 0.55961578793542266),
 (&apos;branagh&apos;, 0.55961578793542266),
 (&apos;reminiscent&apos;, 0.55961578793542266),
 (&apos;performing&apos;, 0.55961578793542266),
 (&apos;wealth&apos;, 0.55961578793542266),
 (&apos;overwhelming&apos;, 0.55961578793542266),
 (&apos;odds&apos;, 0.55961578793542266),
 (&apos;brothers&apos;, 0.55891181043362848),
 (&apos;howard&apos;, 0.55811089675600245),
 (&apos;david&apos;, 0.55693122256475369),
 (&apos;generation&apos;, 0.55628799784274796),
 (&apos;grow&apos;, 0.55612538299565417),
 (&apos;survival&apos;, 0.55594605904646033),
 (&apos;mainstream&apos;, 0.55574731115750231),
 (&apos;dick&apos;, 0.55431073570572953),
 (&apos;charm&apos;, 0.55288175575407861),
 (&apos;kirk&apos;, 0.55278982286502287),
 (&apos;twists&apos;, 0.55244729845681018),
 (&apos;gangster&apos;, 0.55206858230003986),
 (&apos;jeff&apos;, 0.55179306225421365),
 (&apos;family&apos;, 0.55116244510065526),
 (&apos;tend&apos;, 0.55053307336110335),
 (&apos;thanks&apos;, 0.55049088015842218),
 (&apos;world&apos;, 0.54744234723432639),
 (&apos;sutherland&apos;, 0.54743536937855164),
 (&apos;life&apos;, 0.54695514434959924),
 (&apos;disc&apos;, 0.54654370636806993),
 (&apos;bug&apos;, 0.54654370636806993),
 (&apos;tribute&apos;, 0.5455111817538808),
 (&apos;europe&apos;, 0.54522705048332309),
 (&apos;sacrifice&apos;, 0.54430155296238014),
 (&apos;color&apos;, 0.54405127139431109),
 (&apos;superior&apos;, 0.54333490233128523),
 (&apos;york&apos;, 0.54318235866536513),
 (&apos;pulls&apos;, 0.54266622962164945),
 (&apos;jackson&apos;, 0.54232429082536171),
 (&apos;hearts&apos;, 0.54232429082536171),
 (&apos;enjoy&apos;, 0.54124285135906114),
 (&apos;redemption&apos;, 0.54056759296472823),
 (&apos;madness&apos;, 0.540384426007535),
 (&apos;stands&apos;, 0.5389965007326869),
 (&apos;trial&apos;, 0.5389965007326869),
 (&apos;greek&apos;, 0.5389965007326869),
 (&apos;hamilton&apos;, 0.5389965007326869),
 (&apos;each&apos;, 0.5388212312554177),
 (&apos;faithful&apos;, 0.53773307668591508),
 (&apos;received&apos;, 0.5372768098531604),
 (&apos;documentaries&apos;, 0.53714293208336406),
 (&apos;jealous&apos;, 0.53714293208336406),
 (&apos;different&apos;, 0.53709860682460819),
 (&apos;describes&apos;, 0.53680111016925136),
 (&apos;shorts&apos;, 0.53596159703753288),
 (&apos;brilliance&apos;, 0.53551823635636209),
 (&apos;mountains&apos;, 0.53492317534505118),
 (&apos;share&apos;, 0.53408248593025787),
 (&apos;dealt&apos;, 0.53408248593025787),
 (&apos;providing&apos;, 0.53329847961804933),
 (&apos;explore&apos;, 0.53329847961804933),
 (&apos;series&apos;, 0.5325809226575603),
 (&apos;fellow&apos;, 0.5323318289869543),
 (&apos;loves&apos;, 0.53062825106217038),
 (&apos;revolution&apos;, 0.53062825106217038),
 (&apos;olivier&apos;, 0.53062825106217038),
 (&apos;roman&apos;, 0.53062825106217038),
 (&apos;century&apos;, 0.53002783074992665),
 (&apos;musical&apos;, 0.52966871156747064),
 (&apos;heroic&apos;, 0.52925932545482868),
 (&apos;approach&apos;, 0.52806743020049673),
 (&apos;ironically&apos;, 0.52806743020049673),
 (&apos;temple&apos;, 0.52806743020049673),
 (&apos;moves&apos;, 0.5279372642387119),
 (&apos;gift&apos;, 0.52702030968597136),
 (&apos;julie&apos;, 0.52609309589677911),
 (&apos;tells&apos;, 0.52415107836314001),
 (&apos;radio&apos;, 0.52394671172868779),
 (&apos;uncle&apos;, 0.52354439617376536),
 (&apos;union&apos;, 0.52324814376454787),
 (&apos;deep&apos;, 0.52309571635780505),
 (&apos;reminds&apos;, 0.52157841554225237),
 (&apos;famous&apos;, 0.52118841080153722),
 (&apos;jazz&apos;, 0.52053443789295151),
 (&apos;dennis&apos;, 0.51987545928590861),
 (&apos;epic&apos;, 0.51919387343650736),
 (&apos;adult&apos;, 0.519167695083386),
 (&apos;shows&apos;, 0.51915322220375304),
 (&apos;performed&apos;, 0.5191244265806858),
 (&apos;demons&apos;, 0.5191244265806858),
 (&apos;discovered&apos;, 0.51879379341516751),
 (&apos;eric&apos;, 0.51879379341516751),
 (&apos;youth&apos;, 0.5185626062681431),
 (&apos;human&apos;, 0.51851411224987087),
 (&apos;tarzan&apos;, 0.51813827061227724),
 (&apos;ourselves&apos;, 0.51794309153485463),
 (&apos;wwii&apos;, 0.51758240622887042),
 (&apos;passion&apos;, 0.5162164724008671),
 (&apos;desire&apos;, 0.51607497965213445),
 (&apos;pays&apos;, 0.51581316527702981),
 (&apos;dirty&apos;, 0.51557622652458857),
 (&apos;fox&apos;, 0.51557622652458857),
 (&apos;sympathetic&apos;, 0.51546600332249293),
 (&apos;symbolism&apos;, 0.51546600332249293),
 (&apos;attitude&apos;, 0.51530993621331933),
 (&apos;appearances&apos;, 0.51466440007315639),
 (&apos;jeremy&apos;, 0.51466440007315639),
 (&apos;fun&apos;, 0.51439068993048687),
 (&apos;south&apos;, 0.51420972175023116),
 (&apos;arrives&apos;, 0.51409894911095988),
 (&apos;present&apos;, 0.51341965894303732),
 (&apos;com&apos;, 0.51326167856387173),
 (&apos;smile&apos;, 0.51265880484765169),
 (&apos;alan&apos;, 0.51082562376599072),
 (&apos;ring&apos;, 0.51082562376599072),
 (&apos;visit&apos;, 0.51082562376599072),
 (&apos;fits&apos;, 0.51082562376599072),
 (&apos;provided&apos;, 0.51082562376599072),
 (&apos;carter&apos;, 0.51082562376599072),
 (&apos;aging&apos;, 0.51082562376599072),
 (&apos;countryside&apos;, 0.51082562376599072),
 (&apos;begins&apos;, 0.51015650363396647),
 (&apos;success&apos;, 0.50900578704900468),
 (&apos;japan&apos;, 0.50900578704900468),
 (&apos;accurate&apos;, 0.50895471583017893),
 (&apos;proud&apos;, 0.50800474742434931),
 (&apos;daily&apos;, 0.5075946031845443),
 (&apos;karloff&apos;, 0.50724780241810674),
 (&apos;atmospheric&apos;, 0.50724780241810674),
 (&apos;recently&apos;, 0.50714914903668207),
 (&apos;fu&apos;, 0.50704490092608467),
 (&apos;horrors&apos;, 0.50656122497953315),
 (&apos;finding&apos;, 0.50637127341661037),
 (&apos;lust&apos;, 0.5059356384717989),
 (&apos;hitchcock&apos;, 0.50574947073413001),
 (&apos;among&apos;, 0.50334004951332734),
 (&apos;viewing&apos;, 0.50302139827440906),
 (&apos;investigation&apos;, 0.50262885656181222),
 (&apos;shining&apos;, 0.50262885656181222),
 (&apos;duo&apos;, 0.5020919437972361),
 (&apos;cameron&apos;, 0.5020919437972361),
 (&apos;finds&apos;, 0.50128303100539795),
 (&apos;contemporary&apos;, 0.50077528791248915),
 (&apos;genuine&apos;, 0.50046283673044401),
 (&apos;frightening&apos;, 0.49995595152908684),
 (&apos;plays&apos;, 0.49975983848890226),
 (&apos;age&apos;, 0.49941323171424595),
 (&apos;position&apos;, 0.49899116611898781),
 (&apos;continues&apos;, 0.49863035067217237),
 (&apos;roles&apos;, 0.49839716550752178),
 (&apos;james&apos;, 0.49837216269470402),
 (&apos;individuals&apos;, 0.49824684155913052),
 (&apos;brought&apos;, 0.49783842823917956),
 (&apos;hilarious&apos;, 0.49714551986191058),
 (&apos;brutal&apos;, 0.49681488669639234),
 (&apos;appropriate&apos;, 0.49643688631389105),
 (&apos;dance&apos;, 0.49581998314812048),
 (&apos;league&apos;, 0.49578774640145024),
 (&apos;helping&apos;, 0.49578774640145024),
 (&apos;answers&apos;, 0.49578774640145024),
 (&apos;stunts&apos;, 0.49561620510246196),
 (&apos;traveling&apos;, 0.49532143723002542),
 (&apos;thoroughly&apos;, 0.49414593456733524),
 (&apos;depicted&apos;, 0.49317068852726992),
 (&apos;combination&apos;, 0.49247648509779424),
 (&apos;honor&apos;, 0.49247648509779424),
 (&apos;differences&apos;, 0.49247648509779424),
 (&apos;fully&apos;, 0.49213349075383811),
 (&apos;tracy&apos;, 0.49159426183810306),
 (&apos;battles&apos;, 0.49140753790888908),
 (&apos;possibility&apos;, 0.49112055268665822),
 (&apos;romance&apos;, 0.4901589869574316),
 (&apos;initially&apos;, 0.49002249613622745),
 (&apos;happy&apos;, 0.4898997500608791),
 (&apos;crime&apos;, 0.48977221456815834),
 (&apos;singing&apos;, 0.4893852925281213),
 (&apos;especially&apos;, 0.48901267837860624),
 (&apos;shakespeare&apos;, 0.48754793889664511),
 (&apos;hugh&apos;, 0.48729512635579658),
 (&apos;detail&apos;, 0.48609484250827351),
 (&apos;julia&apos;, 0.48550781578170082),
 (&apos;san&apos;, 0.48550781578170082),
 (&apos;guide&apos;, 0.48550781578170082),
 (&apos;desperation&apos;, 0.48550781578170082),
 (&apos;companion&apos;, 0.48550781578170082),
 (&apos;strongly&apos;, 0.48460242866688824),
 (&apos;necessary&apos;, 0.48302334245403883),
 (&apos;humanity&apos;, 0.48265474679929443),
 (&apos;drama&apos;, 0.48221998493060503),
 (&apos;nonetheless&apos;, 0.48183808689273838),
 (&apos;intrigue&apos;, 0.48183808689273838),
 (&apos;warming&apos;, 0.48183808689273838),
 (&apos;cuba&apos;, 0.48183808689273838),
 (&apos;planned&apos;, 0.47957308026188628),
 (&apos;pictures&apos;, 0.47929937011921681),
 (&apos;broadcast&apos;, 0.47849024312305422),
 (&apos;nine&apos;, 0.47803580094299974),
 (&apos;settings&apos;, 0.47743860773325364),
 (&apos;history&apos;, 0.47732966933780852),
 (&apos;ordinary&apos;, 0.47725880012690741),
 (&apos;trade&apos;, 0.47692407209030935),
 (&apos;official&apos;, 0.47608267532211779),
 (&apos;primary&apos;, 0.47608267532211779),
 (&apos;episode&apos;, 0.47529620261150429),
 (&apos;role&apos;, 0.47520268270188676),
 (&apos;spirit&apos;, 0.47477690799839323),
 (&apos;grey&apos;, 0.47409361449726067),
 (&apos;ways&apos;, 0.47323464982718205),
 (&apos;cup&apos;, 0.47260441094579297),
 (&apos;piano&apos;, 0.47260441094579297),
 (&apos;familiar&apos;, 0.47241617565111949),
 (&apos;sinister&apos;, 0.47198579044972683),
 (&apos;reveal&apos;, 0.47171449364936496),
 (&apos;max&apos;, 0.47150852042515579),
 (&apos;dated&apos;, 0.47121648567094482),
 (&apos;losing&apos;, 0.47000362924573563),
 (&apos;discovery&apos;, 0.47000362924573563),
 (&apos;vicious&apos;, 0.47000362924573563),
 (&apos;genuinely&apos;, 0.46871413841586385),
 (&apos;hatred&apos;, 0.46734051182625186),
 (&apos;mistaken&apos;, 0.46702300110759781),
 (&apos;dream&apos;, 0.46608972992459924),
 (&apos;challenge&apos;, 0.46608972992459924),
 (&apos;crisis&apos;, 0.46575733836428446),
 (&apos;photographed&apos;, 0.46488852857896512),
 (&apos;critics&apos;, 0.46430560813109778),
 (&apos;bird&apos;, 0.46430560813109778),
 (&apos;machines&apos;, 0.46430560813109778),
 (&apos;born&apos;, 0.46411383518967209),
 (&apos;detective&apos;, 0.4636633473511525),
 (&apos;higher&apos;, 0.46328467899699055),
 (&apos;remains&apos;, 0.46262352194811296),
 (&apos;inevitable&apos;, 0.46262352194811296),
 (&apos;soviet&apos;, 0.4618180446592961),
 (&apos;ryan&apos;, 0.46134556650262099),
 (&apos;african&apos;, 0.46112595521371813),
 (&apos;smaller&apos;, 0.46081520319132935),
 (&apos;techniques&apos;, 0.46052488529119184),
 (&apos;information&apos;, 0.46034171833399862),
 (&apos;deserved&apos;, 0.45999798712841444),
 (&apos;lynch&apos;, 0.45953232937844013),
 (&apos;spielberg&apos;, 0.45953232937844013),
 (&apos;cynical&apos;, 0.45953232937844013),
 (&apos;tour&apos;, 0.45953232937844013),
 (&apos;francisco&apos;, 0.45953232937844013),
 (&apos;struggle&apos;, 0.45911782160048453),
 (&apos;language&apos;, 0.45902121257712653),
 (&apos;visual&apos;, 0.45823514408822852),
 (&apos;warner&apos;, 0.45724137763188427),
 (&apos;social&apos;, 0.45720078250735313),
 (&apos;reality&apos;, 0.45719346885019546),
 (&apos;hidden&apos;, 0.45675840249571492),
 (&apos;breaking&apos;, 0.45601738727099561),
 (&apos;sometimes&apos;, 0.45563021171182794),
 (&apos;modern&apos;, 0.45500247579345005),
 (&apos;surfing&apos;, 0.45425527227759638),
 (&apos;popular&apos;, 0.45410691533051023),
 (&apos;surprised&apos;, 0.4534409399850382),
 (&apos;follows&apos;, 0.45245361754408348),
 (&apos;keeps&apos;, 0.45234869400701483),
 (&apos;john&apos;, 0.4520909494482197),
 (&apos;mixed&apos;, 0.45198512374305722),
 (&apos;defeat&apos;, 0.45198512374305722),
 (&apos;justice&apos;, 0.45142724367280018),
 (&apos;treasure&apos;, 0.45083371313801535),
 (&apos;presents&apos;, 0.44973793178615257),
 (&apos;years&apos;, 0.44919197032104968),
 (&apos;chief&apos;, 0.44895022004790319),
 (&apos;shadows&apos;, 0.44802472252696035),
 (&apos;closely&apos;, 0.44701411102103689),
 (&apos;segments&apos;, 0.44701411102103689),
 (&apos;lose&apos;, 0.44658335503763702),
 (&apos;caine&apos;, 0.44628710262841953),
 (&apos;caught&apos;, 0.44610275383999071),
 (&apos;hamlet&apos;, 0.44558510189758965),
 (&apos;chinese&apos;, 0.44507424620321018),
 (&apos;welcome&apos;, 0.44438052435783792),
 (&apos;birth&apos;, 0.44368632092836219),
 (&apos;represents&apos;, 0.44320543609101143),
 (&apos;puts&apos;, 0.44279106572085081),
 (&apos;visuals&apos;, 0.44183275227903923),
 (&apos;fame&apos;, 0.44183275227903923),
 (&apos;closer&apos;, 0.44183275227903923),
 (&apos;web&apos;, 0.44183275227903923),
 (&apos;criminal&apos;, 0.4412745608048752),
 (&apos;minor&apos;, 0.4409224199448939),
 (&apos;jon&apos;, 0.44086703515908027),
 (&apos;liked&apos;, 0.44074991514020723),
 (&apos;restaurant&apos;, 0.44031183943833246),
 (&apos;de&apos;, 0.43983275161237217),
 (&apos;flaws&apos;, 0.43983275161237217),
 (&apos;searching&apos;, 0.4393666597838457),
 (&apos;rap&apos;, 0.43891304217570443),
 (&apos;light&apos;, 0.43884433018199892),
 (&apos;elizabeth&apos;, 0.43872232986464677),
 (&apos;marry&apos;, 0.43861731542506488),
 (&apos;learned&apos;, 0.43825493093115531),
 (&apos;controversial&apos;, 0.43825493093115531),
 (&apos;oz&apos;, 0.43825493093115531),
 (&apos;slowly&apos;, 0.43785660389939979),
 (&apos;comedic&apos;, 0.43721380642274466),
 (&apos;wayne&apos;, 0.43721380642274466),
 (&apos;thrilling&apos;, 0.43721380642274466),
 (&apos;bridge&apos;, 0.43721380642274466),
 (&apos;married&apos;, 0.43658501682196887),
 (&apos;nazi&apos;, 0.4361020775700542),
 (&apos;murder&apos;, 0.4353180712578455),
 (&apos;physical&apos;, 0.4353180712578455),
 (&apos;johnny&apos;, 0.43483971678806865),
 (&apos;michelle&apos;, 0.43445264498141672),
 (&apos;wallace&apos;, 0.43403848055222038),
 (&apos;comedies&apos;, 0.43395706390247063),
 (&apos;silent&apos;, 0.43395706390247063),
 (&apos;played&apos;, 0.43387244114515305),
 (&apos;international&apos;, 0.43363598507486073),
 (&apos;vision&apos;, 0.43286408229627887),
 (&apos;intelligent&apos;, 0.43196704885367099),
 (&apos;shop&apos;, 0.43078291609245434),
 (&apos;also&apos;, 0.43036720209769169),
 (&apos;levels&apos;, 0.4302451371066513),
 (&apos;miss&apos;, 0.43006426712153217),
 (&apos;movement&apos;, 0.4295626596872249),
 ...]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># words most frequently seen in a review with a "NEGATIVE" label</span></div><div class="line">list(reversed(pos_neg_ratios.most_common()))[<span class="number">0</span>:<span class="number">30</span>]</div></pre></td></tr></table></figure>
<pre><code>[(&apos;boll&apos;, -4.0778152602708904),
 (&apos;uwe&apos;, -3.9218753018711578),
 (&apos;seagal&apos;, -3.3202501058581921),
 (&apos;unwatchable&apos;, -3.0269848170580955),
 (&apos;stinker&apos;, -2.9876839403711624),
 (&apos;mst&apos;, -2.7753833211707968),
 (&apos;incoherent&apos;, -2.7641396677532537),
 (&apos;unfunny&apos;, -2.5545257844967644),
 (&apos;waste&apos;, -2.4907515123361046),
 (&apos;blah&apos;, -2.4475792789485005),
 (&apos;horrid&apos;, -2.3715779644809971),
 (&apos;pointless&apos;, -2.3451073877136341),
 (&apos;atrocious&apos;, -2.3187369339642556),
 (&apos;redeeming&apos;, -2.2667790015910296),
 (&apos;prom&apos;, -2.2601040980178784),
 (&apos;drivel&apos;, -2.2476029585766928),
 (&apos;lousy&apos;, -2.2118080125207054),
 (&apos;worst&apos;, -2.1930856334332267),
 (&apos;laughable&apos;, -2.172468615469592),
 (&apos;awful&apos;, -2.1385076866397488),
 (&apos;poorly&apos;, -2.1326133844207011),
 (&apos;wasting&apos;, -2.1178155545614512),
 (&apos;remotely&apos;, -2.111046881095167),
 (&apos;existent&apos;, -2.0024805005437076),
 (&apos;boredom&apos;, -1.9241486572738005),
 (&apos;miserably&apos;, -1.9216610938019989),
 (&apos;sucks&apos;, -1.9166645809588516),
 (&apos;uninspired&apos;, -1.9131499212248517),
 (&apos;lame&apos;, -1.9117232884159072),
 (&apos;insult&apos;, -1.9085323769376259)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bokeh.models <span class="keyword">import</span> ColumnDataSource, LabelSet</div><div class="line"><span class="keyword">from</span> bokeh.plotting <span class="keyword">import</span> figure, show, output_file</div><div class="line"><span class="keyword">from</span> bokeh.io <span class="keyword">import</span> output_notebook</div><div class="line">output_notebook()</div></pre></td></tr></table></figure>
<pre><code>&lt;div class=&quot;bk-root&quot;&gt;
    &lt;a href=&quot;http://bokeh.pydata.org&quot; target=&quot;_blank&quot; class=&quot;bk-logo bk-logo-small bk-logo-notebook&quot;&gt;&lt;/a&gt;
    &lt;span id=&quot;67a2b150-b2f3-44b7-a401-91d2f2e64a0b&quot;&gt;Loading BokehJS ...&lt;/span&gt;
&lt;/div&gt;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hist, edges = np.histogram(list(map(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],pos_neg_ratios.most_common())), density=<span class="keyword">True</span>, bins=<span class="number">100</span>, normed=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">p = figure(tools=<span class="string">"pan,wheel_zoom,reset,save"</span>,</div><div class="line">           toolbar_location=<span class="string">"above"</span>,</div><div class="line">           title=<span class="string">"Word Positive/Negative Affinity Distribution"</span>)</div><div class="line">p.quad(top=hist, bottom=<span class="number">0</span>, left=edges[:<span class="number">-1</span>], right=edges[<span class="number">1</span>:], line_color=<span class="string">"#555555"</span>)</div><div class="line">show(p)</div></pre></td></tr></table></figure>
<pre><code>&lt;div class=&quot;bk-root&quot;&gt;
    &lt;div class=&quot;bk-plotdiv&quot; id=&quot;09af843a-8ba0-4f13-a758-59453c5e2213&quot;&gt;&lt;/div&gt;
&lt;/div&gt;
</code></pre><script type="text/javascript">

  (function(global) {
    function now() {
      return new Date();
    }

    var force = false;

    if (typeof (window._bokeh_onload_callbacks) === "undefined" || force === true) {
      window._bokeh_onload_callbacks = [];
      window._bokeh_is_loading = undefined;
    }



    if (typeof (window._bokeh_timeout) === "undefined" || force === true) {
      window._bokeh_timeout = Date.now() + 0;
      window._bokeh_failed_load = false;
    }

    var NB_LOAD_WARNING = {'data': {'text/html':
       "<div style='background-color: #fdd'>\n"+
       "<p>\n"+
       "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
       "may be due to a slow or bad network connection. Possible fixes:\n"+
       "</p>\n"+
       "<ul>\n"+
       "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
       "<li>use INLINE resources instead, as so:</li>\n"+
       "</ul>\n"+
       "<code>\n"+
       "from bokeh.resources import INLINE\n"+
       "output_notebook(resources=INLINE)\n"+
       "</code>\n"+
       "</div>"}};

    function display_loaded() {
      if (window.Bokeh !== undefined) {
        document.getElementById("09af843a-8ba0-4f13-a758-59453c5e2213").textContent = "BokehJS successfully loaded.";
      } else if (Date.now() < window._bokeh_timeout) {
        setTimeout(display_loaded, 100)
      }
    }

    function run_callbacks() {
      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });
      delete window._bokeh_onload_callbacks
      console.info("Bokeh: all callbacks have finished");
    }

    function load_libs(js_urls, callback) {
      window._bokeh_onload_callbacks.push(callback);
      if (window._bokeh_is_loading > 0) {
        console.log("Bokeh: BokehJS is being loaded, scheduling callback at", now());
        return null;
      }
      if (js_urls == null || js_urls.length === 0) {
        run_callbacks();
        return null;
      }
      console.log("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
      window._bokeh_is_loading = js_urls.length;
      for (var i = 0; i < js_urls.length; i++) {
        var url = js_urls[i];
        var s = document.createElement('script');
        s.src = url;
        s.async = false;
        s.onreadystatechange = s.onload = function() {
          window._bokeh_is_loading--;
          if (window._bokeh_is_loading === 0) {
            console.log("Bokeh: all BokehJS libraries loaded");
            run_callbacks()
          }
        };
        s.onerror = function() {
          console.warn("failed to load library " + url);
        };
        console.log("Bokeh: injecting script tag for BokehJS library: ", url);
        document.getElementsByTagName("head")[0].appendChild(s);
      }
    };var element = document.getElementById("09af843a-8ba0-4f13-a758-59453c5e2213");
    if (element == null) {
      console.log("Bokeh: ERROR: autoload.js configured with elementid '09af843a-8ba0-4f13-a758-59453c5e2213' but no matching script tag was found. ")
      return false;
    }

    var js_urls = [];

    var inline_js = [
      function(Bokeh) {
        (function() {
          var fn = function() {
            var docs_json = {"932bbd7d-9cfa-4f24-a68d-65a2f3b9d077":{"roots":{"references":[{"attributes":{"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"},"ticker":{"id":"fceb939b-a091-488b-89d4-4a1289254b2b","type":"BasicTicker"}},"id":"bd6c6269-c94e-423b-a26b-41c0a1d3da33","type":"Grid"},{"attributes":{"formatter":{"id":"56803c7f-e6cd-4496-8898-175419c75307","type":"BasicTickFormatter"},"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"},"ticker":{"id":"a401f008-4871-4894-80ee-d6b81cbac492","type":"BasicTicker"}},"id":"873f13d5-ad53-41cc-9e68-558b3625adb1","type":"LinearAxis"},{"attributes":{},"id":"771947ef-d589-49ae-98f5-6ef45a8c1024","type":"BasicTickFormatter"},{"attributes":{},"id":"a401f008-4871-4894-80ee-d6b81cbac492","type":"BasicTicker"},{"attributes":{"dimension":1,"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"},"ticker":{"id":"a401f008-4871-4894-80ee-d6b81cbac492","type":"BasicTicker"}},"id":"98985a39-f4f7-447e-90da-8df0b5326fe4","type":"Grid"},{"attributes":{"data_source":{"id":"7ffb53d7-2954-42ee-8006-9db7d370a58a","type":"ColumnDataSource"},"glyph":{"id":"9ccfdd0e-2895-4f93-b5bb-b0f46e0d1dba","type":"Quad"},"hover_glyph":null,"nonselection_glyph":{"id":"c19a3f86-aa36-40c1-b111-a8f7593ec01f","type":"Quad"},"selection_glyph":null},"id":"458f8b66-92f2-4945-8953-5ff8544870b6","type":"GlyphRenderer"},{"attributes":{"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"}},"id":"29bf3458-2214-4e1c-8371-cf99a3e3d1ee","type":"PanTool"},{"attributes":{"plot":null,"text":"Word Positive/Negative Affinity Distribution"},"id":"5e6aebc1-300c-4468-bae9-518ac28ca463","type":"Title"},{"attributes":{"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"}},"id":"08797199-4344-44d6-a585-ecd6eec0e0e5","type":"WheelZoomTool"},{"attributes":{"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"}},"id":"c922a12f-3b41-4cfe-ad44-30cb288bd738","type":"ResetTool"},{"attributes":{"bottom":{"value":0},"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"right":{"field":"right"},"top":{"field":"top"}},"id":"c19a3f86-aa36-40c1-b111-a8f7593ec01f","type":"Quad"},{"attributes":{"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"}},"id":"c8c8f3b7-92a6-48de-a5a7-a7c8745d236d","type":"SaveTool"},{"attributes":{"bottom":{"value":0},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_color":{"value":"#555555"},"right":{"field":"right"},"top":{"field":"top"}},"id":"9ccfdd0e-2895-4f93-b5bb-b0f46e0d1dba","type":"Quad"},{"attributes":{"callback":null,"column_names":["left","right","top"],"data":{"left":{"__ndarray__":"Cvm3za5PEMCZHufvxesPwB5LXkQuOA/AonfVmJaEDsAnpEzt/tANwKzQw0FnHQ3AMf06ls9pDMC2KbLqN7YLwDpWKT+gAgvAv4KgkwhPCsBErxfocJsJwMnbjjzZ5wjATggGkUE0CMDSNH3lqYAHwFhh9DkSzQbA3I1rjnoZBsBhuuLi4mUFwObmWTdLsgTAahPRi7P+A8DwP0jgG0sDwHRsvzSElwLA+Zg2iezjAcB+xa3dVDABwAPyJDK9fADAED04DUuS/78Ylia2Gyv+vyLvFF/sw/y/LEgDCL1c+782ofGwjfX5v0D631lejvi/SFPOAi8n979SrLyr/7/1v1wFq1TQWPS/Zl6Z/aDx8r9wt4emcYrxv3gQdk9CI/C/BNPI8CV47b8YhaVCx6nqvyw3gpRo2+e/QOle5gkN5b9Qmzs4qz7iv8iaMBSZ4N6/8P7pt9tD2b8YY6NbHqfTv4COuf7BFMy/0FYsRkfbwL+AfHw2Moemv4BiuKu4XqY/QFB74yjRwD8AiAicowrMP+DfSioPotM/sHuRhsw+2T+QF9jiidveP7BZj58jPOI/oKeyTYIK5T+Q9dX74NjnP3hD+ak/p+o/aJEcWJ517T+o7x+D/iHwP6CWMdotifE/mD1DMV3w8j+M5FSIjFf0P4SLZt+7vvU/eDJ4Nusl9z9w2YmNGo34P2iAm+RJ9Pk/XCetO3lb+z9Uzr6SqML8P0h10OnXKf4/QBziQAeR/z+c4flLG3wAQBa1gveyLwFAkogLo0rjAUAMXJRO4pYCQIgvHfp5SgNABAOmpRH+A0B+1i5RqbEEQPqpt/xAZQVAdH1AqNgYBkDwUMlTcMwGQGwkUv8HgAdA5vfaqp8zCEBiy2NWN+cIQNye7AHPmglAWHJ1rWZOCkDSRf5Y/gELQE4ZhwSWtQtAyuwPsC1pDEBEwJhbxRwNQMCTIQdd0A1AOmeqsvSDDkC2OjNejDcPQDAOvAkk6w9A1nCi2l1PEECU2mawKakQQFJEK4b1AhFADq7vW8FcEUDMF7QxjbYRQIqBeAdZEBJASOs83SRqEkA=","dtype":"float64","shape":[100]},"right":{"__ndarray__":"mR7n78XrD8AeS15ELjgPwKJ31ZiWhA7AJ6RM7f7QDcCs0MNBZx0NwDH9OpbPaQzAtimy6je2C8A6Vik/oAILwL+CoJMITwrARK8X6HCbCcDJ24482ecIwE4IBpFBNAjA0jR95amAB8BYYfQ5Es0GwNyNa456GQbAYbri4uJlBcDm5lk3S7IEwGoT0Yuz/gPA8D9I4BtLA8B0bL80hJcCwPmYNons4wHAfsWt3VQwAcAD8iQyvXwAwBA9OA1Lkv+/GJYmthsr/r8i7xRf7MP8vyxIAwi9XPu/NqHxsI31+b9A+t9ZXo74v0hTzgIvJ/e/Uqy8q/+/9b9cBatU0Fj0v2Zemf2g8fK/cLeHpnGK8b94EHZPQiPwvwTTyPAleO2/GIWlQsep6r8sN4KUaNvnv0DpXuYJDeW/UJs7OKs+4r/ImjAUmeDev/D+6bfbQ9m/GGOjWx6n07+Ajrn+wRTMv9BWLEZH28C/gHx8NjKHpr+AYriruF6mP0BQe+Mo0cA/AIgInKMKzD/g30oqD6LTP7B7kYbMPtk/kBfY4onb3j+wWY+fIzziP6Cnsk2CCuU/kPXV++DY5z94Q/mpP6fqP2iRHFiede0/qO8fg/4h8D+gljHaLYnxP5g9QzFd8PI/jORUiIxX9D+Ei2bfu771P3gyeDbrJfc/cNmJjRqN+D9ogJvkSfT5P1wnrTt5W/s/VM6+kqjC/D9IddDp1yn+P0Ac4kAHkf8/nOH5Sxt8AEAWtYL3si8BQJKIC6NK4wFADFyUTuKWAkCILx36eUoDQAQDpqUR/gNAftYuUamxBED6qbf8QGUFQHR9QKjYGAZA8FDJU3DMBkBsJFL/B4AHQOb32qqfMwhAYstjVjfnCEDcnuwBz5oJQFhyda1mTgpA0kX+WP4BC0BOGYcElrULQMrsD7AtaQxARMCYW8UcDUDAkyEHXdANQDpnqrL0gw5AtjozXow3D0AwDrwJJOsPQNZwotpdTxBAlNpmsCmpEEBSRCuG9QIRQA6u71vBXBFAzBe0MY22EUCKgXgHWRASQEjrPN0kahJABlUBs/DDEkA=","dtype":"float64","shape":[100]},"top":{"__ndarray__":"s6auGMn1ZT+zpq4YyfVlPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALOmrhjJ9WU/AAAAAAAAAAAAAAAAAAAAALOmrhjJ9WU/k6auGMn1ZT8AAAAAAAAAAJOmrhjJ9XU/AAAAAAAAAAAAAAAAAAAAAJOmrhjJ9WU/0qauGMn1dT+Tpq4YyfV1P7OmrhjJ9YU/Bf2C0lZ4gD+zpq4YyfWFP7OmrhjJ9WU/wdGY9Q83kz9fUNpeO3ObPwX9gtJWeJA/s6auGMn1lT/d0Zj1DzeTP8HRmPUPN6M/9GVPzd4Tqj+Je8Q7grSoP/RlT83eE6o/O3JIGwUosT9zD3sTUZGvP/RlT83eE7o/9GVPzd4Tuj+ht+X2LdDAP+gbdGF3pcY/2lQY73k5zz+nXNOsYYfSP6wBwWKVPtQ/xJV3OmQb2z9Z/6EadlviPyTgAZkQXOU/7sBhF6tc6D9YgiEU4F3uP2El8IH0Me4/XSz8TJet6j/wnIMFB5fnP/EzCBg6Kec/9UZePr7m4z89itzRx6vhP+ED4Kq0IdY/9UZePr7m0z+XmrXKouHOP/nrS/TxncU/Zbwjh2yWxD+hOmXwl9K8P/VGXj6+5rM/mzHpzxpGtT/8kDmqJVWnP2W8I4dslqQ/wdGY9Q83oz8qvCOHbJakP/jRmPUPN5M/wdGY9Q83kz8d/YLSVniQP5OmrhjJ9YU/k6auGMn1hT/Spq4YyfVlP5OmrhjJ9WU/0qauGMn1ZT8AAAAAAAAAAJOmrhjJ9WU/0qauGMn1ZT+Tpq4YyfVlP9KmrhjJ9WU/k6auGMn1dT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADSpq4YyfVlPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAk6auGMn1ZT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAk6auGMn1ZT8=","dtype":"float64","shape":[100]}}},"id":"7ffb53d7-2954-42ee-8006-9db7d370a58a","type":"ColumnDataSource"},{"attributes":{"below":[{"id":"d0189600-2bc8-4f4f-8e59-7b111ff4e7ca","type":"LinearAxis"}],"left":[{"id":"873f13d5-ad53-41cc-9e68-558b3625adb1","type":"LinearAxis"}],"renderers":[{"id":"d0189600-2bc8-4f4f-8e59-7b111ff4e7ca","type":"LinearAxis"},{"id":"bd6c6269-c94e-423b-a26b-41c0a1d3da33","type":"Grid"},{"id":"873f13d5-ad53-41cc-9e68-558b3625adb1","type":"LinearAxis"},{"id":"98985a39-f4f7-447e-90da-8df0b5326fe4","type":"Grid"},{"id":"458f8b66-92f2-4945-8953-5ff8544870b6","type":"GlyphRenderer"}],"title":{"id":"5e6aebc1-300c-4468-bae9-518ac28ca463","type":"Title"},"tool_events":{"id":"6fdc9754-e9b6-488e-a2fa-c6b29785e844","type":"ToolEvents"},"toolbar":{"id":"da89543f-9ed9-4bd5-9afc-56343213fc08","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"339bef66-25cb-4439-919f-916b91ddb00d","type":"DataRange1d"},"y_range":{"id":"176af089-47aa-4cd2-a1f1-bf4fa136c326","type":"DataRange1d"}},"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"},{"attributes":{"callback":null},"id":"339bef66-25cb-4439-919f-916b91ddb00d","type":"DataRange1d"},{"attributes":{},"id":"56803c7f-e6cd-4496-8898-175419c75307","type":"BasicTickFormatter"},{"attributes":{"active_drag":"auto","active_scroll":"auto","active_tap":"auto","tools":[{"id":"29bf3458-2214-4e1c-8371-cf99a3e3d1ee","type":"PanTool"},{"id":"08797199-4344-44d6-a585-ecd6eec0e0e5","type":"WheelZoomTool"},{"id":"c922a12f-3b41-4cfe-ad44-30cb288bd738","type":"ResetTool"},{"id":"c8c8f3b7-92a6-48de-a5a7-a7c8745d236d","type":"SaveTool"}]},"id":"da89543f-9ed9-4bd5-9afc-56343213fc08","type":"Toolbar"},{"attributes":{"formatter":{"id":"771947ef-d589-49ae-98f5-6ef45a8c1024","type":"BasicTickFormatter"},"plot":{"id":"7ae81053-1f24-48a9-85e4-b30704bbc24b","subtype":"Figure","type":"Plot"},"ticker":{"id":"fceb939b-a091-488b-89d4-4a1289254b2b","type":"BasicTicker"}},"id":"d0189600-2bc8-4f4f-8e59-7b111ff4e7ca","type":"LinearAxis"},{"attributes":{},"id":"6fdc9754-e9b6-488e-a2fa-c6b29785e844","type":"ToolEvents"},{"attributes":{"callback":null},"id":"176af089-47aa-4cd2-a1f1-bf4fa136c326","type":"DataRange1d"},{"attributes":{},"id":"fceb939b-a091-488b-89d4-4a1289254b2b","type":"BasicTicker"}],"root_ids":["7ae81053-1f24-48a9-85e4-b30704bbc24b"]},"title":"Bokeh Application","version":"0.12.4"}};
            var render_items = [{"docid":"932bbd7d-9cfa-4f24-a68d-65a2f3b9d077","elementid":"09af843a-8ba0-4f13-a758-59453c5e2213","modelid":"7ae81053-1f24-48a9-85e4-b30704bbc24b"}];

            Bokeh.embed.embed_items(docs_json, render_items);
          };
          if (document.readyState != "loading") fn();
          else document.addEventListener("DOMContentLoaded", fn);
        })();
      },
      function(Bokeh) {
      }
    ];

    function run_inline_js() {

      if ((window.Bokeh !== undefined) || (force === true)) {
        for (var i = 0; i < inline_js.length; i++) {
          inline_js[i](window.Bokeh);
        }if (force === true) {
          display_loaded();
        }} else if (Date.now() < window._bokeh_timeout) {
        setTimeout(run_inline_js, 100);
      } else if (!window._bokeh_failed_load) {
        console.log("Bokeh: BokehJS failed to load within specified timeout.");
        window._bokeh_failed_load = true;
      } else if (force !== true) {
        var cell = $(document.getElementById("09af843a-8ba0-4f13-a758-59453c5e2213")).parents('.cell').data().cell;
        cell.output_area.append_execute_result(NB_LOAD_WARNING)
      }

    }

    if (window._bokeh_is_loading === 0) {
      console.log("Bokeh: BokehJS loaded, going straight to plotting");
      run_inline_js();
    } else {
      load_libs(js_urls, function() {
        console.log("Bokeh: BokehJS plotting callback run at", now());
        run_inline_js();
      });
    }
  }(this));
</script>



<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">frequency_frequency = Counter()</div><div class="line"></div><div class="line"><span class="keyword">for</span> word, cnt <span class="keyword">in</span> total_counts.most_common():</div><div class="line">    frequency_frequency[cnt] += <span class="number">1</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hist, edges = np.histogram(list(map(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],frequency_frequency.most_common())), density=<span class="keyword">True</span>, bins=<span class="number">100</span>, normed=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">p = figure(tools=<span class="string">"pan,wheel_zoom,reset,save"</span>,</div><div class="line">           toolbar_location=<span class="string">"above"</span>,</div><div class="line">           title=<span class="string">"The frequency distribution of the words in our corpus"</span>)</div><div class="line">p.quad(top=hist, bottom=<span class="number">0</span>, left=edges[:<span class="number">-1</span>], right=edges[<span class="number">1</span>:], line_color=<span class="string">"#555555"</span>)</div><div class="line">show(p)</div></pre></td></tr></table></figure>
<pre><code>&lt;div class=&quot;bk-root&quot;&gt;
    &lt;div class=&quot;bk-plotdiv&quot; id=&quot;b7f2e30a-9d83-4ebd-a216-d384f5ef713f&quot;&gt;&lt;/div&gt;
&lt;/div&gt;
</code></pre><script type="text/javascript">

  (function(global) {
    function now() {
      return new Date();
    }

    var force = false;

    if (typeof (window._bokeh_onload_callbacks) === "undefined" || force === true) {
      window._bokeh_onload_callbacks = [];
      window._bokeh_is_loading = undefined;
    }



    if (typeof (window._bokeh_timeout) === "undefined" || force === true) {
      window._bokeh_timeout = Date.now() + 0;
      window._bokeh_failed_load = false;
    }

    var NB_LOAD_WARNING = {'data': {'text/html':
       "<div style='background-color: #fdd'>\n"+
       "<p>\n"+
       "BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \n"+
       "may be due to a slow or bad network connection. Possible fixes:\n"+
       "</p>\n"+
       "<ul>\n"+
       "<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\n"+
       "<li>use INLINE resources instead, as so:</li>\n"+
       "</ul>\n"+
       "<code>\n"+
       "from bokeh.resources import INLINE\n"+
       "output_notebook(resources=INLINE)\n"+
       "</code>\n"+
       "</div>"}};

    function display_loaded() {
      if (window.Bokeh !== undefined) {
        document.getElementById("b7f2e30a-9d83-4ebd-a216-d384f5ef713f").textContent = "BokehJS successfully loaded.";
      } else if (Date.now() < window._bokeh_timeout) {
        setTimeout(display_loaded, 100)
      }
    }

    function run_callbacks() {
      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });
      delete window._bokeh_onload_callbacks
      console.info("Bokeh: all callbacks have finished");
    }

    function load_libs(js_urls, callback) {
      window._bokeh_onload_callbacks.push(callback);
      if (window._bokeh_is_loading > 0) {
        console.log("Bokeh: BokehJS is being loaded, scheduling callback at", now());
        return null;
      }
      if (js_urls == null || js_urls.length === 0) {
        run_callbacks();
        return null;
      }
      console.log("Bokeh: BokehJS not loaded, scheduling load and callback at", now());
      window._bokeh_is_loading = js_urls.length;
      for (var i = 0; i < js_urls.length; i++) {
        var url = js_urls[i];
        var s = document.createElement('script');
        s.src = url;
        s.async = false;
        s.onreadystatechange = s.onload = function() {
          window._bokeh_is_loading--;
          if (window._bokeh_is_loading === 0) {
            console.log("Bokeh: all BokehJS libraries loaded");
            run_callbacks()
          }
        };
        s.onerror = function() {
          console.warn("failed to load library " + url);
        };
        console.log("Bokeh: injecting script tag for BokehJS library: ", url);
        document.getElementsByTagName("head")[0].appendChild(s);
      }
    };var element = document.getElementById("b7f2e30a-9d83-4ebd-a216-d384f5ef713f");
    if (element == null) {
      console.log("Bokeh: ERROR: autoload.js configured with elementid 'b7f2e30a-9d83-4ebd-a216-d384f5ef713f' but no matching script tag was found. ")
      return false;
    }

    var js_urls = [];

    var inline_js = [
      function(Bokeh) {
        (function() {
          var fn = function() {
            var docs_json = {"71ebf26b-1b16-419a-bfb4-fb3b12fe4b8e":{"roots":{"references":[{"attributes":{"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"},"ticker":{"id":"80d5047d-6cdd-4f06-a373-f044d2ccf874","type":"BasicTicker"}},"id":"b0566e40-18b7-4f47-9b7f-5b869bd83c36","type":"Grid"},{"attributes":{"formatter":{"id":"e4009fd6-6d49-4acb-96da-1513ad73804e","type":"BasicTickFormatter"},"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"},"ticker":{"id":"841c781a-33a2-4267-b957-c0789a86bd74","type":"BasicTicker"}},"id":"c1a5ddee-bdad-49fd-b476-10a86fd93113","type":"LinearAxis"},{"attributes":{"callback":null},"id":"79df4143-c27c-44df-8806-613cb968be37","type":"DataRange1d"},{"attributes":{"callback":null,"column_names":["left","right","top"],"data":{"left":{"__ndarray__":"AAAAAAAA8D/NzMzMzFhxQM3MzMzMUIFANDMzMzP1iUDNzMzMzEyRQAAAAAAAn5VANDMzMzPxmUBnZmZmZkOeQM3MzMzMSqFAZ2ZmZuZzo0AAAAAAAJ2lQJqZmZkZxqdANDMzMzPvqUDNzMzMTBisQGdmZmZmQa5AAAAAAEA1sEDNzMzMzEmxQJqZmZlZXrJAZ2ZmZuZys0AzMzMzc4e0QAAAAAAAnLVAzczMzIywtkCamZmZGcW3QGdmZmam2bhANDMzMzPuuUAAAAAAwAK7QM3MzMxMF7xAmpmZmdkrvUBnZmZmZkC+QDQzMzPzVL9AAAAAAMA0wEBnZmZmBr/AQM3MzMxMScFAMzMzM5PTwUCamZmZ2V3CQAAAAAAg6MJAZ2ZmZmZyw0DNzMzMrPzDQDMzMzPzhsRAmpmZmTkRxUAAAAAAgJvFQGdmZmbGJcZAzczMzAywxkAzMzMzUzrHQJqZmZmZxMdAAAAAAOBOyEBnZmZmJtnIQM3MzMxsY8lANDMzM7PtyUCamZmZ+XfKQAAAAABAAstAZ2ZmZoaMy0DNzMzMzBbMQDQzMzMTocxAmpmZmVkrzUAAAAAAoLXNQGdmZmbmP85AzczMzCzKzkA0MzMzc1TPQJqZmZm53s9AAAAAAIA00EAzMzMzo3nQQGdmZmbGvtBAmpmZmekD0UDNzMzMDEnRQAAAAAAwjtFAMzMzM1PT0UBnZmZmdhjSQJqZmZmZXdJAzczMzLyi0kAAAAAA4OfSQDMzMzMDLdNAZ2ZmZiZy00CamZmZSbfTQM3MzMxs/NNAAAAAAJBB1EAzMzMzs4bUQGdmZmbWy9RAmpmZmfkQ1UDNzMzMHFbVQAAAAABAm9VAMzMzM2Pg1UBnZmZmhiXWQJqZmZmpatZAzczMzMyv1kAAAAAA8PTWQDMzMzMTOtdAZ2ZmZjZ/10CamZmZWcTXQM3MzMx8CdhAAAAAAKBO2EAzMzMzw5PYQGdmZmbm2NhAmpmZmQke2UDNzMzMLGPZQAAAAABQqNlANDMzM3Pt2UBnZmZmljLaQJqZmZm5d9pAzczMzNy82kA=","dtype":"float64","shape":[100]},"right":{"__ndarray__":"zczMzMxYcUDNzMzMzFCBQDQzMzMz9YlAzczMzMxMkUAAAAAAAJ+VQDQzMzMz8ZlAZ2ZmZmZDnkDNzMzMzEqhQGdmZmbmc6NAAAAAAACdpUCamZmZGcanQDQzMzMz76lAzczMzEwYrEBnZmZmZkGuQAAAAABANbBAzczMzMxJsUCamZmZWV6yQGdmZmbmcrNAMzMzM3OHtEAAAAAAAJy1QM3MzMyMsLZAmpmZmRnFt0BnZmZmptm4QDQzMzMz7rlAAAAAAMACu0DNzMzMTBe8QJqZmZnZK71AZ2ZmZmZAvkA0MzMz81S/QAAAAADANMBAZ2ZmZga/wEDNzMzMTEnBQDMzMzOT08FAmpmZmdldwkAAAAAAIOjCQGdmZmZmcsNAzczMzKz8w0AzMzMz84bEQJqZmZk5EcVAAAAAAICbxUBnZmZmxiXGQM3MzMwMsMZAMzMzM1M6x0CamZmZmcTHQAAAAADgTshAZ2ZmZibZyEDNzMzMbGPJQDQzMzOz7clAmpmZmfl3ykAAAAAAQALLQGdmZmaGjMtAzczMzMwWzEA0MzMzE6HMQJqZmZlZK81AAAAAAKC1zUBnZmZm5j/OQM3MzMwsys5ANDMzM3NUz0CamZmZud7PQAAAAACANNBAMzMzM6N50EBnZmZmxr7QQJqZmZnpA9FAzczMzAxJ0UAAAAAAMI7RQDMzMzNT09FAZ2ZmZnYY0kCamZmZmV3SQM3MzMy8otJAAAAAAODn0kAzMzMzAy3TQGdmZmYmctNAmpmZmUm300DNzMzMbPzTQAAAAACQQdRAMzMzM7OG1EBnZmZm1svUQJqZmZn5ENVAzczMzBxW1UAAAAAAQJvVQDMzMzNj4NVAZ2ZmZoYl1kCamZmZqWrWQM3MzMzMr9ZAAAAAAPD01kAzMzMzEzrXQGdmZmY2f9dAmpmZmVnE10DNzMzMfAnYQAAAAACgTthAMzMzM8OT2EBnZmZm5tjYQJqZmZkJHtlAzczMzCxj2UAAAAAAUKjZQDQzMzNz7dlAZ2ZmZpYy2kCamZmZuXfaQM3MzMzcvNpAAAAAAAAC20A=","dtype":"float64","shape":[100]},"top":{"__ndarray__":"TDhFg5YVbT+JTZDME4n7PtMKDQpDB+Y+1QoNCkMH1j7VCg0KQwfWPgAAAAAAAAAA1QoNCkMHxj7VCg0KQwfGPgAAAAAAAAAA2goNCkMHxj4AAAAAAAAAAAAAAAAAAAAA2goNCkMHxj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5QoNCkMHxj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOUKDQpDB8Y+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5QoNCkMHxj4=","dtype":"float64","shape":[100]}}},"id":"1dcf734c-3ee8-4820-b255-a6d09b3f6630","type":"ColumnDataSource"},{"attributes":{"plot":null,"text":"The frequency distribution of the words in our corpus"},"id":"32291e3c-3b99-4022-a205-eb50ee2e3791","type":"Title"},{"attributes":{"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"}},"id":"c1650719-b9f0-4219-a6ba-d65320df6105","type":"ResetTool"},{"attributes":{"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"}},"id":"c916bd7e-aa63-4038-a897-ae996b97b15f","type":"SaveTool"},{"attributes":{},"id":"5011db81-ef2c-4076-80e0-1e1ad0235528","type":"ToolEvents"},{"attributes":{"below":[{"id":"f06a62f8-4479-4ddb-8c38-ba4cfd716307","type":"LinearAxis"}],"left":[{"id":"c1a5ddee-bdad-49fd-b476-10a86fd93113","type":"LinearAxis"}],"renderers":[{"id":"f06a62f8-4479-4ddb-8c38-ba4cfd716307","type":"LinearAxis"},{"id":"b0566e40-18b7-4f47-9b7f-5b869bd83c36","type":"Grid"},{"id":"c1a5ddee-bdad-49fd-b476-10a86fd93113","type":"LinearAxis"},{"id":"f46df637-6370-4ad2-8c4c-e660fbdafc69","type":"Grid"},{"id":"0498b1d6-9a31-4c8c-8f03-cf575e7040a5","type":"GlyphRenderer"}],"title":{"id":"32291e3c-3b99-4022-a205-eb50ee2e3791","type":"Title"},"tool_events":{"id":"5011db81-ef2c-4076-80e0-1e1ad0235528","type":"ToolEvents"},"toolbar":{"id":"f0ea0e05-5534-4c03-9a92-502f9ffba541","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"79df4143-c27c-44df-8806-613cb968be37","type":"DataRange1d"},"y_range":{"id":"51c6ffd2-1fde-4648-89ee-ee00cd39a672","type":"DataRange1d"}},"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"},{"attributes":{"formatter":{"id":"4dc029e2-a490-4afe-9d77-8d9d7ee08260","type":"BasicTickFormatter"},"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"},"ticker":{"id":"80d5047d-6cdd-4f06-a373-f044d2ccf874","type":"BasicTicker"}},"id":"f06a62f8-4479-4ddb-8c38-ba4cfd716307","type":"LinearAxis"},{"attributes":{"active_drag":"auto","active_scroll":"auto","active_tap":"auto","tools":[{"id":"8d2223a7-1e09-4dec-bddc-b1ee2cf4c729","type":"PanTool"},{"id":"5bead03e-6766-4265-abc1-96776fa9c176","type":"WheelZoomTool"},{"id":"c1650719-b9f0-4219-a6ba-d65320df6105","type":"ResetTool"},{"id":"c916bd7e-aa63-4038-a897-ae996b97b15f","type":"SaveTool"}]},"id":"f0ea0e05-5534-4c03-9a92-502f9ffba541","type":"Toolbar"},{"attributes":{"bottom":{"value":0},"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"right":{"field":"right"},"top":{"field":"top"}},"id":"aecb1e69-3dd3-4661-9a1c-d12b0e5174f4","type":"Quad"},{"attributes":{"callback":null},"id":"51c6ffd2-1fde-4648-89ee-ee00cd39a672","type":"DataRange1d"},{"attributes":{"bottom":{"value":0},"fill_color":{"value":"#1f77b4"},"left":{"field":"left"},"line_color":{"value":"#555555"},"right":{"field":"right"},"top":{"field":"top"}},"id":"73151402-98e3-4d15-b1c1-9905289b200d","type":"Quad"},{"attributes":{},"id":"80d5047d-6cdd-4f06-a373-f044d2ccf874","type":"BasicTicker"},{"attributes":{},"id":"841c781a-33a2-4267-b957-c0789a86bd74","type":"BasicTicker"},{"attributes":{"dimension":1,"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"},"ticker":{"id":"841c781a-33a2-4267-b957-c0789a86bd74","type":"BasicTicker"}},"id":"f46df637-6370-4ad2-8c4c-e660fbdafc69","type":"Grid"},{"attributes":{},"id":"4dc029e2-a490-4afe-9d77-8d9d7ee08260","type":"BasicTickFormatter"},{"attributes":{},"id":"e4009fd6-6d49-4acb-96da-1513ad73804e","type":"BasicTickFormatter"},{"attributes":{"data_source":{"id":"1dcf734c-3ee8-4820-b255-a6d09b3f6630","type":"ColumnDataSource"},"glyph":{"id":"73151402-98e3-4d15-b1c1-9905289b200d","type":"Quad"},"hover_glyph":null,"nonselection_glyph":{"id":"aecb1e69-3dd3-4661-9a1c-d12b0e5174f4","type":"Quad"},"selection_glyph":null},"id":"0498b1d6-9a31-4c8c-8f03-cf575e7040a5","type":"GlyphRenderer"},{"attributes":{"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"}},"id":"5bead03e-6766-4265-abc1-96776fa9c176","type":"WheelZoomTool"},{"attributes":{"plot":{"id":"419cc3b9-0bfc-4618-b282-20eddfbff215","subtype":"Figure","type":"Plot"}},"id":"8d2223a7-1e09-4dec-bddc-b1ee2cf4c729","type":"PanTool"}],"root_ids":["419cc3b9-0bfc-4618-b282-20eddfbff215"]},"title":"Bokeh Application","version":"0.12.4"}};
            var render_items = [{"docid":"71ebf26b-1b16-419a-bfb4-fb3b12fe4b8e","elementid":"b7f2e30a-9d83-4ebd-a216-d384f5ef713f","modelid":"419cc3b9-0bfc-4618-b282-20eddfbff215"}];

            Bokeh.embed.embed_items(docs_json, render_items);
          };
          if (document.readyState != "loading") fn();
          else document.addEventListener("DOMContentLoaded", fn);
        })();
      },
      function(Bokeh) {
      }
    ];

    function run_inline_js() {

      if ((window.Bokeh !== undefined) || (force === true)) {
        for (var i = 0; i < inline_js.length; i++) {
          inline_js[i](window.Bokeh);
        }if (force === true) {
          display_loaded();
        }} else if (Date.now() < window._bokeh_timeout) {
        setTimeout(run_inline_js, 100);
      } else if (!window._bokeh_failed_load) {
        console.log("Bokeh: BokehJS failed to load within specified timeout.");
        window._bokeh_failed_load = true;
      } else if (force !== true) {
        var cell = $(document.getElementById("b7f2e30a-9d83-4ebd-a216-d384f5ef713f")).parents('.cell').data().cell;
        cell.output_area.append_execute_result(NB_LOAD_WARNING)
      }

    }

    if (window._bokeh_is_loading === 0) {
      console.log("Bokeh: BokehJS loaded, going straight to plotting");
      run_inline_js();
    } else {
      load_libs(js_urls, function() {
        console.log("Bokeh: BokehJS plotting callback run at", now());
        run_inline_js();
      });
    }
  }(this));
</script>



<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="comment"># Let's tweak our network from before to model these phenomena</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SentimentNetwork</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, reviews,labels, min_count = <span class="number">10</span>, polarity_cutoff = <span class="number">0.1</span>, hidden_nodes = <span class="number">10</span>, learning_rate = <span class="number">0.1</span>)</span>:</span></div><div class="line">       </div><div class="line">        np.random.seed(<span class="number">1</span>)</div><div class="line">    </div><div class="line">        self.pre_process_data(reviews, polarity_cutoff, min_count)</div><div class="line">        </div><div class="line">        self.init_network(len(self.review_vocab),hidden_nodes, <span class="number">1</span>, learning_rate)</div><div class="line">        </div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span><span class="params">(self,reviews)</span>:</span></div><div class="line">        </div><div class="line">        review_vocab = set()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> reviews:</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">                review_vocab.add(word)</div><div class="line">        self.review_vocab = list(review_vocab)</div><div class="line">        </div><div class="line">        label_vocab = set()</div><div class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels:</div><div class="line">            label_vocab.add(label)</div><div class="line">        </div><div class="line">        self.label_vocab = list(label_vocab)</div><div class="line">        </div><div class="line">        self.review_vocab_size = len(self.review_vocab)</div><div class="line">        self.label_vocab_size = len(self.label_vocab)</div><div class="line">        </div><div class="line">        self.word2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(self.review_vocab):</div><div class="line">            self.word2index[word] = i</div><div class="line">        </div><div class="line">        self.label2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(self.label_vocab):</div><div class="line">            self.label2index[label] = i</div><div class="line">         </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_process_data</span><span class="params">(self, revies, polarity_cutoff, min_count)</span>:</span></div><div class="line">        positive_counts = Counter()</div><div class="line">        negative_counts = Counter()</div><div class="line">        total_counts = Counter()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(reviews)):</div><div class="line">            <span class="keyword">if</span>(labels[i] == <span class="string">'POSITIVE'</span>):</div><div class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> reviews[i].split(<span class="string">' '</span>):</div><div class="line">                    positive_counts[word] += <span class="number">1</span></div><div class="line">                    total_counts[word] += <span class="number">1</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> reviews[i].split(<span class="string">' '</span>):</div><div class="line">                    negative_counts[word] += <span class="number">1</span></div><div class="line">                    total_counts[word] += <span class="number">1</span></div><div class="line">                    </div><div class="line">        pos_neg_ratios = Counter()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> term, cnt <span class="keyword">in</span> list(total_counts.most_common()):</div><div class="line">            <span class="keyword">if</span>(cnt &gt;= <span class="number">50</span>):</div><div class="line">                pos_neg_ratio = positive_counts[term] / float(negative_counts[term] + <span class="number">1</span>)</div><div class="line">                pos_neg_ratios[term] = pos_neg_ratio</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> word, ratio <span class="keyword">in</span> pos_neg_ratios.most_common():</div><div class="line">            <span class="keyword">if</span>(ratio &gt; <span class="number">1</span>):</div><div class="line">                pos_neg_ratios[word] = np.log(ratio)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                pos_neg_ratios[word] = -np.log(<span class="number">1</span> / (ratio + <span class="number">0.01</span>))</div><div class="line">        </div><div class="line">        review_vocab = set()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> reviews:</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">' '</span>):</div><div class="line">                <span class="keyword">if</span>(total_counts[word] &gt; min_count):</div><div class="line">                    <span class="keyword">if</span>(word <span class="keyword">in</span> pos_neg_ratios.keys()):</div><div class="line">                        <span class="keyword">if</span>((pos_neg_ratios[word] &gt;= polarity_cutoff) <span class="keyword">or</span> (pos_neg_ratios[word] &lt;= -polarity_cutoff)):</div><div class="line">                            review_vocab.add(word)</div><div class="line">                        <span class="keyword">else</span>:</div><div class="line">                            review_vocab.add(word)</div><div class="line">        </div><div class="line">        self.review_vocab = list(review_vocab)</div><div class="line">        </div><div class="line">        label_vocab = set()</div><div class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels:</div><div class="line">            label_vocab.add(label)</div><div class="line">            </div><div class="line">        self.label_vocab = list(label_vocab)</div><div class="line">        </div><div class="line">        self.review_vocab_size = len(self.review_vocab)</div><div class="line">        self.label_vocab_size = len(self.label_vocab)</div><div class="line">        </div><div class="line">        self.word2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(self.review_vocab):</div><div class="line">            self.word2index[word] = i</div><div class="line">            </div><div class="line">        self.label2index = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(self.label_vocab):</div><div class="line">            self.label2index[label] = i</div><div class="line">            </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">(self, input_nodes, hidden_nodes, output_nodes, learning_rate)</span>:</span></div><div class="line">        <span class="comment"># Set number of nodes in input, hidden and output layers.</span></div><div class="line">        self.input_nodes = input_nodes</div><div class="line">        self.hidden_nodes = hidden_nodes</div><div class="line">        self.output_nodes = output_nodes</div><div class="line"></div><div class="line">        <span class="comment"># Initialize weights</span></div><div class="line">        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))</div><div class="line">    </div><div class="line">        self.weights_1_2 = np.random.normal(<span class="number">0.0</span>, self.output_nodes**<span class="number">-0.5</span>, </div><div class="line">                                                (self.hidden_nodes, self.output_nodes))</div><div class="line">        </div><div class="line">        self.learning_rate = learning_rate</div><div class="line">        </div><div class="line">        self.layer_0 = np.zeros((<span class="number">1</span>,input_nodes))</div><div class="line">        self.layer_1 = np.zeros((<span class="number">1</span>,hidden_nodes))</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(self,x)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid_output_2_derivative</span><span class="params">(self,output)</span>:</span></div><div class="line">        <span class="keyword">return</span> output * (<span class="number">1</span> - output)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_input_layer</span><span class="params">(self,review)</span>:</span></div><div class="line"></div><div class="line">        <span class="comment"># clear out previous state, reset the layer to be all 0s</span></div><div class="line">        self.layer_0 *= <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">            self.layer_0[<span class="number">0</span>][self.word2index[word]] = <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_target_for_label</span><span class="params">(self,label)</span>:</span></div><div class="line">        <span class="keyword">if</span>(label == <span class="string">'POSITIVE'</span>):</div><div class="line">            <span class="keyword">return</span> <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, training_reviews_raw, training_labels)</span>:</span></div><div class="line">        </div><div class="line">        training_reviews = list()</div><div class="line">        <span class="keyword">for</span> review <span class="keyword">in</span> training_reviews_raw:</div><div class="line">            indices = set()</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> review.split(<span class="string">" "</span>):</div><div class="line">                <span class="keyword">if</span>(word <span class="keyword">in</span> self.word2index.keys()):</div><div class="line">                    indices.add(self.word2index[word])</div><div class="line">            training_reviews.append(list(indices))</div><div class="line">        </div><div class="line">        <span class="keyword">assert</span>(len(training_reviews) == len(training_labels))</div><div class="line">        </div><div class="line">        correct_so_far = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(training_reviews)):</div><div class="line">            </div><div class="line">            review = training_reviews[i]</div><div class="line">            label = training_labels[i]</div><div class="line">            </div><div class="line">            <span class="comment">#### Implement the forward pass here ####</span></div><div class="line">            <span class="comment">### Forward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># Input Layer</span></div><div class="line"></div><div class="line">            <span class="comment"># Hidden layer</span></div><div class="line"><span class="comment">#             layer_1 = self.layer_0.dot(self.weights_0_1)</span></div><div class="line">            self.layer_1 *= <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> review:</div><div class="line">                self.layer_1 += self.weights_0_1[index]</div><div class="line">            </div><div class="line">            <span class="comment"># Output layer</span></div><div class="line">            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</div><div class="line"></div><div class="line">            <span class="comment">#### Implement the backward pass here ####</span></div><div class="line">            <span class="comment">### Backward pass ###</span></div><div class="line"></div><div class="line">            <span class="comment"># Output error</span></div><div class="line">            layer_2_error = layer_2 - self.get_target_for_label(label) <span class="comment"># Output layer error is the difference between desired target and actual output.</span></div><div class="line">            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)</div><div class="line"></div><div class="line">            <span class="comment"># Backpropagated error</span></div><div class="line">            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) <span class="comment"># errors propagated to the hidden layer</span></div><div class="line">            layer_1_delta = layer_1_error <span class="comment"># hidden layer gradients - no nonlinearity so it's the same as the error</span></div><div class="line"></div><div class="line">            <span class="comment"># Update the weights</span></div><div class="line">            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate <span class="comment"># update hidden-to-output weights with gradient descent step</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> review:</div><div class="line">                self.weights_0_1[index] -= layer_1_delta[<span class="number">0</span>] * self.learning_rate <span class="comment"># update input-to-hidden weights with gradient descent step</span></div><div class="line"></div><div class="line">            <span class="keyword">if</span>(np.abs(layer_2_error) &lt; <span class="number">0.5</span>):</div><div class="line">                correct_so_far += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(training_reviews)))[:<span class="number">4</span>] + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] + <span class="string">" #Correct:"</span> + str(correct_so_far) + <span class="string">" #Trained:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Training Accuracy:"</span> + str(correct_so_far * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">        </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self, testing_reviews, testing_labels)</span>:</span></div><div class="line">        </div><div class="line">        correct = <span class="number">0</span></div><div class="line">        </div><div class="line">        start = time.time()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testing_reviews)):</div><div class="line">            pred = self.run(testing_reviews[i])</div><div class="line">            <span class="keyword">if</span>(pred == testing_labels[i]):</div><div class="line">                correct += <span class="number">1</span></div><div class="line">            </div><div class="line">            reviews_per_second = i / float(time.time() - start)</div><div class="line">            </div><div class="line">            sys.stdout.write(<span class="string">"\rProgress:"</span> + str(<span class="number">100</span> * i/float(len(testing_reviews)))[:<span class="number">4</span>] \</div><div class="line">                             + <span class="string">"% Speed(reviews/sec):"</span> + str(reviews_per_second)[<span class="number">0</span>:<span class="number">5</span>] \</div><div class="line">                            + <span class="string">" #Correct:"</span> + str(correct) + <span class="string">" #Tested:"</span> + str(i+<span class="number">1</span>) + <span class="string">" Testing Accuracy:"</span> + str(correct * <span class="number">100</span> / float(i+<span class="number">1</span>))[:<span class="number">4</span>] + <span class="string">"%"</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, review)</span>:</span></div><div class="line">        </div><div class="line">        <span class="comment"># Input Layer</span></div><div class="line"></div><div class="line"></div><div class="line">        <span class="comment"># Hidden layer</span></div><div class="line">        self.layer_1 *= <span class="number">0</span></div><div class="line">        unique_indices = set()</div><div class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> review.lower().split(<span class="string">" "</span>):</div><div class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> self.word2index.keys():</div><div class="line">                unique_indices.add(self.word2index[word])</div><div class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> unique_indices:</div><div class="line">            self.layer_1 += self.weights_0_1[index]</div><div class="line">        </div><div class="line">        <span class="comment"># Output layer</span></div><div class="line">        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</div><div class="line">        </div><div class="line">        <span class="keyword">if</span>(layer_2[<span class="number">0</span>] &gt; <span class="number">0.5</span>):</div><div class="line">            <span class="keyword">return</span> <span class="string">"POSITIVE"</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">"NEGATIVE"</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], min_count=<span class="number">20</span>, polarity_cutoff=<span class="number">0.05</span>, learning_rate=<span class="number">0.01</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):2550. #Correct:20282 #Trained:24000 Training Accuracy:84.5%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp.test(reviews[<span class="number">-1000</span>:],labels[<span class="number">-1000</span>:])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):3239. #Correct:855 #Tested:1000 Testing Accuracy:85.5%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp = SentimentNetwork(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>], min_count=<span class="number">20</span>, polarity_cutoff=<span class="number">0.8</span>, learning_rate=<span class="number">0.01</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp.train(reviews[:<span class="number">-1000</span>],labels[:<span class="number">-1000</span>])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):2566. #Correct:20282 #Trained:24000 Training Accuracy:84.5%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mlp.test(reviews[<span class="number">-1000</span>:],labels[<span class="number">-1000</span>:])</div></pre></td></tr></table></figure>
<pre><code>Progress:99.9% Speed(reviews/sec):3238. #Correct:855 #Tested:1000 Testing Accuracy:85.5%
</code></pre><hr>
<h2 id="博客地址：52ml-me"><a href="#博客地址：52ml-me" class="headerlink" title="博客地址：52ml.me"></a>博客地址：<a href="http://www.52ml.me" target="_blank" rel="external">52ml.me</a></h2>
      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/assets/img/weixin.jpg">
                      <span class="reward-type">微信</span>
                    </div>
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">纳米学位</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">DLND</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="http://s.jiathis.com/qrcode.php?url=http://52ml.me/2017/02/12/How-To-Frame-Problems-for-a-Neural-Network/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2017/02/13/Sentiment-analysis-with-TFLearn/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          Sentiment analysis with TFLearn
        
      </div>
    </a>
  
  
    <a href="/2017/02/05/Predicting-daily-bike-rental-ridership/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Predicting daily bike rental ridership</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>






  
    <div class="duoshuo"></div>
  




          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2017 Vincent
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(r){if(e[r])return e[r].exports;var o=e[r]={exports:{},id:r,loaded:!1};return t[r].call(o.exports,o,o.exports,n),o.loaded=!0,o.exports}var e={};return n.m=t,n.c=e,n.p="./",n(0)}([function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}function o(t,n){var e=/\/|index.html/g;return t.replace(e,"")===n.replace(e,"")}function i(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,e=0,r=t.length;e<r;e++){var i=t[e];o(n,i.getAttribute("href"))&&(0,d.default)(i,"active")}}function u(t){for(var n=t.offsetLeft,e=t.offsetParent;null!==e;)n+=e.offsetLeft,e=e.offsetParent;return n}function f(t){for(var n=t.offsetTop,e=t.offsetParent;null!==e;)n+=e.offsetTop,e=e.offsetParent;return n}function c(t,n,e,r,o){var i=u(t),c=f(t)-n;if(c-e<=o){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,h.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(e||c)+"px",a.style.left=i+"px",a.style.zIndex=r||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");c(t,document.body.scrollTop,-63,2,0),c(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}function l(){x.default.versions.mobile&&window.screen.width<800&&(i(),s())}var p=e(71),d=r(p),v=e(72),y=(r(v),e(84)),h=r(y),b=e(69),x=r(b),m=e(75),g=r(m),w=e(70);l(),(0,w.addLoadEvent)(function(){g.default.init()}),t.exports={}},function(t,n){var e=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=e)},function(t,n){var e={}.hasOwnProperty;t.exports=function(t,n){return e.call(t,n)}},function(t,n,e){var r=e(49),o=e(15);t.exports=function(t){return r(o(t))}},function(t,n,e){t.exports=!e(8)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,e){var r=e(6),o=e(12);t.exports=e(4)?function(t,n,e){return r.f(t,n,o(1,e))}:function(t,n,e){return t[n]=e,t}},function(t,n,e){var r=e(10),o=e(30),i=e(24),u=Object.defineProperty;n.f=e(4)?Object.defineProperty:function(t,n,e){if(r(t),n=i(n,!0),r(e),o)try{return u(t,n,e)}catch(t){}if("get"in e||"set"in e)throw TypeError("Accessors not supported!");return"value"in e&&(t[n]=e.value),t}},function(t,n,e){var r=e(22)("wks"),o=e(13),i=e(1).Symbol,u="function"==typeof i,f=t.exports=function(t){return r[t]||(r[t]=u&&i[t]||(u?i:o)("Symbol."+t))};f.store=r},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,e){var r=e(35),o=e(16);t.exports=Object.keys||function(t){return r(t,o)}},function(t,n,e){var r=e(11);t.exports=function(t){if(!r(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var e=0,r=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++e+r).toString(36))}},function(t,n){var e=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=e)},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,e){var r=e(6).f,o=e(2),i=e(7)("toStringTag");t.exports=function(t,n,e){t&&!o(t=e?t:t.prototype,i)&&r(t,i,{configurable:!0,value:n})}},function(t,n,e){var r=e(22)("keys"),o=e(13);t.exports=function(t){return r[t]||(r[t]=o(t))}},function(t,n,e){var r=e(1),o="__core-js_shared__",i=r[o]||(r[o]={});t.exports=function(t){return i[t]||(i[t]={})}},function(t,n){var e=Math.ceil,r=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?r:e)(t)}},function(t,n,e){var r=e(11);t.exports=function(t,n){if(!r(t))return t;var e,o;if(n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;if("function"==typeof(e=t.valueOf)&&!r(o=e.call(t)))return o;if(!n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;throw TypeError("Can't convert object to primitive value")}},function(t,n,e){var r=e(1),o=e(14),i=e(18),u=e(26),f=e(6).f;t.exports=function(t){var n=o.Symbol||(o.Symbol=i?{}:r.Symbol||{});"_"==t.charAt(0)||t in n||f(n,t,{value:u.f(t)})}},function(t,n,e){n.f=e(7)},function(t,n,e){var r=e(1),o=e(14),i=e(46),u=e(5),f="prototype",c=function(t,n,e){var a,s,l,p=t&c.F,d=t&c.G,v=t&c.S,y=t&c.P,h=t&c.B,b=t&c.W,x=d?o:o[n]||(o[n]={}),m=x[f],g=d?r:v?r[n]:(r[n]||{})[f];d&&(e=n);for(a in e)s=!p&&g&&void 0!==g[a],s&&a in x||(l=s?g[a]:e[a],x[a]=d&&"function"!=typeof g[a]?e[a]:h&&s?i(l,r):b&&g[a]==l?function(t){var n=function(n,e,r){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,e)}return new t(n,e,r)}return t.apply(this,arguments)};return n[f]=t[f],n}(l):y&&"function"==typeof l?i(Function.call,l):l,y&&((x.virtual||(x.virtual={}))[a]=l,t&c.R&&m&&!m[a]&&u(m,a,l)))};c.F=1,c.G=2,c.S=4,c.P=8,c.B=16,c.W=32,c.U=64,c.R=128,t.exports=c},function(t,n){var e={}.toString;t.exports=function(t){return e.call(t).slice(8,-1)}},function(t,n,e){var r=e(11),o=e(1).document,i=r(o)&&r(o.createElement);t.exports=function(t){return i?o.createElement(t):{}}},function(t,n,e){t.exports=!e(4)&&!e(8)(function(){return 7!=Object.defineProperty(e(29)("div"),"a",{get:function(){return 7}}).a})},function(t,n,e){"use strict";var r=e(18),o=e(27),i=e(36),u=e(5),f=e(2),c=e(17),a=e(51),s=e(20),l=e(58),p=e(7)("iterator"),d=!([].keys&&"next"in[].keys()),v="@@iterator",y="keys",h="values",b=function(){return this};t.exports=function(t,n,e,x,m,g,w){a(e,n,x);var O,S,_,j=function(t){if(!d&&t in A)return A[t];switch(t){case y:return function(){return new e(this,t)};case h:return function(){return new e(this,t)}}return function(){return new e(this,t)}},P=n+" Iterator",E=m==h,M=!1,A=t.prototype,T=A[p]||A[v]||m&&A[m],L=T||j(m),N=m?E?j("entries"):L:void 0,C="Array"==n?A.entries||T:T;if(C&&(_=l(C.call(new t)),_!==Object.prototype&&(s(_,P,!0),r||f(_,p)||u(_,p,b))),E&&T&&T.name!==h&&(M=!0,L=function(){return T.call(this)}),r&&!w||!d&&!M&&A[p]||u(A,p,L),c[n]=L,c[P]=b,m)if(O={values:E?L:j(h),keys:g?L:j(y),entries:N},w)for(S in O)S in A||i(A,S,O[S]);else o(o.P+o.F*(d||M),n,O);return O}},function(t,n,e){var r=e(10),o=e(55),i=e(16),u=e(21)("IE_PROTO"),f=function(){},c="prototype",a=function(){var t,n=e(29)("iframe"),r=i.length,o="<",u=">";for(n.style.display="none",e(48).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write(o+"script"+u+"document.F=Object"+o+"/script"+u),t.close(),a=t.F;r--;)delete a[c][i[r]];return a()};t.exports=Object.create||function(t,n){var e;return null!==t?(f[c]=r(t),e=new f,f[c]=null,e[u]=t):e=a(),void 0===n?e:o(e,n)}},function(t,n,e){var r=e(35),o=e(16).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return r(t,o)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,e){var r=e(2),o=e(3),i=e(45)(!1),u=e(21)("IE_PROTO");t.exports=function(t,n){var e,f=o(t),c=0,a=[];for(e in f)e!=u&&r(f,e)&&a.push(e);for(;n.length>c;)r(f,e=n[c++])&&(~i(a,e)||a.push(e));return a}},function(t,n,e){t.exports=e(5)},function(t,n,e){var r=e(15);t.exports=function(t){return Object(r(t))}},function(t,n,e){t.exports={default:e(41),__esModule:!0}},function(t,n,e){t.exports={default:e(42),__esModule:!0}},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var o=e(39),i=r(o),u=e(38),f=r(u),c="function"==typeof f.default&&"symbol"==typeof i.default?function(t){return typeof t}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":typeof t};n.default="function"==typeof f.default&&"symbol"===c(i.default)?function(t){return"undefined"==typeof t?"undefined":c(t)}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":"undefined"==typeof t?"undefined":c(t)}},function(t,n,e){e(65),e(63),e(66),e(67),t.exports=e(14).Symbol},function(t,n,e){e(64),e(68),t.exports=e(26).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,e){var r=e(3),o=e(61),i=e(60);t.exports=function(t){return function(n,e,u){var f,c=r(n),a=o(c.length),s=i(u,a);if(t&&e!=e){for(;a>s;)if(f=c[s++],f!=f)return!0}else for(;a>s;s++)if((t||s in c)&&c[s]===e)return t||s||0;return!t&&-1}}},function(t,n,e){var r=e(43);t.exports=function(t,n,e){if(r(t),void 0===n)return t;switch(e){case 1:return function(e){return t.call(n,e)};case 2:return function(e,r){return t.call(n,e,r)};case 3:return function(e,r,o){return t.call(n,e,r,o)}}return function(){return t.apply(n,arguments)}}},function(t,n,e){var r=e(9),o=e(34),i=e(19);t.exports=function(t){var n=r(t),e=o.f;if(e)for(var u,f=e(t),c=i.f,a=0;f.length>a;)c.call(t,u=f[a++])&&n.push(u);return n}},function(t,n,e){t.exports=e(1).document&&document.documentElement},function(t,n,e){var r=e(28);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==r(t)?t.split(""):Object(t)}},function(t,n,e){var r=e(28);t.exports=Array.isArray||function(t){return"Array"==r(t)}},function(t,n,e){"use strict";var r=e(32),o=e(12),i=e(20),u={};e(5)(u,e(7)("iterator"),function(){return this}),t.exports=function(t,n,e){t.prototype=r(u,{next:o(1,e)}),i(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,e){var r=e(9),o=e(3);t.exports=function(t,n){for(var e,i=o(t),u=r(i),f=u.length,c=0;f>c;)if(i[e=u[c++]]===n)return e}},function(t,n,e){var r=e(13)("meta"),o=e(11),i=e(2),u=e(6).f,f=0,c=Object.isExtensible||function(){return!0},a=!e(8)(function(){return c(Object.preventExtensions({}))}),s=function(t){u(t,r,{value:{i:"O"+ ++f,w:{}}})},l=function(t,n){if(!o(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!i(t,r)){if(!c(t))return"F";if(!n)return"E";s(t)}return t[r].i},p=function(t,n){if(!i(t,r)){if(!c(t))return!0;if(!n)return!1;s(t)}return t[r].w},d=function(t){return a&&v.NEED&&c(t)&&!i(t,r)&&s(t),t},v=t.exports={KEY:r,NEED:!1,fastKey:l,getWeak:p,onFreeze:d}},function(t,n,e){var r=e(6),o=e(10),i=e(9);t.exports=e(4)?Object.defineProperties:function(t,n){o(t);for(var e,u=i(n),f=u.length,c=0;f>c;)r.f(t,e=u[c++],n[e]);return t}},function(t,n,e){var r=e(19),o=e(12),i=e(3),u=e(24),f=e(2),c=e(30),a=Object.getOwnPropertyDescriptor;n.f=e(4)?a:function(t,n){if(t=i(t),n=u(n,!0),c)try{return a(t,n)}catch(t){}if(f(t,n))return o(!r.f.call(t,n),t[n])}},function(t,n,e){var r=e(3),o=e(33).f,i={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],f=function(t){try{return o(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==i.call(t)?f(t):o(r(t))}},function(t,n,e){var r=e(2),o=e(37),i=e(21)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=o(t),r(t,i)?t[i]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,e){var r=e(23),o=e(15);t.exports=function(t){return function(n,e){var i,u,f=String(o(n)),c=r(e),a=f.length;return c<0||c>=a?t?"":void 0:(i=f.charCodeAt(c),i<55296||i>56319||c+1===a||(u=f.charCodeAt(c+1))<56320||u>57343?t?f.charAt(c):i:t?f.slice(c,c+2):(i-55296<<10)+(u-56320)+65536)}}},function(t,n,e){var r=e(23),o=Math.max,i=Math.min;t.exports=function(t,n){return t=r(t),t<0?o(t+n,0):i(t,n)}},function(t,n,e){var r=e(23),o=Math.min;t.exports=function(t){return t>0?o(r(t),9007199254740991):0}},function(t,n,e){"use strict";var r=e(44),o=e(52),i=e(17),u=e(3);t.exports=e(31)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,e=this._i++;return!t||e>=t.length?(this._t=void 0,o(1)):"keys"==n?o(0,e):"values"==n?o(0,t[e]):o(0,[e,t[e]])},"values"),i.Arguments=i.Array,r("keys"),r("values"),r("entries")},function(t,n){},function(t,n,e){"use strict";var r=e(59)(!0);e(31)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,e=this._i;return e>=n.length?{value:void 0,done:!0}:(t=r(n,e),this._i+=t.length,{value:t,done:!1})})},function(t,n,e){"use strict";var r=e(1),o=e(2),i=e(4),u=e(27),f=e(36),c=e(54).KEY,a=e(8),s=e(22),l=e(20),p=e(13),d=e(7),v=e(26),y=e(25),h=e(53),b=e(47),x=e(50),m=e(10),g=e(3),w=e(24),O=e(12),S=e(32),_=e(57),j=e(56),P=e(6),E=e(9),M=j.f,A=P.f,T=_.f,L=r.Symbol,N=r.JSON,C=N&&N.stringify,k="prototype",F=d("_hidden"),q=d("toPrimitive"),I={}.propertyIsEnumerable,B=s("symbol-registry"),D=s("symbols"),W=s("op-symbols"),H=Object[k],K="function"==typeof L,R=r.QObject,J=!R||!R[k]||!R[k].findChild,U=i&&a(function(){return 7!=S(A({},"a",{get:function(){return A(this,"a",{value:7}).a}})).a})?function(t,n,e){var r=M(H,n);r&&delete H[n],A(t,n,e),r&&t!==H&&A(H,n,r)}:A,G=function(t){var n=D[t]=S(L[k]);return n._k=t,n},$=K&&"symbol"==typeof L.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof L},z=function(t,n,e){return t===H&&z(W,n,e),m(t),n=w(n,!0),m(e),o(D,n)?(e.enumerable?(o(t,F)&&t[F][n]&&(t[F][n]=!1),e=S(e,{enumerable:O(0,!1)})):(o(t,F)||A(t,F,O(1,{})),t[F][n]=!0),U(t,n,e)):A(t,n,e)},Y=function(t,n){m(t);for(var e,r=b(n=g(n)),o=0,i=r.length;i>o;)z(t,e=r[o++],n[e]);return t},Q=function(t,n){return void 0===n?S(t):Y(S(t),n)},X=function(t){var n=I.call(this,t=w(t,!0));return!(this===H&&o(D,t)&&!o(W,t))&&(!(n||!o(this,t)||!o(D,t)||o(this,F)&&this[F][t])||n)},V=function(t,n){if(t=g(t),n=w(n,!0),t!==H||!o(D,n)||o(W,n)){var e=M(t,n);return!e||!o(D,n)||o(t,F)&&t[F][n]||(e.enumerable=!0),e}},Z=function(t){for(var n,e=T(g(t)),r=[],i=0;e.length>i;)o(D,n=e[i++])||n==F||n==c||r.push(n);return r},tt=function(t){for(var n,e=t===H,r=T(e?W:g(t)),i=[],u=0;r.length>u;)!o(D,n=r[u++])||e&&!o(H,n)||i.push(D[n]);return i};K||(L=function(){if(this instanceof L)throw TypeError("Symbol is not a constructor!");var t=p(arguments.length>0?arguments[0]:void 0),n=function(e){this===H&&n.call(W,e),o(this,F)&&o(this[F],t)&&(this[F][t]=!1),U(this,t,O(1,e))};return i&&J&&U(H,t,{configurable:!0,set:n}),G(t)},f(L[k],"toString",function(){return this._k}),j.f=V,P.f=z,e(33).f=_.f=Z,e(19).f=X,e(34).f=tt,i&&!e(18)&&f(H,"propertyIsEnumerable",X,!0),v.f=function(t){return G(d(t))}),u(u.G+u.W+u.F*!K,{Symbol:L});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),et=0;nt.length>et;)d(nt[et++]);for(var nt=E(d.store),et=0;nt.length>et;)y(nt[et++]);u(u.S+u.F*!K,"Symbol",{for:function(t){return o(B,t+="")?B[t]:B[t]=L(t)},keyFor:function(t){if($(t))return h(B,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){J=!0},useSimple:function(){J=!1}}),u(u.S+u.F*!K,"Object",{create:Q,defineProperty:z,defineProperties:Y,getOwnPropertyDescriptor:V,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),N&&u(u.S+u.F*(!K||a(function(){var t=L();return"[null]"!=C([t])||"{}"!=C({a:t})||"{}"!=C(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!$(t)){for(var n,e,r=[t],o=1;arguments.length>o;)r.push(arguments[o++]);return n=r[1],"function"==typeof n&&(e=n),!e&&x(n)||(n=function(t,n){if(e&&(n=e.call(this,t,n)),!$(n))return n}),r[1]=n,C.apply(N,r)}}}),L[k][q]||e(5)(L[k],q,L[k].valueOf),l(L,"Symbol"),l(Math,"Math",!0),l(r.JSON,"JSON",!0)},function(t,n,e){e(25)("asyncIterator")},function(t,n,e){e(25)("observable")},function(t,n,e){e(62);for(var r=e(1),o=e(5),i=e(17),u=e(7)("toStringTag"),f=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],c=0;c<5;c++){var a=f[c],s=r[a],l=s&&s.prototype;l&&!l[u]&&o(l,u,a),i[a]=i.Array}},function(t,n){"use strict";var e={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&t.indexOf("KHTML")==-1,mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:t.indexOf("Safari")==-1,weixin:t.indexOf("MicroMessenger")==-1}}()};t.exports=e},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}var o=e(40),i=r(o),u=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):o[t]||t}function n(t){return l[t]}var e=/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,r=/['<> "&]/g,o={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},f=/\u00a0/g,c=/<br\s*\/?>/gi,a=/\r?\n/g,s=/\s/g,l={};for(var p in o)l[o[p]]=p;return o["&apos;"]="'",l["'"]="&#39;",{encode:function(t){return t?(""+t).replace(r,n).replace(a,"<br/>").replace(s,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(c,"\n").replace(e,t).replace(f," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e+=2)n.push(String.fromCharCode("0x"+t.slice(e,e+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,e=t.length;e>n;n++)t[n]=u.encodeObject(t[n]);else if("object"==("undefined"==typeof t?"undefined":(0,i.default)(t)))for(var r in t)t[r]=u.encodeObject(t[r]);else if("string"==typeof t)return u.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=u},function(t,n){function e(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=e},function(t,n){function e(t,n){if(t.classList)t.classList.remove(n);else{var e=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(e," ")}}t.exports=e},,,function(t,n){"use strict";function e(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){var n=document.querySelectorAll(".article-entry a:not(.article-more-a)");n.forEach(function(t){t.setAttribute("target","_blank")})}var e=document.querySelector("#js-aboutme");e&&0!==e.length&&(e.innerHTML=e.innerText)}t.exports={init:e}},,,,,,,,,function(t,n){function e(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var e=t.nextSibling;return e?t.parentNode.insertBefore(n,e):t.parentNode.appendChild(n)}t.exports=e}])</script><script src="/./main.2d7529.js"></script><script>!function(){var e=function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)};e("/slider.885efe.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 50%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 50%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">ml</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">纳米学位</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">DLND</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">MLND</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">cs231n</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">tips</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">学习计划</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            2、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: true
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">我是Vincent&lt;br&gt;&lt;br&gt;热衷于机器学习，移动应用开发，&lt;br&gt;欢迎交流！</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>