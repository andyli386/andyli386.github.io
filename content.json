[{"title":"预测波士顿房价","date":"2017-01-21T07:02:02.000Z","path":"2017/01/21/预测波士顿房价/","text":"模型评价与验证项目 1: 预测波士顿房价欢迎来到机器学习工程师纳米学位的第一个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能来让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以‘练习’开始的标题表示接下来的内容中有需要你必须实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以‘TODO’标出。请仔细阅读所有的提示！ 除了实现代码外，你还必须回答一些与项目和实现有关的问题。每一个需要你回答的问题都会以‘问题 X’为标题。请仔细阅读每个问题，并且在问题后的‘回答’文字框中写出完整的答案。你的项目将会根据你对问题的回答和撰写代码所实现的功能来进行评分。 提示：Code 和 Markdown 区域可通过 Shift + Enter 快捷键运行。此外，Markdown可以通过双击进入编辑模式。 开始 在这个项目中，你将利用马萨诸塞州波士顿郊区的房屋信息数据训练和测试一个模型，并对模型的性能和预测能力进行测试。通过该数据训练后的好的模型可以被用来对房屋做特定预测—尤其是对房屋的价值。对于房地产经纪等人的日常工作来说，这样的预测模型被证明非常有价值。 此项目的数据集来自UCI机器学习知识库。波士顿房屋这些数据于1978年开始统计，共506个数据点，涵盖了麻省波士顿不同郊区房屋14种特征的信息。本项目对原始数据集做了以下处理： 有16个&#39;MEDV&#39; 值为50.0的数据点被移除。 这很可能是由于这些数据点包含遗失或看不到的值。 有1个数据点的 &#39;RM&#39; 值为8.78. 这是一个异常值，已经被移除。 对于本项目，房屋的&#39;RM&#39;， &#39;LSTAT&#39;，&#39;PTRATIO&#39;以及&#39;MEDV&#39;特征是必要的，其余不相关特征已经被移除。 &#39;MEDV&#39;特征的值已经过必要的数学转换，可以反映35年来市场的通货膨胀效应。 运行下面区域的代码以载入波士顿房屋数据集，以及一些此项目所需的Python库。如果成功返回数据集的大小，表示数据集已载入成功。 1234567891011121314151617181920# Import libraries necessary for this project# 载入此项目所需要的库import numpy as npimport pandas as pdimport visuals as vs # Supplementary codefrom sklearn.cross_validation import ShuffleSplit# Pretty display for notebooks# 让结果在notebook中显示%matplotlib inline# Load the Boston housing dataset# 载入波士顿房屋的数据集data = pd.read_csv('housing.csv')prices = data['MEDV']features = data.drop('MEDV', axis = 1) # Success# 完成print \"Boston housing dataset has &#123;&#125; data points with &#123;&#125; variables each.\".format(*data.shape) Boston housing dataset has 489 data points with 4 variables each. 分析数据在项目的第一个部分，你会对波士顿房地产数据进行初步的观察并给出你的分析。通过对数据的探索来熟悉数据可以让你更好地理解和解释你的结果。 由于这个项目的最终目标是建立一个预测房屋价值的模型，我们需要将数据集分为特征(features)和目标变量(target variable)。特征 &#39;RM&#39;， &#39;LSTAT&#39;，和 &#39;PTRATIO&#39;，给我们提供了每个数据点的数量相关的信息。目标变量：&#39;MEDV&#39;，是我们希望预测的变量。他们分别被存在features和prices两个变量名中。 练习：基础统计运算你的第一个编程练习是计算有关波士顿房价的描述统计数据。我们已为你导入了numpy，你需要使用这个库来执行必要的计算。这些统计数据对于分析模型的预测结果非常重要的。在下面的代码中，你要做的是： 计算prices中的&#39;MEDV&#39;的最小值、最大值、均值、中值和标准差； 将运算结果储存在相应的变量中。 123456789101112131415161718192021222324252627282930# TODO: Minimum price of the data#目标：计算价值的最小值minimum_price = np.min(prices)# TODO: Maximum price of the data#目标：计算价值的最大值maximum_price = np.max(prices)# TODO: Mean price of the data#目标：计算价值的平均值mean_price = np.mean(prices)# TODO: Median price of the data#目标：计算价值的中值print type(prices)median_price = np.median(prices)# TODO: Standard deviation of prices of the data#目标：计算价值的标准差std_price = np.std(prices)# Show the calculated statistics#目标：输出计算的结果print \"Statistics for Boston housing dataset:\\n\"print \"Minimum price: $&#123;:,.2f&#125;\".format(minimum_price)print \"Maximum price: $&#123;:,.2f&#125;\".format(maximum_price)print \"Mean price: $&#123;:,.2f&#125;\".format(mean_price)print \"Median price $&#123;:,.2f&#125;\".format(median_price)print \"Standard deviation of prices: $&#123;:,.2f&#125;\".format(std_price) &lt;class &apos;pandas.core.series.Series&apos;&gt; Statistics for Boston housing dataset: Minimum price: $105,000.00 Maximum price: $1,024,800.00 Mean price: $454,342.94 Median price $438,900.00 Standard deviation of prices: $165,171.13 问题1 - 特征观察如前文所述，本项目中我们关注的是其中三个值:&#39;RM&#39;、&#39;LSTAT&#39; 和&#39;PTRATIO&#39;，对每一个数据点: &#39;RM&#39; 是该地区中每个房屋的平均房间数量； &#39;LSTAT&#39; 是指该地区有多少百分比的房东属于是低收入阶层（有工作但收入微薄）； &#39;PTRATIO&#39; 是该地区的中学和小学里，学生和老师的数目比（学生/老师）。 凭直觉，上述三个特征中对每一个来说，你认为增大该特征的数值，&#39;MEDV&#39;的值会是增大还是减小呢？每一个答案都需要你给出理由。 提示：你预期一个&#39;RM&#39; 值是6的房屋跟&#39;RM&#39; 值是7的房屋相比，价值更高还是更低呢？ 回答: 增大RM，MEDV会增大，因为房间多了，房子的总面积会增大，因此MEDV会增大 增大LATAT，MEDV会减小，因为低收入阶层多了，该地区的消费能力就会降低，因此MEDV会减少 增大PTRATIO，MEDV会减小，因为学生多老师少，说明该地区教育投入有限，家长不愿意让小孩在这个地方上学，因此MEDV会减少 建模在项目的第二部分中，你需要了解必要的工具和技巧来让你的模型进行预测。用这些工具和技巧对每一个模型的表现做精确的衡量可以极大地增强你预测的信心。 练习：定义衡量标准如果不能对模型的训练和测试的表现进行量化地评估，我们就很难衡量模型的好坏。通常我们会定义一些衡量标准，这些标准可以通过对某些误差或者拟合程度的计算来得到。在这个项目中，你将通过运算决定系数R2 来量化模型的表现。模型的决定系数是回归分析中十分常用的统计信息，经常被当作衡量模型预测能力好坏的标准。 R2的数值范围从0至1，表示目标变量的预测值和实际值之间的相关程度平方的百分比。一个模型的R2 值为0还不如直接用平均值来预测效果好；而一个R2 值为1的模型则可以对目标变量进行完美的预测。从0至1之间的数值，则表示该模型中目标变量中有百分之多少能够用特征来解释。_模型也可能出现负值的R2，这种情况下模型所做预测有时会比直接计算目标变量的平均值差很多。 在下方代码的 performance_metric 函数中，你要实现： 使用 sklearn.metrics 中的 r2_score 来计算 y_true 和 y_predict的R2值，作为对其表现的评判。 将他们的表现评分储存到score变量中。 1234567891011# TODO: Import 'r2_score'from sklearn.metrics import r2_scoredef performance_metric(y_true, y_predict): \"\"\" Calculates and returns the performance score between true and predicted values based on the metric chosen. \"\"\" # TODO: Calculate the performance score between 'y_true' and 'y_predict' score = r2_score(y_true, y_predict) # Return the score return score 问题2 - 拟合程度假设一个数据集有五个数据且一个模型做出下列目标变量的预测： 真实数值 预测数值 3.0 2.5 -0.5 0.0 2.0 2.1 7.0 7.8 4.2 5.3 你会觉得这个模型已成功地描述了目标变量的变化吗？如果成功，请解释为什么，如果没有，也请给出原因。 运行下方的代码，使用performance_metric函数来计算模型的决定系数。 123# Calculate the performance of this modelscore = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])print \"Model has a coefficient of determination, R^2, of &#123;:.3f&#125;.\".format(score) Model has a coefficient of determination, R^2, of 0.923. 回答: 已经成功的描述了目标变量的变化，因为决定系数已经非常高了。 练习: 数据分割与重排接下来，你需要把波士顿房屋数据集分成训练和测试两个子集。通常在这个过程中，数据也会被重新排序，以消除数据集中由于排序而产生的偏差。在下面的代码中，你需要： 使用 sklearn.cross_validation 中的 train_test_split， 将features和prices的数据都分成用于训练的数据子集和用于测试的数据子集。 分割比例为：80%的数据用于训练，20%用于测试； 选定一个数值以设定 train_test_split 中的 random_state ，这会确保结果的一致性； 最终分离出的子集为X_train,X_test,y_train,和y_test。 12345678# TODO: Import 'train_test_split'from sklearn.cross_validation import train_test_split# TODO: Shuffle and split the data into training and testing subsetsX_train, X_test, y_train, y_test = train_test_split(features, prices, test_size=0.2, random_state=30)# Successprint \"Training and testing split was successful.\" Training and testing split was successful. 问题 3- 训练及测试将数据集按一定比例分为训练用的数据集和测试用的数据集对学习算法有什么好处？ 提示： 如果没有数据来对模型进行测试，会出现什么问题？ 答案: 测试可以用来评估模型对未知数据的预测能力。如果没有进行测试，就无法得知对未知数据的预测是否可靠。 分析模型的表现在项目的第三部分，我们来看一下几个模型针对不同的数据集在学习和测试上的表现。另外，你需要专注于一个特定的算法，用全部训练集训练时，提高它的&#39;max_depth&#39; 参数，观察这一参数的变化如何影响模型的表现。把你模型的表现画出来对于分析过程十分有益。可视化可以让我们看到一些单看结果看不到的行为。 学习曲线下方区域内的代码会输出四幅图像，它们是一个决策树模型在不同最大深度下的表现。每一条曲线都直观的显示了随着训练数据量的增加，模型学习曲线的训练评分和测试评分的变化。注意，曲线的阴影区域代表的是该曲线的不确定性（用标准差衡量）。这个模型的训练和测试部分都使用决定系数R2来评分。 运行下方区域中的代码，并利用输出的图形回答下面的问题。 12# Produce learning curves for varying training set sizes and maximum depthsvs.ModelLearning(features, prices) /Users/vincent/anaconda/envs/dato-env/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison if self._edgecolors == str(&apos;face&apos;): 问题 4 - 学习数据选择上述图像中的其中一个，并给出其最大深度。随着训练数据量的增加，训练曲线的评分有怎样的变化？测试曲线呢？如果有更多的训练数据，是否能有效提升模型的表现呢？提示：学习曲线的评分是否最终会收敛到特定的值？ 答案: max_depth=3时，开始随着训练数据量增加，训练数据0-50时，训练曲线的评分逐渐减少，测试曲线开始阶段增加很快；训练数据50之后，测试曲线逐渐趋于某个特定的数值0.8。数据量足够大时再增加训练数据不能有效提升模型的表现。 复杂度曲线下列代码内的区域会输出一幅图像，它展示了一个已经经过训练和验证的决策树模型在不同最大深度条件下的表现。这个图形将包含两条曲线，一个是训练的变化，一个是测试的变化。跟学习曲线相似，阴影区域代表该曲线的不确定性，模型训练和测试部分的评分都用的 performance_metric 函数。 运行下方区域中的代码，并利用输出的图形并回答下面的两个问题。 1vs.ModelComplexity(X_train, y_train) 问题 5- 偏差与方差之间的权衡取舍当模型以最大深度 1训练时，模型的预测是出现很大的偏差还是出现了很大的方差？当模型以最大深度10训练时，情形又如何呢？图形中的哪些特征能够支持你的结论？ 提示： 你如何得知模型是否出现了偏差很大或者方差很大的问题？ 答案: 最大深度1训练时，出现了很大的偏差，因为评分最低阴影区域相对集中并且训练和测试得分都不高，最大深度10训练时，出现了很大的方差，因为评分相对比较高，但是阴影区域范围大，并且训练得分和测试得分相差比较大。 问题 6- 最优模型的猜测你认为最大深度是多少的模型能够最好地对未见过的数据进行预测？为什么你会得出了这个答案？ 答案: 最大深度为4时可以最好的对未见过的数据进行预测，因为这是评分最高，而且阴影区域波动相对较小。 评价模型表现在这个项目的最后，你将自己建立模型，并使用最优化的fit_model函数，基于客户房子的特征来预测该房屋的价值。 问题 7- 网格搜索（Grid Search）什么是网格搜索法？如何用它来优化学习算法？ 回答: 用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。 问题 8- 交叉验证什么是K折交叉验证法（k-fold cross-validation）？优化模型时，使用这种方法对网格搜索有什么好处？ 提示： 跟为何需要一组训练集的原因差不多，网格搜索时如果不使用交叉验证会有什么问题？ 答案: 将数据集分成K份，每一次训练都选取其中一份用来做测试，其他用来训练，训练K次，最后求出平均值。可以选择最佳的参数组合。K折交叉验证法可以验证网格搜索到的参数是否可以达到最佳效果。 练习：训练模型在最后一个练习中，你将需要将所学到的内容整合，使用决策树演算法训练一个模型。为了保证你得出的是一个最优模型，你需要使用网格搜索法训练模型，以找到最佳的 &#39;max_depth&#39; 参数。你可以把&#39;max_depth&#39; 参数理解为决策树算法在做出预测前，允许其对数据提出问题的数量。决策树是监督学习算法中的一种。 此外，你会发现你的实现使用的是 ShuffleSplit() 。它也是交叉验证的一种方式（见变量 &#39;cv_sets&#39;）。虽然这不是问题8中描述的 K-Fold 交叉验证，这个教程验证方法也很有用！这里 ShuffleSplit() 会创造十个混洗过的集合，每个集合中20%(&#39;test_size&#39;)的数据会被用作验证集。当你在实现的时候，想一想这跟 K-Fold 交叉验证有哪些相同点，哪些不同点？ 在下方 fit_model 函数中，你需要做的是： 使用 sklearn.tree 中的 DecisionTreeRegressor 创建一个决策树的回归函数； 将这个回归函数储存到 &#39;regressor&#39; 变量中； 为 &#39;max_depth&#39; 创造一个字典，它的值是从1至10的数组，并储存到 &#39;params&#39; 变量中； 使用 sklearn.metrics 中的 make_scorer 创建一个评分函数； 将 performance_metric 作为参数传至这个函数中； 将评分函数储存到 &#39;scoring_fnc&#39; 变量中； 使用 sklearn.grid_search 中的 GridSearchCV 创建一个网格搜索对象； 将变量&#39;regressor&#39;, &#39;params&#39;, &#39;scoring_fnc&#39;, 和 &#39;cv_sets&#39; 作为参数传至这个对象中； 将 GridSearchCV 存到 &#39;grid&#39; 变量中。 1234567891011121314151617181920212223242526272829# TODO: Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'from sklearn.tree import DecisionTreeRegressorfrom sklearn.metrics import make_scorerfrom sklearn.grid_search import GridSearchCVdef fit_model(X, y): \"\"\" Performs grid search over the 'max_depth' parameter for a decision tree regressor trained on the input data [X, y]. \"\"\" # Create cross-validation sets from the training data cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0) # TODO: Create a decision tree regressor object regressor = DecisionTreeRegressor(random_state=30) # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10 params = &#123;'max_depth':[i+1 for i in range(10)]&#125; # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' scoring_fnc = make_scorer(performance_metric) # TODO: Create the grid search object grid = GridSearchCV(regressor, params, scoring=scoring_fnc, cv=cv_sets) # Fit the grid search object to the data to compute the optimal model grid = grid.fit(X, y) # Return the optimal model after fitting the data return grid.best_estimator_ 做出预测当我们用数据训练出一个模型，它现在就可用于对新的数据进行预测。在决策树回归函数中，模型已经学会对新输入的数据提问，并返回对目标变量的预测值。你可以用这个预测来获取数据未知目标变量的信息，这些数据必须是不包含在训练数据之内的。 问题 9- 最优模型最优模型的最大深度（maximum depth）是多少？此答案与你在问题 6所做的猜测是否相同？ 运行下方区域内的代码，将决策树回归函数代入训练数据的集合，以得到最优化的模型。 12345# Fit the training data to the model using grid searchreg = fit_model(X_train, y_train)# Produce the value for 'max_depth'print \"Parameter 'max_depth' is &#123;&#125; for the optimal model.\".format(reg.get_params()['max_depth']) Parameter &apos;max_depth&apos; is 4 for the optimal model. Answer: 4，与问题6中的猜测相同。 问题 10 - 预测销售价格想像你是一个在波士顿地区的房屋经纪人，并期待使用此模型以帮助你的客户评估他们想出售的房屋。你已经从你的三个客户收集到以下的资讯: 特征 客戶 1 客戶 2 客戶 3 房屋内房间总数 5 间房间 4 间房间 8 间房间 社区贫困指数（％被认为是贫困阶层） 17% 32% 3% 邻近学校的学生-老师比例 15：1 22：1 12：1 你会建议每位客户的房屋销售的价格为多少？从房屋特征的数值判断，这样的价格合理吗？ 提示：用你在分析数据部分计算出来的统计信息来帮助你证明你的答案。 运行下列的代码区域，使用你优化的模型来为每位客户的房屋价值做出预测。 12345678# Produce a matrix for client dataclient_data = [[5, 17, 15], # Client 1 [4, 32, 22], # Client 2 [8, 3, 12]] # Client 3# Show predictionsfor i, price in enumerate(reg.predict(client_data)): print \"Predicted selling price for Client &#123;&#125;'s home: $&#123;:,.2f&#125;\".format(i+1, price) Predicted selling price for Client 1&apos;s home: $409,752.00 Predicted selling price for Client 2&apos;s home: $220,886.84 Predicted selling price for Client 3&apos;s home: $937,650.00 答案: 客户1 409,752.00 合理，有5间房间，社会贫困指数不到1/5，学生老师比中等水平 客户2 220,886.84 合理，只有4间房间，社会贫困指数比较高，学生老师比最高，该地区对教育投入有限，家长不愿意在这里买房 客户3 937,650.00 合理，有8间房，贫困指数非常低，学生老师比最低，该地区应该是富人区，所以房间贵 敏感度一个最优的模型不一定是一个健壮模型。有的时候模型会过于复杂或者过于简单，以致于难以泛化新增添的数据；有的时候模型采用的学习算法并不适用于特定的数据结构；有的时候样本本身可能有太多噪点或样本过少，使得模型无法准确地预测目标变量。这些情况下我们会说模型是欠拟合的。执行下方区域中的代码，采用不同的训练和测试集执行 fit_model 函数10次。注意观察对一个特定的客户来说，预测是如何随训练数据的变化而变化的。 1vs.PredictTrials(features, prices, fit_model, client_data) Trial 1: $391,183.33 Trial 2: $411,417.39 Trial 3: $415,800.00 Trial 4: $428,316.00 Trial 5: $413,334.78 Trial 6: $411,931.58 Trial 7: $399,663.16 Trial 8: $407,232.00 Trial 9: $402,531.82 Trial 10: $413,700.00 Range in prices: $37,132.67 问题 11 - 实用性探讨简单地讨论一下你建构的模型能否在现实世界中使用？ 提示： 回答几个问题： 1978年所采集的数据，在今天是否仍然适用？ 数据中呈现的特征是否足够描述一个房屋？ 模型是否足够健壮来保证预测的一致性？ 在波士顿这样的大都市采集的数据，能否应用在其它乡镇地区？ 答案: 不能够，要考虑到通货膨胀等因素 不够，还要有房子的新旧程度，房子面子，是否有车库游泳池等 可以保证一致性，因为波动范围比较小 不适用其他乡镇地区 综上，该模型不适合在现实世界中使用 12 博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[{"name":"机器学习工程师纳米学位","slug":"机器学习工程师纳米学位","permalink":"http://52ml.me/tags/机器学习工程师纳米学位/"}]},{"title":"Android 彩蛋路径","date":"2016-01-28T06:59:11.000Z","path":"2016/01/28/Android-彩蛋路径/","text":"彩蛋路径是1android/frameworks/base/packages/SystemUI/src/com/android/systemui/egg 博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[]},{"title":"some tips","date":"2016-01-22T07:57:24.000Z","path":"2016/01/22/some-tips/","text":"adb模拟点击ADB中通过input来实现，用于输入touch，key等事件：The sources are: trackball joystick touchnavigation mouse keyboard gamepad touchpad dpad stylus touchscreenThe commands and default sources are: text (Default: touchscreen) keyevent [–longpress] … (Default: keyboard) tap (Default: touchscreen) swipe [duration(ms)] (Default: touchscreen) press (Default: trackball) roll (Default: trackball)1adb shell input touchscreen tap 10 10 adb+python截图screencap 本身支持标准输出，所以可以用管道符链接。但是 adb shell 会将结果中的 LF 转换为 CR+LF，会将 png 的格式破坏。于是这里将LF前的CR移除。12adb shell screencap -p | sed &apos;s/\\r$//&apos; &gt; screen.pngadb shell screencap -p | perl -pe &apos;s/\\x0D\\x0A/\\x0A/g&apos; &gt; screen.png 123import subprocessreturnValue = subprocess.check_output([\"adb\", \"shell\", \"screencap\", \"-p\"])returnValue.replace('\\x0D\\x0A', '\\x0A') 1234567891011121314151617#!/usr/bin/pythonimport subprocessimport timefor i in range(5): tic = time.time() subprocess.call([\"adb\", \"shell\", \"input\", \"touchscreen\", \"tap\", \"10\", \"10\"]) toc = time.time() tic1 = time.time() returnValue = subprocess.check_output([\"adb\", \"shell\", \"screencap\", \"-p\"]).replace('\\x0D\\x0A', '\\x0A') toc1 = time.time() print 'time = ', toc-tic print 'time1 = ', toc1-tic1 #returnValue = returnValue.replace('\\x0D\\x0A', '\\x0A') fileName = 'screenshot-%d.png' % i screenshot = open(fileName, 'w') screenshot.write(returnValue) screenshot.close() 博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[{"name":"tips","slug":"tips","permalink":"http://52ml.me/tags/tips/"}]},{"title":"Image Classification -- Data-driven Approach, k-Nearest Neighbor, train/val/test splits","date":"2016-01-16T14:04:43.000Z","path":"2016/01/16/classification/","text":"前言本文翻译的是这篇CS231n Convolutional Neural Networks for Visual Recognition文章。 图像分类原因 这一节我们将介绍图像分类问题，这是一个从一组固定类别中指定输入图像标签的任务。这是计算机视觉中的一个核心问题，尽管它简单，在实际中有各种各样的应用。此外，我们会在使用过程中看到，许多其他看似不同的计算机视觉任务（如目标检测，分割）可以归结为图像分类。 例子 例如，下图中一个图像分类模型获取一张图片然后指定四个标签的{cat, dog, hat, mug}概率。如图所示，请记住，图像在计算机中表示为一个大的三维数组。在这个例子中，猫的图片宽度为248像素，高度为400像素，并且有三个颜色通道：Red，Green，Blue（或者缩写为RGB）。因此，图像由248×400×3或总共297600个数字组成。每个数字是一个整数，范围从0（黑色）到255（白色）。我们的任务是将百万数据中得四分之一标记为单一的标签，如“猫”。 图像分类的任务是对于一个给定的图像预测一个标签（或这里显示的不同标签下概率分布，用以表示我们的信任）。图像是整数三维数组，整数的范围从0到255，图像的大小是宽度x高度x3。3表示三个颜色通道：Red，Green，Blue。 挑战 由于识别视觉概念（如猫）这个任务对于人来说非常容易做到，这是一个值得思考的涉及到计算机视觉算法视角的挑战。正如我们以下提出的一系列挑战，请记住，图像的原始表示是一个三维阵列: 视点变化 一个物体的可以多个角度观察。 比例变化 可见的物体通常在尺寸上表现出变化（现实世界中的尺寸，不仅是其在图像中的区域）。 形变 许多关注的对象不是刚体，可以以极端的方式变形。 遮挡 关注的对象会被遮挡。有时可能一个对象中的一小部分（甚至几个像素）是可见的。 光照条件 光照的影响在像素级是非常剧烈的。 背景混乱 关注的对象可能融入周围的环境，使他们难以确定。 类内变化 关注的对象往往是比较宽泛的，比如椅子。这些对象中有许多不同的类型，每种类型都有自己的外观。 一个好的图像分类模型所有变量的叉积必须是不变的，同时对于类内变化保持敏感性。 数据驱动方法 我们要写一个什么样的算法才能将图像分为不同的类别？例如，不像写一个排序算法，人们写一个用于识别图像中猫的算法并不是显而易见的。因此，我们采取的方法和你会对小孩子采用的方法一样，而不是试图直接在代码中指定关注的物体的每一类是什么样的。我们给计算机提供每一类物体的很多样本，然后制定学习算法，看看这些例子，了解每个物体的视觉外观。这种方法被称为数据驱动方法，它依赖于已标记图像的训练数据集的最初积累。这里有一个关于这种数据集可能的例子： 这是四个类别训练集的例子。在实践中，我们可能有数以千计的类别，每个类别有成千上万个图像。 图像分类流程 我们看到，图像分类的任务是，输入代表一张图片的像素数组，并为其分配一个标签。我们完整的流程可以按以下形式表示： 输入 我们的输入N个图像，每个图像标为K个不同的类别中的一个。我们将此数据作为训练集。 学习 我们的任务就是利用训练集学习每一个类别是什么样子。我们把这个步骤叫做训练分类器，或学习一个模型。 评估 最后，我们通过让分类器预测一组它从未见过的新图像来评估分类器的质量。我们将用这些图像的真实标签和那些由分类预测的标签进行比较。直观地说，我们希望有大量的预测同真正答案（我们称之为基础事实）相匹配。 近邻分类器作为我们的第一个方法，我们将开发一个被称为近邻分类器的算法。这种分类和卷积神经网络没有关系，并且在实践中很少使用，但它使我们明白图像分类问题的基本方法。 图像分类数据集：CIFAR-10示例 一种流行的微型图像分类数据集CIFAR-10 dataset。此数据集包括60,000个微小的图像，这些图像是32像素x32像素。每个图像都标为十类（例如“飞机，汽车，鸟等”）中的一类。这60,000个图像被划分成包含50,000个图像的训练集和包含10,000个图像的测试集。下图中可以看到从十个类的每个类中都随机选取十个示例图片： 左：CIFAR-10 dataset中的示例图片，右：第一列显示了一些测试图像，接下来，根据根据逐像素差我们显示这些测试图像在训练集中前10个近邻。 假设现在我们得到CIFAR-10训练集中的50,000个图像（每个标签有5,000个图像），我们希望标注剩余的10,000。最近邻分类器将测试图像同训练集中的的每一个图像比较，并预测与其最接近的训练集图像的标签。在上图右侧，你可以看到10个测试图像处理后的结果。注意，仅约3/10的图像被正确检索到，而剩余的7/10没有被正确检索。例如，第八行中与马的头部最近邻的训练图像是一部红色的汽车，大概是由于汽车背景过于黑。其结果导致了一匹马在这种情况下被被误认为成一辆车。 你可能已经注意到，我们并未详细说明是如何比较两幅图片的，这个例子中图片的大小都是32×32×3。其中一个最简单的办法是按照像素进行比较，并把差值相加。换句话说，给定的两个图片并把他们当作矢量$I_1$，$I_2$，比较这两个图片一个合理的选择是L1 distance：$$d_1 (I_1, I_2) = \\sum_p \\left| I^p_1 - I^p_2 \\right|$$这里把所有差值相加，一下是具体的步骤： 这是采用逐像素差异来比较两个图像的L1 distance（这是一个颜色通道）的一个例子。两个图像按像素相减，然后所有差异相加。如果两个图像相同，结果将是零。但是如果图像有很大的不同，结果将非常大。 让我们看看如何用代码实现分类器。首先，加载CIFAR-10数据集到内存中，存储为4个数组：训练数据集及标签和测试数据集及标签。在下面的代码，Xtr（大小是50,000×32×32×3）存储训练集中的所有图像，相应的1维阵列Ytr（长度50,000）存储训练集的标签（从0到9）： 1234Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide# flatten out all images to be one-dimensionalXtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072 现在，我们把所有的图像都延展成行向量，以下是我们如何训练、评估分类器： 123456nn = NearestNeighbor() # create a Nearest Neighbor classifier classnn.train(Xtr_rows, Ytr) # train the classifier on the training images and labelsYte_predict = nn.predict(Xte_rows) # predict labels on the test images# and now print the classification accuracy, which is the average number# of examples that are correctly predicted (i.e. label matches)print 'accuracy: %f' % ( np.mean(Yte_predict == Yte) ) 注意，作为评价的标准，通常使用精确度衡量正确预测的百分比。请注意，我们要建立的所有分类器，将使用这一个通用的API：train(X,y)，该函数获取数据及相应标签用以训练。分类器应该建立某种标签的模型，该模型可以用数据进行预测。接着一个predict(X)函数，该函数获取新的数据并预测其标签。当然，我们已经忽略了事物的主体–分类器本身。下面是一个简单的L1 distance近邻分类器的实现模板： 123456789101112131415161718192021222324252627import numpy as npclass NearestNeighbor: def __init__(self): pass def train(self, X, y): \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\" # the nearest neighbor classifier simply remembers all the training data self.Xtr = X self.ytr = y def predict(self, X): \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\" num_test = X.shape[0] # lets make sure that the output type matches the input type Ypred = np.zeros(num_test, dtype = self.ytr.dtype) # loop over all test rows for i in xrange(num_test): # find the nearest training image to the i'th test image # using the L1 distance (sum of absolute value differences) distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1) min_index = np.argmin(distances) # get the index with smallest distance Ypred[i] = self.ytr[min_index] # predict the label of the nearest example return Ypred 如果你运行这段代码，你会看到该分类器在CIFAR-10上只有38.6％的精确度。这是比随机猜测（10％的准确度，因为有10个类）要好一点，但是远不及人的行为（估计约为94％）或最好的卷积神经网络可以达到95％，和人的准确率相匹配（参考Kaggle比赛上最近CIFAR-10的排行榜）。选择distance 有许多计算两个向量之间距离的方法。另一种常见的选择是L2 distance，其几何解释就是计算两个向量之间的欧几里得距离。公式如下：$$d_2 (I_1, I_2) = \\sqrt{\\sum_p \\left( I^p_1 - I^p_2 \\right)^2}$$换句话说，我们会像以前那样计算逐像素的差异，但这次我们将所有差异值取平方然后相加，最后取平方根。在numpy中，使用上面代码我们只需要替换其中的一行。下面这行计算L2 distance：1distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1)) 注意，上述代码调用了np.sqrt，但在一个实用的近邻应用中，我们可以忽略求平方根操作，因为平方根是一个单调函数。也就是说，它扩展了距离的绝对值大小，但它保留了排序，所以有没有取平方根近邻都是相同的。如果你用这个距离的近邻分类器在CIFAR-10上运行，你将获得35.4％的准确度（略低于L1 distance的结果）。L1 vs. L2 考虑两个度量之间的差异很有意义。具体地，当涉及到两个向量之间的差异时L2比L1更严厉。也就是说L2相对于中等的差异更喜欢大的差异。L1和L2是p-norm特殊情况中最常用的。 k-近邻分类你可能已经注意到了，当我们做预测时，只用最近邻图像的标签，这非常奇怪。事实上，使用K-近邻分类器几乎总是可以得到更好的结果。我们的想法很简单：找到训练集中前k个最接近的图像，而不是找训练集中最接近的图像，并让它们和测试图像的标签一一对应。特别是，当k= 1时，得到最近邻分类器。直观地看，K值越高产生平滑作用，使分类更加耐异常值： 这是使用2维点和3个类（红，蓝，绿）展示的最近邻和5-近邻分类器之间的差异的例子。着色区域显示的决策边界是由使用L2 distance分类器产生的。白色区域中的点分类不清晰（即图中的点至少和两个类对应）。请注意，在最近邻分类器中异常数据点生成可能不正确的预测区域（例如蓝色区域中的绿点），而5-近邻分类器抚平了这些不正确的地方，可能会对测试数据产生更好的泛化（未示出）。 在实践中，你将几乎总是想用k近邻。但是，你应该使用什么样的k值？我们下面介绍这个问题。 超参数调整的验证集k-近邻分类器需要对设置k的值。但是值为多少效果最好？此外，我们看到，我们可以使用有许多不同距离函数，：L1，L2，还有很多其他我们甚至没有考虑的选择（如：点积）。这些选择被称为超参数，在设计很多机器学习算法时它们都会经常出现。但是选择什么样的值通常并不清楚。 你也许会认为，我们应该尝试许多不同的值，看看哪个效果最好。这是一个很好的想法，这确实是我们会做的，但这一定要非常谨慎。特别是，不能用测试集调整超参数。无论何时你设计机器学习算法，你应该把测试集当做非常宝贵的资源，应该树立只有在最后时刻才能使用它们的观念。否则，真正的危险是你可能在测试集上把你的超参数调整的很好，但一旦你部署你的模型，你会看到性能显著降低。在实践中，我们会说，你的测试集过拟合。另外一个看待这个问题的角度是，如果你在测试集上调整你的超参数，你实际上是把测试集当做训练集在使用，因此你获得的性能同你部署模型后真正观察到的性能相比会过于乐观。但是，如果你只在最后使用一次测试集，它仍然是能非常好的衡量你的分类器泛化能力（稍后我们会看到更多关于泛化能力的讨论）。Evaluate on the test set only a single time, at the very end.幸运的是，这有调整超参数的正确方式，并且不会触及测试集。想法是把训练集分成两部分：略小的训练集和我们所说的验证集。以CIFAR-10为例，我们可以使用训练集中49,000个图像进行训练，并留下1000个图像作为验证集。这个验证集基本上是一个用来调整超参数假的测试集。 以下是在CIFAR-10这个例子中用法： 123456789101112131415161718192021# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before# recall Xtr_rows is 50,000 x 3072 matrixXval_rows = Xtr_rows[:1000, :] # take first 1000 for validationYval = Ytr[:1000]Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for trainYtr = Ytr[1000:]# find hyperparameters that work best on the validation setvalidation_accuracies = []for k in [1, 3, 5, 10, 20, 50, 100]: # use a particular value of k and evaluation on validation data nn = NearestNeighbor() nn.train(Xtr_rows, Ytr) # here we assume a modified NearestNeighbor class that can take a k as input Yval_predict = nn.predict(Xval_rows, k = k) acc = np.mean(Yval_predict == Yval) print 'accuracy: %f' % (acc,) # keep track of what works on the validation set validation_accuracies.append((k, acc)) 这段程序结束后，我们可以绘制曲线图，显示其中效果最好的K值。然后，我们会一直使用这个值，并且在真正的测试集上评估一次。 把训练集分割成训练集和验证集。使用验证集调整所有的超参数。最后在测试集上运行一次并报告性能。 交叉验证 在训练数据集（因此也是验证数据集）规模较小的情况下，人们有时会使用更加先进的方法进行超参数调整，这种方法被称为交叉验证。继续前面的例子，这个想法是，为了避免随意挑选1,000个数据点作为验证集和余下的作为训练集，你可以通过遍历确定K值的不同验证集得到平均的性能，这样可以得到更好的更低噪音的估值。例如，在5次交叉验证中，我们将在训练数据分成5等份，使用其中份进行训练，1份进行验证。然后，我们将依次将每个等份作为验证集，评估性能，最后求不同等份性能的平均值。 参数k为5时，5倍交叉验证运行例子。Example of a 5-fold cross-validation run for the parameter k. 对于每个k值，我们在训练4倍和评估5日。因此，对于每K个收到5精度上验证倍（精度为y轴，每个结果是一个点）。For each value of k we train on 4 folds and evaluate on the 5th. Hence, for each k we receive 5 accuracies on the validation fold (accuracy is the y-axis, each result is a point). The trend line is drawn through the average of the results for each k and the error bars indicate the standard deviation. Note that in this particular case, the cross-validation suggests that a value of about k = 7 works best on this particular dataset (corresponding to the peak in the plot). If we used more than 5 folds, we might expect to see a smoother (i.e. less noisy) curve. 实践 在实践中，人们更喜欢用一次验证，而不是交叉验证，因为交叉验证的运算量非常大。人们倾向于使用50％-90％的训练数据进行训练，剩余的验证。然而，这取决于多种因素：例如，如果超参数的数目大则可能更喜欢使用更大验证集。如果在验证集合样本的数目小（可能只有几百个左右），使用交叉验证则更加安全。实践中典型的交叉验证数目是3倍，5倍或10倍交叉验证。 常用数据集。列出了训练和测试集。训练集被分成若干等份（例如这里5份）。1-4等份成为训练集。一个等份（如这里黄色的第5等份）作为验证集并且被用于调整超参数。交叉验证会分别从1-5等份挑选验证集。这被称为5-倍交叉验证。最后一旦训练好模型，确定好所有超参数，就用测试数据（红色）对该模型进行一次评价。 最近邻分类的优缺点 最近邻分类的优缺点值得思考。显然，一个优点是，很容易实现和理解。此外，这个分类器不花时间来训练，因为所需要的就是存储训练数据，有可能需要索引训练数据。但是，我们在测试时会付出计算成本，因为把测试集分类时需要和每一个训练样本进行比对。这是退步，因为在实践中，我们经常更加关心的测试的效率而不是训练时的效率。事实上，我们在后面课程中会涉及的深度神经网络把这个平衡推向了另一个极端：训练时代价很高，但是一旦训练结束后把一个新的测试样本分类就没有什么代价了。这种操作方式在实践中更加可取。 顺便说一句，最近邻分类器的计算复杂度是一个活跃的研究领域，并且几个近似最近邻（ANN）的算法和库存在，可以加速最近邻在数据集的查询（例如FLANN）。这些算法允许折中最邻近算法的正确率和算法的时空复杂度，算法通常依赖于预处理/索引阶段，涉及构建kd树，或运行k-means算法。最近邻分类有时在某些情况下（特别是如果数据是低维的）是一个不错的选择，但很少适合于图像分类问题。一个原因是图像是高维的对象（即它们通常含有许多像素），以及高维空间的距离是非常反直觉的。下图说明了这一点，我们上面开发的基于像素的L2相似度和感官的相似度有很大不同： 高维数据（尤其是图像）中基于像素的距离非常的不直观。原始图像（左）和它旁边三个图像的L2距离非常远。显然，逐像素距离在感官或语义相似度上根本不适用。 下面是多个图像来说服大家，用像素差异比较图像是不够的。我们可以使用一个名为t-SNE可视化技术处理CIFAR-10图像并将其嵌入二维中，and embed them in two dimensions so that their (local) pairwise distances are best preserved. 在该可视化中，显示出来相近的图像在上述我们开发出来的L2距离上非常接近： 使用t-SNE将CIFAR-10图像以二维方式展示。这幅图片中相邻的图片在L2像素距离上也是相近的。请注意背景的影响比真实的意义大的多。点击这里查看一个更大的可视化版本。 具体地，注意，互相接近的图片随着颜色或者背景不同而变动，而不是它们真实的意义。例如，可以看到一条狗非常靠近一个青蛙因为两者正好是白色背景。理想情况下，我们希望所有的10个类别的图像形成自己的集群，使同一类的图片都在附近彼此不分，而与其他的特点和变化（如背景）无关。然而，要达到这个性能，我们将必须超越原始像素。 总结 我们介绍了图像分类问题，这里我们有一组都标有一个单一类别的图像。我们接着预测新的测试图像的类别，并测量预测的准确性。 我们引入了一个简单的分类器叫做最近邻分类器。我们看到，和这个分类器相关的多个超参数（如k的值，或例子中用来比较的不同类型的距离），没有明显的办法选择他们。。 我们看到，正确设置这些超参数的方法是将训练数据分为两个：一个训练集和一个我们称之为验证集的假的测试集。我们尝试不同的超参数值，并保存在验证集上有最佳性能的值。 如果有缺乏训练数据的问题，我们讨论了一个叫做交叉验证的程序，它可以在评估超参数时帮助减少噪音。 一旦发现最佳超参数，我们解决了这些问题，并在实际的测试集执行一次评估。 我们看到，最近邻分类可以在CIFAR-10上得到约40％的精确度。这是简单的实现，但是要求我们存储整个训练集，并且在测试集评估时消耗非常大。 最后，我们看到，在原始像素上使用L1或L2距离并不合适，因为距离和背景、图像的颜色分布的相关性比它们的实际内容更强。 在接下来的课程，我们将着手解决这些挑战，并获得最终解决方案，可以达到90％的精确度，可以让我们在一次训练完成之后就彻底放弃训练集，使得我们能够在不到一毫秒内评估一个测试图像。 博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[{"name":"cs231n","slug":"cs231n","permalink":"http://52ml.me/tags/cs231n/"}]},{"title":"Mac sed 坑","date":"2016-01-16T02:47:46.000Z","path":"2016/01/16/Mac-sed-坑/","text":"坑1执行1sed -i \"s/xxx/yyy/g\" filename 出现错误1sed: 1: invalid command code B 这种在Linux的用法不可以在Mac下直接使用，需要加上’’12sed -i '' \"s/xxx/yyy/g\" filename (不需要备份)sed -i '.bak' \"s/xxx/yyy/g\" filename (需要备份，备份为filename.bak) 坑2上述命令执行后仍有错误1sed: RE error: illegal byte sequence 需要在shell中加上：12export LC_COLLATE=&apos;C&apos;export LC_CTYPE=&apos;C&apos; 博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[]},{"title":"学习计划","date":"2016-01-15T08:03:01.000Z","path":"2016/01/15/Learning-Plan/","text":"课程 课程 机构 进度 链接 课程记录 Machine Learning Stanford University(Cousera) 100% 机器学习 Machine Learning Washington University(Cousera) 33% 机器学习 Algorithms, Part I Princeton University (Cousera) 0% 算法 Convolutional Neural Networks for Visual Recognition Stanford University 0% 卷积神经网络的视觉识别 Deep Learning Udacity 0% 深度学习 Machine Learning: Reinforcement Learning Udacity 0% 强化学习 Statistical Learning Stanford University(edX) 0% 统计学习 Deep Learning for Natural Language Processing Stanford University 0% 在自然语言处理中使用深度学习 FP101x Introduction to Functional Programming Delft University of Technology(edX) 0% FP101x函数式编程介绍 scikit-learn 0% sklearn Kaggle 0% Kaggle 教材 博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[{"name":"学习计划","slug":"学习计划","permalink":"http://52ml.me/tags/学习计划/"}]},{"title":"Generalized Linear Models","date":"2016-01-13T14:47:02.000Z","path":"2016/01/13/Generalized-Linear-Models/","text":"博客地址：52ml.me原创文章，版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0","tags":[{"name":"ml","slug":"ml","permalink":"http://52ml.me/tags/ml/"}]}]